# -*- coding: utf-8 -*-
"""base code_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A5xUWQqr-I7saOCyoLvsDrIAMDrg0RjZ
"""

# ======================
# 0. Kaggle APIë¡œ ë°ì´í„° ìë™ ë‹¤ìš´ë¡œë“œ (Drive X)
# ======================

import os
from pathlib import Path

# Colabì— kaggle.json ì—…ë¡œë“œí•´ì•¼ í•¨
# âš ï¸ ì•„ë˜ ì…€ ì‹¤í–‰í•˜ë©´ íŒŒì¼ ì—…ë¡œë“œ ì°½ ëœ¸
from google.colab import files
files.upload()  # kaggle.json ì—…ë¡œë“œí•˜ì„¸ìš”

# kaggle.json ì„¸íŒ…
os.makedirs('/root/.kaggle', exist_ok=True)
os.system('mv kaggle.json /root/.kaggle/')
os.system('chmod 600 /root/.kaggle/kaggle.json')

# Kaggleì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
!kaggle competitions download -c state-farm-distracted-driver-detection -p ./dataset
!unzip -qq ./dataset/state-farm-distracted-driver-detection.zip -d ./dataset

base_dir = Path("./dataset/state-farm-distracted-driver-detection")

print("âœ… ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ:", base_dir.exists())

!pip install kaggle
from google.colab import files
files.upload()

ls -1ha kaggle.json

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

# Permission Warning ë°©ì§€
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c state-farm-distracted-driver-detection

!unzip state-farm-distracted-driver-detection

# ======================
# 1. ê¸°ë³¸ ì„¤ì •
# ======================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from tqdm.notebook import tqdm
import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from sklearn.model_selection import KFold
import os

# GPU ìë™ ì„ íƒ
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}')


# ======================
# 2. ê²½ë¡œ ì„¤ì •
# ======================

from pathlib import Path
import os

base_dir = Path("/content")

driver_csv_path = base_dir / "driver_imgs_list.csv"
train_dir = base_dir / "imgs" / "train"
test_dir = base_dir / "imgs" / "test"

print("âœ… CSV ê²½ë¡œ:", driver_csv_path)
print("âœ… Train ê²½ë¡œ:", train_dir)
print("âœ… Test ê²½ë¡œ:", test_dir)

print("CSV ì¡´ì¬ ì—¬ë¶€:", driver_csv_path.exists())
print("Train í´ë” ì¡´ì¬ ì—¬ë¶€:", train_dir.exists())
print("Test í´ë” ì¡´ì¬ ì—¬ë¶€:", test_dir.exists())


# ======================
# 3. í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ======================
img_size = 224
batch_size = 32 if device.type == 'cuda' else 8
num_classes = 10
num_epochs = 10
learning_rate = 1e-4
num_workers = 2 if device.type == 'cuda' else 0


# ======================
# 4. ë°ì´í„° ë¡œë”©
# ======================
driver_df = pd.read_csv(driver_csv_path)
all_drivers = sorted(driver_df['subject'].unique())

n_folds = 5
kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)

fold_splits = []
for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(all_drivers)):
    train_drivers = [all_drivers[i] for i in train_indices]
    val_drivers = [all_drivers[i] for i in val_indices]
    fold_splits.append({
        'fold': fold_idx + 1,
        'train_drivers': train_drivers,
        'val_drivers': val_drivers
    })

print(f"ì´ {n_folds}ê°œ fold ì¤‘ 1ê°œë§Œ í•™ìŠµ ì˜ˆì •.")


# ======================
# 5. Dataset ì •ì˜
# ======================
class DriverDataset(Dataset):
    def __init__(self, data_dir, driver_df, driver_list, transform=None, is_test=False):
        self.data_dir = data_dir
        self.transform = transform
        self.is_test = is_test
        self.images, self.labels = [], []

        if is_test:
            for img_name in os.listdir(data_dir):
                self.images.append(os.path.join(data_dir, img_name))
        else:
            subset = driver_df[driver_df['subject'].isin(driver_list)]
            for _, row in subset.iterrows():
                class_name = row['classname']
                img_name = row['img']
                img_path = os.path.join(data_dir, class_name, img_name)
                self.images.append(img_path)
                self.labels.append(int(class_name[1:]))
        print(f"{'í…ŒìŠ¤íŠ¸ì…‹' if is_test else f'ìš´ì „ì {len(driver_list)}ëª…'}, ì´ë¯¸ì§€ {len(self.images)}ê°œ")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        if self.is_test:
            return image, os.path.basename(img_path)
        else:
            label = self.labels[idx]
            return image, label


# ======================
# 6. Transform ì„¤ì •
# ======================
transform_train = transforms.Compose([
    transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.RandomGrayscale(p=0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

transform_eval = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(img_size),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])



# ======================
# 7. í•™ìŠµ / ê²€ì¦ í•¨ìˆ˜
# ======================
def train_epoch(model, loader, criterion, optimizer):
    model.train()
    running_loss, correct, total = 0.0, 0, 0
    for inputs, labels in tqdm(loader, desc="Training"):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * inputs.size(0)
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    return running_loss / total, 100 * correct / total


def validate(model, loader, criterion):
    model.eval()
    running_loss, correct, total = 0.0, 0, 0
    with torch.no_grad():
        for inputs, labels in tqdm(loader, desc="Validating"):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    return running_loss / total, 100 * correct / total


# ======================
# 8. Fold 1ê°œë§Œ í•™ìŠµ
# ======================
fold_info = fold_splits[0]
fold_idx = fold_info['fold']
train_drivers = fold_info['train_drivers']
val_drivers = fold_info['val_drivers']

print(f"\n========== Fold {fold_idx} ì‹œì‘ ==========")

train_dataset = DriverDataset(train_dir, driver_df, train_drivers, transform_train)
val_dataset = DriverDataset(train_dir, driver_df, val_drivers, transform_eval)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

# âœ… VGG16 ëª¨ë¸ (weights ë²„ì „ í˜¸í™˜)
model = models.vgg16(weights='IMAGENET1K_V1')
model.classifier[6] = nn.Linear(4096, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

best_val_loss = float('inf')
best_model_path = f'best_vgg16_fold{fold_idx}.pth'
history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}

for epoch in range(num_epochs):
    print(f"\nEpoch [{epoch+1}/{num_epochs}]")
    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)
    val_loss, val_acc = validate(model, val_loader, criterion)
    history['train_loss'].append(train_loss)
    history['val_loss'].append(val_loss)
    history['train_acc'].append(train_acc)
    history['val_acc'].append(val_acc)

    print(f"Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%")

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save({'model_state_dict': model.state_dict()}, best_model_path)
        print(f"âœ… Best model saved at {best_model_path}")

print(f"\nFold {fold_idx} ì™„ë£Œ! Best Val Loss: {best_val_loss:.4f}")


# ======================
# 9. í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ (Kaggle ì œì¶œìš©)
# ======================
print("\nğŸ“¦ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...")

test_dataset = DriverDataset(test_dir, driver_df, [], transform_eval, is_test=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

checkpoint = torch.load(best_model_path, map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

all_preds = []
img_names = []

with torch.no_grad():
    for imgs, filenames in tqdm(test_loader, desc="Predicting"):
        imgs = imgs.to(device)
        outputs = model(imgs)
        probs = torch.softmax(outputs, dim=1)
        all_preds.append(probs.cpu().numpy())
        img_names.extend(filenames)

all_preds = np.vstack(all_preds)
print("âœ… ì˜ˆì¸¡ ì™„ë£Œ!")

submission = pd.DataFrame({
    'img': img_names,
    **{f'c{i}': all_preds[:, i] for i in range(10)}
})

submission_file = 'vgg16_fold1_submission.csv'
submission.to_csv(submission_file, index=False)
print(f"\nâœ… Submission íŒŒì¼ ìƒì„± ì™„ë£Œ: {submission_file}")
print(submission.head())

# ======================
# 1. ê¸°ë³¸ ì„¤ì •
# ======================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from tqdm.notebook import tqdm
import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from sklearn.model_selection import KFold
import os

# GPU ìë™ ì„ íƒ
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}')


# ======================
# 2. ê²½ë¡œ ì„¤ì •
# ======================

from pathlib import Path
import os

base_dir = Path("/content")

driver_csv_path = base_dir / "driver_imgs_list.csv"
train_dir = base_dir / "imgs" / "train"
test_dir = base_dir / "imgs" / "test"

print("âœ… CSV ê²½ë¡œ:", driver_csv_path)
print("âœ… Train ê²½ë¡œ:", train_dir)
print("âœ… Test ê²½ë¡œ:", test_dir)

print("CSV ì¡´ì¬ ì—¬ë¶€:", driver_csv_path.exists())
print("Train í´ë” ì¡´ì¬ ì—¬ë¶€:", train_dir.exists())
print("Test í´ë” ì¡´ì¬ ì—¬ë¶€:", test_dir.exists())


# ======================
# 3. í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ======================
img_size = 224
batch_size = 32 if device.type == 'cuda' else 8
num_classes = 10
num_epochs = 10
learning_rate = 1e-4
num_workers = 2 if device.type == 'cuda' else 0


# ======================
# 4. ë°ì´í„° ë¡œë”©
# ======================
driver_df = pd.read_csv(driver_csv_path)
all_drivers = sorted(driver_df['subject'].unique())

n_folds = 5
kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)

fold_splits = []
for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(all_drivers)):
    train_drivers = [all_drivers[i] for i in train_indices]
    val_drivers = [all_drivers[i] for i in val_indices]
    fold_splits.append({
        'fold': fold_idx + 1,
        'train_drivers': train_drivers,
        'val_drivers': val_drivers
    })

print(f"ì´ {n_folds}ê°œ fold ì¤‘ 1ê°œë§Œ í•™ìŠµ ì˜ˆì •.")


# ======================
# 5. Dataset ì •ì˜
# ======================
class DriverDataset(Dataset):
    def __init__(self, data_dir, driver_df, driver_list, transform=None, is_test=False):
        self.data_dir = data_dir
        self.transform = transform
        self.is_test = is_test
        self.images, self.labels = [], []

        if is_test:
            for img_name in os.listdir(data_dir):
                self.images.append(os.path.join(data_dir, img_name))
        else:
            subset = driver_df[driver_df['subject'].isin(driver_list)]
            for _, row in subset.iterrows():
                class_name = row['classname']
                img_name = row['img']
                img_path = os.path.join(data_dir, class_name, img_name)
                self.images.append(img_path)
                self.labels.append(int(class_name[1:]))
        print(f"{'í…ŒìŠ¤íŠ¸ì…‹' if is_test else f'ìš´ì „ì {len(driver_list)}ëª…'}, ì´ë¯¸ì§€ {len(self.images)}ê°œ")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        if self.is_test:
            return image, os.path.basename(img_path)
        else:
            label = self.labels[idx]
            return image, label


# ======================
# 6. Transform ì„¤ì •
# ======================
from torchvision import transforms

transform_train = transforms.Compose([
    transforms.Resize((256, 256)),  # ê¸°ë³¸ ë¦¬ì‚¬ì´ì¦ˆ
    transforms.ToTensor(),          # PIL Imageë¥¼ Tensorë¡œ ë³€í™˜
    transforms.RandomApply([        # ëœë¤í•˜ê²Œ Sharpen ì ìš©
        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1.5))
    ], p=0.3),
    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05)),  # ì•½ê°„ì˜ ì´ë™/íšŒì „
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.25, contrast=0.3, saturation=0.2, hue=0.02),
    transforms.RandomErasing(p=0.2, scale=(0.02, 0.15), ratio=(0.3, 3.3), value='random'),
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

transform_eval = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])



# ======================
# 7. í•™ìŠµ / ê²€ì¦ í•¨ìˆ˜
# ======================
def train_epoch(model, loader, criterion, optimizer):
    model.train()
    running_loss, correct, total = 0.0, 0, 0
    for inputs, labels in tqdm(loader, desc="Training"):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * inputs.size(0)
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    return running_loss / total, 100 * correct / total


def validate(model, loader, criterion):
    model.eval()
    running_loss, correct, total = 0.0, 0, 0
    with torch.no_grad():
        for inputs, labels in tqdm(loader, desc="Validating"):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    return running_loss / total, 100 * correct / total


# ======================
# 8. Fold 1ê°œë§Œ í•™ìŠµ
# ======================
fold_info = fold_splits[0]
fold_idx = fold_info['fold']
train_drivers = fold_info['train_drivers']
val_drivers = fold_info['val_drivers']

print(f"\n========== Fold {fold_idx} ì‹œì‘ ==========")

train_dataset = DriverDataset(train_dir, driver_df, train_drivers, transform_train)
val_dataset = DriverDataset(train_dir, driver_df, val_drivers, transform_eval)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

# âœ… VGG16 ëª¨ë¸ (weights ë²„ì „ í˜¸í™˜)
model = models.vgg16(weights='IMAGENET1K_V1')
model.classifier[6] = nn.Linear(4096, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

best_val_loss = float('inf')
best_model_path = f'best_vgg16_fold{fold_idx}.pth'
history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}

for epoch in range(num_epochs):
    print(f"\nEpoch [{epoch+1}/{num_epochs}]")
    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)
    val_loss, val_acc = validate(model, val_loader, criterion)
    history['train_loss'].append(train_loss)
    history['val_loss'].append(val_loss)
    history['train_acc'].append(train_acc)
    history['val_acc'].append(val_acc)

    print(f"Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%")

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save({'model_state_dict': model.state_dict()}, best_model_path)
        print(f"âœ… Best model saved at {best_model_path}")

print(f"\nFold {fold_idx} ì™„ë£Œ! Best Val Loss: {best_val_loss:.4f}")


# ======================
# 9. í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ (Kaggle ì œì¶œìš©)
# ======================
print("\nğŸ“¦ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...")

test_dataset = DriverDataset(test_dir, driver_df, [], transform_eval, is_test=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

checkpoint = torch.load(best_model_path, map_location=device)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

all_preds = []
img_names = []

with torch.no_grad():
    for imgs, filenames in tqdm(test_loader, desc="Predicting"):
        imgs = imgs.to(device)
        outputs = model(imgs)
        probs = torch.softmax(outputs, dim=1)
        all_preds.append(probs.cpu().numpy())
        img_names.extend(filenames)

all_preds = np.vstack(all_preds)
print("âœ… ì˜ˆì¸¡ ì™„ë£Œ!")

submission = pd.DataFrame({
    'img': img_names,
    **{f'c{i}': all_preds[:, i] for i in range(10)}
})

submission_file = 'vgg16_submission_v2.csv'
submission.to_csv(submission_file, index=False)
print(f"\nâœ… Submission íŒŒì¼ ìƒì„± ì™„ë£Œ: {submission_file}")
print(submission.head())