{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 5048,
          "databundleVersionId": 868335,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "resnet_gnws_centercut",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "1WidG-0Mi_jw"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "state_farm_distracted_driver_detection_path = kagglehub.competition_download('state-farm-distracted-driver-detection')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "GbNEEpZpi_jy"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T06:32:50.08865Z",
          "iopub.execute_input": "2025-11-16T06:32:50.089362Z"
        },
        "id": "DmiyD3Wti_j1",
        "outputId": "fddda2a6-f31f-415f-f5f0-921e7c55367a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/state-farm-distracted-driver-detection/sample_submission.csv\n/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 0) Kaggle ÌôòÍ≤Ω Ï§ÄÎπÑ\n",
        "# =========================================\n",
        "import os, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "BASE_DIR   = \"/kaggle/input/state-farm-distracted-driver-detection\"\n",
        "DRIVER_CSV = f\"{BASE_DIR}/driver_imgs_list.csv\"\n",
        "TRAIN_DIR  = f\"{BASE_DIR}/imgs/train\"\n",
        "TEST_DIR   = f\"{BASE_DIR}/imgs/test\"\n",
        "\n",
        "print(\"üìÅ BASE_DIR:\", BASE_DIR)\n",
        "print(\"üìÑ driver_imgs_list.csv:\", os.path.exists(DRIVER_CSV))\n",
        "print(\"üìÅ Train:\", os.path.exists(TRAIN_DIR))\n",
        "print(\"üìÅ Test :\", os.path.exists(TEST_DIR))\n",
        "\n",
        "# =========================================\n",
        "# 1) ÎùºÏù¥Î∏åÎü¨Î¶¨\n",
        "# =========================================\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"DEVICE:\", device)\n",
        "\n",
        "# =========================================\n",
        "# 2) ÏÑ§Ï†ïÍ∞í\n",
        "# =========================================\n",
        "IMG_SIZE      = 224\n",
        "NUM_CLASSES   = 10\n",
        "BATCH_SIZE    = 64\n",
        "EPOCHS        = 40\n",
        "LR            = 5e-5\n",
        "WEIGHT_DECAY  = 1e-4\n",
        "NUM_WORKERS   = 2\n",
        "PATIENCE      = 6\n",
        "FOLD_INDEX    = 1\n",
        "\n",
        "OFFLINE_CACHE_DIR = \"/kaggle/working/statefarm_offline_cache\"\n",
        "os.makedirs(OFFLINE_CACHE_DIR, exist_ok=True)\n",
        "\n",
        "# =========================================\n",
        "# 3) Îç∞Ïù¥ÌÑ∞ Î°úÎìú + KFold\n",
        "# =========================================\n",
        "driver_df = pd.read_csv(DRIVER_CSV)\n",
        "ALL_DRIVERS = sorted(driver_df[\"subject\"].unique())\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# =========================================\n",
        "# 4) OFFLINE ÌåÄ Í≥µÌÜµ Ï†ÑÏ≤òÎ¶¨\n",
        "# =========================================\n",
        "def team_processing_offline_pil(img_pil, out_size=IMG_SIZE):\n",
        "    img = img_pil.convert(\"RGB\")\n",
        "    img = img.resize((out_size, out_size), Image.BILINEAR)\n",
        "\n",
        "    img = ImageEnhance.Contrast(img).enhance(1.05)\n",
        "    img = ImageEnhance.Sharpness(img).enhance(1.05)\n",
        "\n",
        "    r, g, b = img.split()\n",
        "    r, g, b = ImageOps.equalize(r), ImageOps.equalize(g), ImageOps.equalize(b)\n",
        "    return Image.merge(\"RGB\", (r, g, b))\n",
        "\n",
        "\n",
        "def build_offline_cache(train_dir, driver_df, driver_list, cache_root):\n",
        "    for c in [f\"c{i}\" for i in range(NUM_CLASSES)]:\n",
        "        os.makedirs(os.path.join(cache_root, c), exist_ok=True)\n",
        "\n",
        "    subset = driver_df[driver_df[\"subject\"].isin(driver_list)]\n",
        "    for row in tqdm(subset.itertuples(), total=len(subset), desc=\"OFFLINE caching\"):\n",
        "        cls, img = row.classname, row.img\n",
        "        src = os.path.join(train_dir, cls, img)\n",
        "        dst = os.path.join(cache_root, cls, img)\n",
        "\n",
        "        if os.path.exists(dst):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with Image.open(src) as im:\n",
        "                out = team_processing_offline_pil(im)\n",
        "                out.save(dst, quality=95)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# =========================================\n",
        "# 5) ONLINE transform\n",
        "# =========================================\n",
        "normalize_imagenet = transforms.Normalize([0.485,0.456,0.406],\n",
        "                                          [0.229,0.224,0.225])\n",
        "\n",
        "transform_online_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.15, 0.15, 0.10),\n",
        "    transforms.RandomRotation(12),\n",
        "    transforms.ToTensor(),\n",
        "    normalize_imagenet\n",
        "])\n",
        "\n",
        "# üî• Option A ‚Äî CenterCrop Ï∂îÍ∞Ä\n",
        "transform_eval = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    normalize_imagenet\n",
        "])\n",
        "\n",
        "# =========================================\n",
        "# 6) Dataset ÌÅ¥ÎûòÏä§\n",
        "# =========================================\n",
        "class DriverDataset(Dataset):\n",
        "    def __init__(self, data_dir, driver_df, driver_list, transform=None):\n",
        "        self.transform = transform\n",
        "        self.images, self.labels = [], []\n",
        "\n",
        "        subset = driver_df[driver_df[\"subject\"].isin(driver_list)]\n",
        "        for _, row in subset.iterrows():\n",
        "            cls = row[\"classname\"]\n",
        "            img = row[\"img\"]\n",
        "            self.images.append(os.path.join(data_dir, cls, img))\n",
        "            self.labels.append(int(cls[1:]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        with Image.open(path) as im:\n",
        "            im = im.convert(\"RGB\")\n",
        "            if self.transform:\n",
        "                im = self.transform(im)\n",
        "        return im, label\n",
        "\n",
        "# =========================================\n",
        "# 7) Conv2d WS + GN Ï†ÅÏö©\n",
        "# =========================================\n",
        "class Conv2dWS(nn.Conv2d):\n",
        "    def forward(self, x):\n",
        "        w = self.weight\n",
        "        w = w - w.mean(dim=(1,2,3), keepdim=True)\n",
        "        s = w.view(w.size(0), -1).std(dim=1, keepdim=True).view(-1,1,1,1) + 1e-5\n",
        "        w = w / s\n",
        "        return nn.functional.conv2d(x, w, self.bias, self.stride,\n",
        "                                    self.padding, self.dilation, self.groups)\n",
        "\n",
        "def replace_bn_with_gn(module, groups=32):\n",
        "    for name, m in list(module.named_children()):\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            setattr(module, name, nn.GroupNorm(groups, m.num_features))\n",
        "        else:\n",
        "            replace_bn_with_gn(m, groups)\n",
        "\n",
        "def replace_conv_with_ws(module):\n",
        "    for name, m in list(module.named_children()):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            ws = Conv2dWS(m.in_channels, m.out_channels,\n",
        "                          m.kernel_size, m.stride, m.padding,\n",
        "                          m.dilation, m.groups, bias=(m.bias is not None))\n",
        "            ws.weight.data.copy_(m.weight.data)\n",
        "            if m.bias is not None: ws.bias.data.copy_(m.bias.data)\n",
        "            setattr(module, name, ws)\n",
        "        else:\n",
        "            replace_conv_with_ws(m)\n",
        "\n",
        "# =========================================\n",
        "# 8) ResNet34(GN+WS) + Dropout0.1 + layer4 only train\n",
        "# =========================================\n",
        "def build_resnet34_gn_ws_dropout(num_classes=NUM_CLASSES):\n",
        "    model = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    in_feat = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(in_feat, num_classes)\n",
        "    )\n",
        "\n",
        "    replace_bn_with_gn(model.layer3)\n",
        "    replace_bn_with_gn(model.layer4)\n",
        "    replace_conv_with_ws(model.layer3)\n",
        "    replace_conv_with_ws(model.layer4)\n",
        "\n",
        "    for p in model.layer1.parameters(): p.requires_grad = False\n",
        "    for p in model.layer2.parameters(): p.requires_grad = False\n",
        "    for p in model.layer3.parameters(): p.requires_grad = False\n",
        "    for p in model.layer4.parameters(): p.requires_grad = True\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 9) Train/Eval Ìï®Ïàò\n",
        "# =========================================\n",
        "def train_one_epoch(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for x, y in tqdm(loader, desc=\"Train\", leave=False):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()*x.size(0)\n",
        "        correct    += (out.argmax(1)==y).sum().item()\n",
        "        total      += y.size(0)\n",
        "    return total_loss/total, correct/total*100\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for x, y in tqdm(loader, desc=\"Valid\", leave=False):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "\n",
        "        total_loss += loss.item()*x.size(0)\n",
        "        correct    += (out.argmax(1)==y).sum().item()\n",
        "        total      += y.size(0)\n",
        "    return total_loss/total, correct/total*100\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=6, delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best = None\n",
        "        self.count = 0\n",
        "        self.stop = False\n",
        "\n",
        "    def step(self, metric, model, path):\n",
        "        if self.best is None or (self.best - metric) > self.delta:\n",
        "            self.best = metric\n",
        "            self.count = 0\n",
        "            torch.save(model.state_dict(), path)\n",
        "            print(f\"  üî• Best Í∞±Ïã† ‚Üí {metric:.4f}\")\n",
        "        else:\n",
        "            self.count += 1\n",
        "            print(f\"  ‚è≥ EarlyStopping {self.count}/{self.patience}\")\n",
        "            if self.count >= self.patience:\n",
        "                self.stop = True\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# üî• 10) Fold split & Cache build\n",
        "# =========================================\n",
        "folds = list(kfold.split(ALL_DRIVERS))\n",
        "train_idx, val_idx = folds[FOLD_INDEX]\n",
        "\n",
        "train_drivers = [ALL_DRIVERS[i] for i in train_idx]\n",
        "val_drivers   = [ALL_DRIVERS[i] for i in val_idx]\n",
        "\n",
        "print(\"TRAIN:\", len(train_drivers), \" VAL:\", len(val_drivers))\n",
        "\n",
        "build_offline_cache(TRAIN_DIR, driver_df, train_drivers, OFFLINE_CACHE_DIR)\n",
        "build_offline_cache(TRAIN_DIR, driver_df, val_drivers,   OFFLINE_CACHE_DIR)\n",
        "\n",
        "train_ds = DriverDataset(OFFLINE_CACHE_DIR, driver_df, train_drivers, transform=transform_online_train)\n",
        "val_ds   = DriverDataset(OFFLINE_CACHE_DIR, driver_df, val_drivers,   transform=transform_eval)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# üî• 11) Î™®Îç∏ + Optim + Scheduler\n",
        "# =========================================\n",
        "model = build_resnet34_gn_ws_dropout().to(device)\n",
        "\n",
        "optim_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = optim.AdamW(optim_params, lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "warmup_epochs = 3\n",
        "def lr_lambda(epoch):\n",
        "    if epoch < warmup_epochs:\n",
        "        return float(epoch+1)/warmup_epochs\n",
        "    prog = (epoch-warmup_epochs)/(EPOCHS-warmup_epochs)\n",
        "    return 0.5*(1+math.cos(math.pi*prog))\n",
        "\n",
        "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "print(\"Trainable params:\", sum(p.numel() for p in optim_params))\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# üî• 12) ÌïôÏäµ Î£®ÌîÑ\n",
        "# =========================================\n",
        "history = {\"train_loss\":[], \"train_acc\":[], \"val_loss\":[], \"val_acc\":[]}\n",
        "best_model_path = \"/kaggle/working/resnet34_gnws_best.pth\"\n",
        "es = EarlyStopping(patience=PATIENCE)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nüîµ Epoch {epoch+1}/{EPOCHS} | LR={optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    t_loss, t_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
        "    v_loss, v_acc = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    history[\"train_loss\"].append(t_loss)\n",
        "    history[\"train_acc\"].append(t_acc)\n",
        "    history[\"val_loss\"].append(v_loss)\n",
        "    history[\"val_acc\"].append(v_acc)\n",
        "\n",
        "    print(f\"  Train Loss={t_loss:.4f}, Acc={t_acc:.2f}%\")\n",
        "    print(f\"  Val   Loss={v_loss:.4f}, Acc={v_acc:.2f}%\")\n",
        "\n",
        "    es.step(v_loss, model, best_model_path)\n",
        "    if es.stop:\n",
        "        print(\"üõë EarlyStopping Î∞úÎèô\")\n",
        "        break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# üî• 13) ÌÖåÏä§Ìä∏ ÏÑ∏Ìä∏ Ï∂îÎ°† + Ï†úÏ∂ú ÌååÏùº\n",
        "# =========================================\n",
        "best_path = best_model_path\n",
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "test_imgs = sorted(os.listdir(TEST_DIR))\n",
        "\n",
        "class TestSet(Dataset):\n",
        "    def __len__(self): return len(test_imgs)\n",
        "    def __getitem__(self, i):\n",
        "        p = os.path.join(TEST_DIR, test_imgs[i])\n",
        "        with Image.open(p) as im:\n",
        "            im = im.convert(\"RGB\")\n",
        "            im = transform_eval(im)\n",
        "        return im, test_imgs[i]\n",
        "\n",
        "test_loader = DataLoader(TestSet(), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "preds, names = [], []\n",
        "with torch.no_grad():\n",
        "    for x, fn in tqdm(test_loader, desc=\"Predict\"):\n",
        "        x = x.to(device)\n",
        "        out = model(x)\n",
        "        prob = torch.softmax(out, dim=1).cpu().numpy()\n",
        "        preds.append(prob)\n",
        "        names += fn\n",
        "\n",
        "preds = np.vstack(preds)\n",
        "df = pd.DataFrame(preds, columns=[f\"c{i}\" for i in range(NUM_CLASSES)])\n",
        "df.insert(0, \"img\", names)\n",
        "\n",
        "SUBMIT_PATH = \"/kaggle/working/submission.csv\"\n",
        "df.to_csv(SUBMIT_PATH, index=False)\n",
        "\n",
        "print(\"Ï†ÄÏû• ÏôÑÎ£å:\", SUBMIT_PATH)\n",
        "df.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-16T06:35:44.788356Z",
          "iopub.execute_input": "2025-11-16T06:35:44.78896Z",
          "iopub.status.idle": "2025-11-16T07:13:56.988263Z",
          "shell.execute_reply.started": "2025-11-16T06:35:44.788939Z",
          "shell.execute_reply": "2025-11-16T07:13:56.987486Z"
        },
        "id": "tehLCDd3i_j4",
        "outputId": "1c1878c9-73d9-4b48-f4c4-d84708aec5bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üìÅ BASE_DIR: /kaggle/input/state-farm-distracted-driver-detection\nüìÑ driver_imgs_list.csv: True\nüìÅ Train: True\nüìÅ Test : True\nDEVICE: cuda\nTRAIN: 21  VAL: 5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "OFFLINE caching: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18418/18418 [04:52<00:00, 63.02it/s]\nOFFLINE caching: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4006/4006 [01:01<00:00, 65.35it/s]\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83.3M/83.3M [00:00<00:00, 165MB/s] \n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Trainable params: 13129034\n\nüîµ Epoch 1/40 | LR=0.000017\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  Train Loss=1.3074, Acc=60.44%\n  Val   Loss=1.1638, Acc=63.35%\n  üî• Best Í∞±Ïã† ‚Üí 1.1638\n\nüîµ Epoch 2/40 | LR=0.000033\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  Train Loss=0.3264, Acc=91.58%\n  Val   Loss=0.8970, Acc=74.69%\n  üî• Best Í∞±Ïã† ‚Üí 0.8970\n\nüîµ Epoch 3/40 | LR=0.000050\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  Train Loss=0.1607, Acc=95.78%\n  Val   Loss=0.8001, Acc=76.54%\n  üî• Best Í∞±Ïã† ‚Üí 0.8001\n\nüîµ Epoch 4/40 | LR=0.000050\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  Train Loss=0.0921, Acc=97.57%\n  Val   Loss=1.0837, Acc=72.09%\n  ‚è≥ EarlyStopping 1/6\n\nüîµ Epoch 5/40 | LR=0.000050\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  Train Loss=0.0716, Acc=97.87%\n  Val   Loss=1.1402, Acc=72.27%\n  ‚è≥ EarlyStopping 2/6\n\nüîµ Epoch 6/40 | LR=0.000050\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  Train Loss=0.0513, Acc=98.53%\n  Val   Loss=1.1024, Acc=74.41%\n  ‚è≥ EarlyStopping 3/6\n\nüîµ Epoch 7/40 | LR=0.000049\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  Train Loss=0.0481, Acc=98.67%\n  Val   Loss=0.9796, Acc=76.88%\n  ‚è≥ EarlyStopping 4/6\n\nüîµ Epoch 8/40 | LR=0.000049\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  Train Loss=0.0395, Acc=98.85%\n  Val   Loss=1.0303, Acc=73.79%\n  ‚è≥ EarlyStopping 5/6\n\nüîµ Epoch 9/40 | LR=0.000048\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                        \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  Train Loss=0.0355, Acc=98.93%\n  Val   Loss=1.1049, Acc=74.91%\n  ‚è≥ EarlyStopping 6/6\nüõë EarlyStopping Î∞úÎèô\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Predict: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1246/1246 [18:51<00:00,  1.10it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Ï†ÄÏû• ÏôÑÎ£å: /kaggle/working/submission.csv\n",
          "output_type": "stream"
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "              img        c0        c1        c2        c3        c4        c5  \\\n0       img_1.jpg  0.002757  0.847939  0.014127  0.036086  0.001014  0.037280   \n1      img_10.jpg  0.002469  0.001174  0.000045  0.000817  0.001270  0.989551   \n2     img_100.jpg  0.789620  0.015487  0.068741  0.004313  0.000458  0.028160   \n3    img_1000.jpg  0.001085  0.014567  0.971250  0.000048  0.000072  0.001027   \n4  img_100000.jpg  0.010779  0.005759  0.000138  0.133363  0.001521  0.836966   \n\n         c6        c7        c8        c9  \n0  0.001430  0.050067  0.006261  0.003039  \n1  0.002906  0.000682  0.000618  0.000469  \n2  0.005918  0.012718  0.034943  0.039641  \n3  0.001597  0.000172  0.009776  0.000407  \n4  0.001114  0.000602  0.005989  0.003770  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img</th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n      <th>c4</th>\n      <th>c5</th>\n      <th>c6</th>\n      <th>c7</th>\n      <th>c8</th>\n      <th>c9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_1.jpg</td>\n      <td>0.002757</td>\n      <td>0.847939</td>\n      <td>0.014127</td>\n      <td>0.036086</td>\n      <td>0.001014</td>\n      <td>0.037280</td>\n      <td>0.001430</td>\n      <td>0.050067</td>\n      <td>0.006261</td>\n      <td>0.003039</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_10.jpg</td>\n      <td>0.002469</td>\n      <td>0.001174</td>\n      <td>0.000045</td>\n      <td>0.000817</td>\n      <td>0.001270</td>\n      <td>0.989551</td>\n      <td>0.002906</td>\n      <td>0.000682</td>\n      <td>0.000618</td>\n      <td>0.000469</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_100.jpg</td>\n      <td>0.789620</td>\n      <td>0.015487</td>\n      <td>0.068741</td>\n      <td>0.004313</td>\n      <td>0.000458</td>\n      <td>0.028160</td>\n      <td>0.005918</td>\n      <td>0.012718</td>\n      <td>0.034943</td>\n      <td>0.039641</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_1000.jpg</td>\n      <td>0.001085</td>\n      <td>0.014567</td>\n      <td>0.971250</td>\n      <td>0.000048</td>\n      <td>0.000072</td>\n      <td>0.001027</td>\n      <td>0.001597</td>\n      <td>0.000172</td>\n      <td>0.009776</td>\n      <td>0.000407</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_100000.jpg</td>\n      <td>0.010779</td>\n      <td>0.005759</td>\n      <td>0.000138</td>\n      <td>0.133363</td>\n      <td>0.001521</td>\n      <td>0.836966</td>\n      <td>0.001114</td>\n      <td>0.000602</td>\n      <td>0.005989</td>\n      <td>0.003770</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}