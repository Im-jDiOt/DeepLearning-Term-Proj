# ============================================
# 1. Í∏∞Î≥∏ ÏÑ§Ï†ï
# ============================================
import pandas as pd
import numpy as np
from PIL import Image
from tqdm.notebook import tqdm
import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from sklearn.model_selection import GroupKFold
import cv2
import os
from pathlib import Path

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§:", device)


# ============================================
# 2. Í≤ΩÎ°ú ÏÑ§Ï†ï
# ============================================
base_dir = Path("/content")

driver_csv_path = base_dir / "driver_imgs_list.csv"
train_dir = base_dir / "imgs" / "train"
test_dir = base_dir / "imgs" / "test"


# ============================================
# 3. ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞
# ============================================
img_size = 224
batch_size = 32
num_classes = 10
num_epochs = 25
learning_rate = 3e-4
weight_decay = 1e-4
num_workers = 2


# ============================================
# 4. CLAHE Ï†ÅÏö© Ìï®Ïàò
# ============================================
def apply_clahe(pil_img):
    img = np.array(pil_img)
    img = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(img)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    merged = cv2.merge((cl,a,b))
    rgb = cv2.cvtColor(merged, cv2.COLOR_LAB2RGB)
    return Image.fromarray(rgb)


# ============================================
# 5. Dataset Ï†ïÏùò
# ============================================
class DriverDataset(Dataset):
    def __init__(self, img_dir, df, driver_list, transform=None, is_test=False):
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test
        self.images, self.labels = [], []

        if is_test:
            for img_name in sorted(os.listdir(img_dir)):
                self.images.append(os.path.join(img_dir, img_name))

        else:
            subset = df[df['subject'].isin(driver_list)]
            for _, row in subset.iterrows():
                class_name = row['classname']
                img_name = row['img']
                path = os.path.join(img_dir, class_name, img_name)
                self.images.append(path)
                self.labels.append(int(class_name[1:]))

        print(f"{'TEST' if is_test else 'TRAIN'}: {len(self.images)}Í∞ú Ïù¥ÎØ∏ÏßÄ")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        img = Image.open(img_path).convert("RGB")

        # Offline preprocessing
        img = apply_clahe(img)
        img = img.resize((img_size, img_size))

        if self.transform:
            img = self.transform(img)

        if self.is_test:
            return img, os.path.basename(img_path)
        else:
            return img, self.labels[idx]


# ============================================
# 6. Online Transform
# ============================================
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(img_size, scale=(0.85, 1.0)),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.05),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

eval_transform = transforms.Compose([
    transforms.Resize((img_size, img_size)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])


# ============================================
# 7. GroupKFold split
# ============================================
df = pd.read_csv(driver_csv_path)
groups = df['subject']
gkf = GroupKFold(n_splits=5)

folds = list(gkf.split(df, df['classname'], groups))


# ============================================
# 8. Train / Validate Ìï®Ïàò
# ============================================
def train_epoch(model, loader, criterion, optimizer):
    model.train()
    running_loss, correct, total = 0.0, 0, 0

    for x, y in tqdm(loader, desc="TRAIN", leave=False):
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()

        out = model(x)
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * x.size(0)
        correct += (out.argmax(1) == y).sum().item()
        total += y.size(0)

    return running_loss / total, 100 * correct / total


def validate(model, loader, criterion):
    model.eval()
    running_loss, correct, total = 0.0, 0, 0

    with torch.no_grad():
        for x, y in tqdm(loader, desc="VALID", leave=False):
            x, y = x.to(device), y.to(device)

            out = model(x)
            loss = criterion(out, y)

            running_loss += loss.item() * x.size(0)
            correct += (out.argmax(1) == y).sum().item()
            total += y.size(0)

    return running_loss / total, 100 * correct / total


# ============================================
# 9. Fold 1Í∞úÎßå ÌïôÏäµ
# ============================================
fold_idx = 0
train_idx, val_idx = folds[fold_idx]

train_drivers = df.iloc[train_idx]['subject'].unique()
val_drivers   = df.iloc[val_idx]['subject'].unique()

train_dataset = DriverDataset(train_dir, df, train_drivers, transform=train_transform)
val_dataset   = DriverDataset(train_dir, df, val_drivers, transform=eval_transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)


# ============================================
# 10. ResNet50 Î™®Îç∏ Ï§ÄÎπÑ
# ============================================
model = models.resnet50(weights="IMAGENET1K_V1")
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss(label_smoothing=0.05)
optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)

best_val_loss = 1e9
best_path = f"best_resnet50_fold{fold_idx}.pth"


# ============================================
# 11. Training Loop
# ============================================
for epoch in range(num_epochs):
    print(f"\nEpoch {epoch+1}/{num_epochs}")

    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)
    val_loss, val_acc = validate(model, val_loader, criterion)

    scheduler.step()

    print(f"Train Loss {train_loss:.4f} | Acc {train_acc:.2f}%")
    print(f"Val   Loss {val_loss:.4f} | Acc {val_acc:.2f}%")

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), best_path)
        print(f"üî• Best model updated: {best_path}")


# ============================================
# 12. ÌÖåÏä§Ìä∏ÏÖã ÏòàÏ∏° ‚Üí Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ±
# ============================================
print("\nüì¶ ÌÖåÏä§Ìä∏ÏÖã ÏòàÏ∏° ÏãúÏûë‚Ä¶")

model.load_state_dict(torch.load(best_path, map_location=device))
model.eval()

test_dataset = DriverDataset(test_dir, None, None, transform=eval_transform, is_test=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

all_probs = []
all_imgs  = []

with torch.no_grad():
    for imgs, names in tqdm(test_loader, desc="PREDICT"):
        imgs = imgs.to(device)
        out = model(imgs)
        probs = torch.softmax(out, dim=1).cpu().numpy()

        all_probs.append(probs)
        all_imgs.extend(names)

all_probs = np.vstack(all_probs)

submission = pd.DataFrame({
    'img': all_imgs,
    **{f'c{i}': all_probs[:, i] for i in range(10)}
})

sub_path = f"submission_resnet50_fold{fold_idx}.csv"
submission.to_csv(sub_path, index=False)

print(f"\n‚úÖ ÏµúÏ¢Ö Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ± ÏôÑÎ£å: {sub_path}")
print(submission.head())
