# ì œì¼ ì„±ëŠ¥ ì¢‹ì€ ì½”ë“œ ê¸°ë°˜
# clahe ì ìš© ì•ˆí•˜ê³ , resnet50 ëª¨ë¸ ì‚¬ìš©
# epoch 50ìœ¼ë¡œ ì¦ê°€ & early stopping (patience = 5)
# driver p081 ì œì™¸ 

# ============================================
# 1. ê¸°ë³¸ ì„¤ì •
# ============================================
import pandas as pd
import numpy as np
from PIL import Image
from tqdm.notebook import tqdm
import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from sklearn.model_selection import GroupKFold
import cv2
import os
from pathlib import Path

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("ì‚¬ìš© ë””ë°”ì´ìŠ¤:", device)


# ============================================
# 2. ê²½ë¡œ ì„¤ì •
# ============================================
train_dir = "/kaggle/input/state-farm-distracted-driver-detection/imgs/train"
test_dir = "/kaggle/input/state-farm-distracted-driver-detection/imgs/test"
driver_csv_path = "/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv"


# ============================================
# 3. í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ============================================
img_size = 224
batch_size = 32
num_classes = 10
num_epochs = 50
patience = 10
early_stop_counter = 0
learning_rate = 3e-4
weight_decay = 1e-4
num_workers = 2


# ============================================
# 4. CLAHE ì ìš© í•¨ìˆ˜
# ============================================
def apply_clahe(pil_img):
    img = np.array(pil_img)
    img = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(img)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    merged = cv2.merge((cl,a,b))
    rgb = cv2.cvtColor(merged, cv2.COLOR_LAB2RGB)
    return Image.fromarray(rgb)


# ============================================
# 5. Dataset ì •ì˜
# ============================================
class DriverDataset(Dataset):
    def __init__(self, img_dir, df, driver_list, transform=None, is_test=False):
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test
        self.images, self.labels = [], []

        if is_test:
            for img_name in sorted(os.listdir(img_dir)):
                self.images.append(os.path.join(img_dir, img_name))

        else:
            subset = df[df['subject'].isin(driver_list)]
            for _, row in subset.iterrows():
                class_name = row['classname']
                img_name = row['img']
                path = os.path.join(img_dir, class_name, img_name)
                self.images.append(path)
                self.labels.append(int(class_name[1:]))

        print(f"{'TEST' if is_test else 'TRAIN'}: {len(self.images)}ê°œ ì´ë¯¸ì§€")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        img = Image.open(img_path).convert("RGB")

        # Offline preprocessing
        #img = apply_clahe(img)
        img = img.resize((img_size, img_size))

        if self.transform:
            img = self.transform(img)

        if self.is_test:
            return img, os.path.basename(img_path)
        else:
            return img, self.labels[idx]


# ============================================
# 6. Online Transform
# ============================================
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(img_size, scale=(0.85, 1.0)),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.05),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

eval_transform = transforms.Compose([
    transforms.Resize((img_size, img_size)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])


# ============================================
# 7. GroupKFold split (p081 ì œê±° ë°˜ì˜)
# ============================================
driver_df = pd.read_csv(driver_csv_path)

# p081 ì œì™¸
driver_df = driver_df[driver_df['subject'] != 'p081'].reset_index(drop=True)
print("Unique drivers:", driver_df['subject'].nunique())

groups = driver_df['subject']
gkf = GroupKFold(n_splits=5)
folds = list(gkf.split(driver_df, driver_df['classname'], groups))



# ============================================
# 8. Train / Validate í•¨ìˆ˜
# ============================================
def train_epoch(model, loader, criterion, optimizer):
    model.train()
    running_loss, correct, total = 0.0, 0, 0

    for x, y in tqdm(loader, desc="TRAIN", leave=False):
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()

        out = model(x)
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * x.size(0)
        correct += (out.argmax(1) == y).sum().item()
        total += y.size(0)

    return running_loss / total, 100 * correct / total


def validate(model, loader, criterion):
    model.eval()
    running_loss, correct, total = 0.0, 0, 0

    with torch.no_grad():
        for x, y in tqdm(loader, desc="VALID", leave=False):
            x, y = x.to(device), y.to(device)

            out = model(x)
            loss = criterion(out, y)

            running_loss += loss.item() * x.size(0)
            correct += (out.argmax(1) == y).sum().item()
            total += y.size(0)

    return running_loss / total, 100 * correct / total


# ============================================
# 9. Fold 1ê°œë§Œ í•™ìŠµ
# ============================================
fold_idx = 0
train_idx, val_idx = folds[fold_idx]

train_drivers = driver_df.iloc[train_idx]['subject'].unique()
val_drivers   = driver_df.iloc[val_idx]['subject'].unique()

train_dataset = DriverDataset(train_dir, driver_df, train_drivers, transform=train_transform)
val_dataset   = DriverDataset(train_dir, driver_df, val_drivers, transform=eval_transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)


# ============================================
# 10. ResNet34 ëª¨ë¸ ì¤€ë¹„
# ============================================
model = models.resnet34(weights="IMAGENET1K_V1")
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss(label_smoothing=0.05)
optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)

best_val_loss = 1e9
best_path = f"best_resnet50_fold{fold_idx}.pth"


# ============================================
# 11. Training Loop
# ============================================
for epoch in range(num_epochs):
    print(f"\nEpoch {epoch+1}/{num_epochs}")

    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)
    val_loss, val_acc = validate(model, val_loader, criterion)

    scheduler.step()

    print(f"Train Loss {train_loss:.4f} | Acc {train_acc:.2f}%")
    print(f"Val   Loss {val_loss:.4f} | Acc {val_acc:.2f}%")

    # Best ëª¨ë¸ ê°±ì‹ 
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), best_path)
        print(f"ğŸ”¥ Best model updated: {best_path}")
        early_stop_counter = 0
    else:
        early_stop_counter += 1
        print(f"âš ï¸ EarlyStop counter: {early_stop_counter}/{patience}")

        if early_stop_counter >= patience:
            print("ğŸ›‘ Early Stopping ë°œë™")
            break


# ============================================
# 12. í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ â†’ ì œì¶œ íŒŒì¼ ìƒì„±
# ============================================
print("\nğŸ“¦ í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ ì‹œì‘â€¦")

model.load_state_dict(torch.load(best_path, map_location=device))
model.eval()

test_dataset = DriverDataset(test_dir, None, None, transform=eval_transform, is_test=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

all_probs = []
all_imgs  = []

with torch.no_grad():
    for imgs, names in tqdm(test_loader, desc="PREDICT"):
        imgs = imgs.to(device)
        out = model(imgs)
        probs = torch.softmax(out, dim=1).cpu().numpy()

        all_probs.append(probs)
        all_imgs.extend(names)

all_probs = np.vstack(all_probs)

submission = pd.DataFrame({
    'img': all_imgs,
    **{f'c{i}': all_probs[:, i] for i in range(10)}
})

sub_path = f"submission_resnet50_epoch50_p081X.csv"
submission.to_csv(sub_path, index=False)

print(f"\nâœ… ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {sub_path}")
print(submission.head())
