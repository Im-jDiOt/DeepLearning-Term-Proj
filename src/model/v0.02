# ============================================
# 1. Í∏∞Î≥∏ ÏÑ§Ï†ï
# ============================================
import pandas as pd
import numpy as np
from PIL import Image
from tqdm.notebook import tqdm
import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from sklearn.model_selection import GroupKFold
import cv2
import os
from pathlib import Path

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§:", device)

import albumentations as A
from albumentations.pytorch import ToTensorV2


# ============================================
# 2. Í≤ΩÎ°ú ÏÑ§Ï†ï
# ============================================
train_dir = "/kaggle/input/state-farm-distracted-driver-detection/imgs/train"
test_dir = "/kaggle/input/state-farm-distracted-driver-detection/imgs/test"
driver_csv_path = "/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv"

# ============================================
# 3. ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞
# ============================================
img_size = 224
batch_size = 32
num_classes = 10
num_epochs = 15
learning_rate = 3e-4
weight_decay = 1e-4
num_workers = 2


# ============================================
# 4. Dataset Ï†ïÏùò (Albumentations Ï†ÅÏö©)
# ============================================
class DriverDataset(Dataset):
    def __init__(self, img_dir, df, driver_list, transform=None, is_test=False):
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test
        self.images, self.labels = [], []

        if is_test:
            for img_name in sorted(os.listdir(img_dir)):
                self.images.append(os.path.join(img_dir, img_name))

        else:
            subset = df[df['subject'].isin(driver_list)]
            for _, row in subset.iterrows():
                class_name = row['classname']
                img_name = row['img']
                path = os.path.join(img_dir, class_name, img_name)
                self.images.append(path)
                self.labels.append(int(class_name[1:]))

        print(f"{'TEST' if is_test else 'TRAIN'}: {len(self.images)}Í∞ú Ïù¥ÎØ∏ÏßÄ")

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]

        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        img = cv2.resize(img, (img_size, img_size))

        if self.transform:
            img = self.transform(image=img)["image"]

        if self.is_test:
            return img, os.path.basename(img_path)
        else:
            return img, self.labels[idx]


# ============================================
# 5. Albumentations Transform
# ============================================
train_transform = A.Compose([
    A.RandomScale(scale_limit=(-0.3, 0.0), p=1.0),  # 70~100% ÌÅ¨Í∏∞
    A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=cv2.BORDER_CONSTANT),
    A.RandomCrop(height=img_size, width=img_size, p=1.0),

    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.5),
    A.RandomGamma(p=0.4),
    A.GaussianBlur(blur_limit=(3, 5), p=0.2),
    A.HueSaturationValue(p=0.3),

    A.Normalize(mean=(0.485,0.456,0.406),
                std=(0.229,0.224,0.225)),
    ToTensorV2()
])

eval_transform = A.Compose([
    A.Resize(img_size, img_size),
    A.Normalize(mean=(0.485,0.456,0.406),
                std=(0.229,0.224,0.225)),
    ToTensorV2()
])


# ============================================
# 6. GroupKFold split
# ============================================
df = pd.read_csv(driver_csv_path)
groups = df['subject']
gkf = GroupKFold(n_splits=5)
folds = list(gkf.split(df, df['classname'], groups))


# ============================================
# 7. Train / Validate
# ============================================
def train_epoch(model, loader, criterion, optimizer):
    model.train()
    running_loss, correct, total = 0.0, 0, 0

    for x, y in tqdm(loader, desc="TRAIN", leave=False):
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()

        out = model(x)
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * x.size(0)
        correct += (out.argmax(1) == y).sum().item()
        total += y.size(0)

    return running_loss / total, 100 * correct / total


def validate(model, loader, criterion):
    model.eval()
    running_loss, correct, total = 0.0, 0, 0

    with torch.no_grad():
        for x, y in tqdm(loader, desc="VALID", leave=False):
            x, y = x.to(device), y.to(device)

            out = model(x)
            loss = criterion(out, y)

            running_loss += loss.item() * x.size(0)
            correct += (out.argmax(1) == y).sum().item()
            total += y.size(0)

    return running_loss / total, 100 * correct / total


# ============================================
# 8. Warmup + CosineAnnealing
# ============================================
class WarmupCosineLR(torch.optim.lr_scheduler._LRScheduler):
    def __init__(self, optimizer, warmup_epochs, max_epochs, last_epoch=-1):
        self.warmup_epochs = warmup_epochs
        self.max_epochs = max_epochs
        super().__init__(optimizer, last_epoch)

    def get_lr(self):
        if self.last_epoch < self.warmup_epochs:
            return [base_lr * (self.last_epoch + 1) / self.warmup_epochs
                    for base_lr in self.base_lrs]

        cos_epoch = self.last_epoch - self.warmup_epochs
        total_cos = self.max_epochs - self.warmup_epochs

        return [
            base_lr * 0.5 * (1 + np.cos(np.pi * cos_epoch / total_cos))
            for base_lr in self.base_lrs
        ]


# ============================================
# 9. Fold ÌïôÏäµ
# ============================================
fold_idx = 0
train_idx, val_idx = folds[fold_idx]

train_drivers = df.iloc[train_idx]['subject'].unique()
val_drivers   = df.iloc[val_idx]['subject'].unique()

train_dataset = DriverDataset(train_dir, df, train_drivers, transform=train_transform)
val_dataset   = DriverDataset(train_dir, df, val_drivers, transform=eval_transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)


# ============================================
# 10. ResNet34 Î™®Îç∏
# ============================================
model = models.resnet50(weights="IMAGENET1K_V1")
model.fc = nn.Linear(model.fc.in_features, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
scheduler = WarmupCosineLR(optimizer, warmup_epochs=3, max_epochs=num_epochs)

best_val_loss = 1e9
best_path = f"best_resnet34_fold{fold_idx}.pth"


# ============================================
# 11. Training Loop
# ============================================
for epoch in range(num_epochs):
    print(f"\nEpoch {epoch+1}/{num_epochs}")

    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)
    val_loss, val_acc = validate(model, val_loader, criterion)

    scheduler.step()

    print(f"Train Loss {train_loss:.4f} | Acc {train_acc:.2f}%")
    print(f"Val   Loss {val_loss:.4f} | Acc {val_acc:.2f}%")

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), best_path)
        print(f"üî• Best model updated: {best_path}")


# ============================================
# 12. ÌÖåÏä§Ìä∏ÏÖã ÏòàÏ∏°
# ============================================
model.load_state_dict(torch.load(best_path, map_location=device))
model.eval()

test_dataset = DriverDataset(test_dir, None, None, transform=eval_transform, is_test=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

all_probs = []
all_imgs = []

with torch.no_grad():
    for imgs, names in tqdm(test_loader, desc="PREDICT"):
        imgs = imgs.to(device)
        out = model(imgs)
        probs = torch.softmax(out, dim=1).cpu().numpy()

        all_probs.append(probs)
        all_imgs.extend(names)

all_probs = np.vstack(all_probs)

submission = pd.DataFrame({
    'img': all_imgs,
    **{f'c{i}': all_probs[:, i] for i in range(10)}
})

sub_path = f"submission_resnet50_fold{fold_idx}.csv"
submission.to_csv(sub_path, index=False)

print("\nDONE:", sub_path)
