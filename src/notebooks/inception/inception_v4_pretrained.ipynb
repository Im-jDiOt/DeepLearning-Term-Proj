{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42258a5e",
   "metadata": {},
   "source": [
    "# Inception V4 Pretrained Model (timm)\n",
    "\n",
    "`timm` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ImageNetìœ¼ë¡œ pretrainëœ ìˆœìˆ˜ Inception V4 ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ìš´ì „ì í–‰ë™ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70a5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.3-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached numpy-2.3.4-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ---------------------------------------- 4/4 [pandas]\n",
      "\n",
      "Successfully installed numpy-2.3.4 pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661b87ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Using cached timm-1.0.22-py3-none-any.whl.metadata (63 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting pillow\n",
      "  Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting torch (from timm)\n",
      "  Using cached torch-2.9.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision (from timm)\n",
      "  Using cached torchvision-0.24.0-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting pyyaml (from timm)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Using cached huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.16.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting filelock (from huggingface_hub->timm)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub->timm)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from huggingface_hub->timm)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting shellingham (from huggingface_hub->timm)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface_hub->timm)\n",
      "  Using cached typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub->timm)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface_hub->timm)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting sympy>=1.13.3 (from torch->timm)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch->timm)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch->timm)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting setuptools (from torch->timm)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->timm)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->timm)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface_hub->timm)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached timm-1.0.22-py3-none-any.whl (2.5 MB)\n",
      "Using cached matplotlib-3.10.7-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.1-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached scipy-1.16.3-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached huggingface_hub-1.0.1-py3-none-any.whl (503 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached torch-2.9.0-cp312-cp312-win_amd64.whl (109.3 MB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached torchvision-0.24.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Using cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, tqdm, threadpoolctl, sympy, sniffio, shellingham, setuptools, scipy, safetensors, pyyaml, pyparsing, pillow, networkx, MarkupSafe, kiwisolver, joblib, idna, hf-xet, h11, fsspec, fonttools, filelock, cycler, contourpy, click, certifi, typer-slim, scikit-learn, matplotlib, jinja2, httpcore, anyio, torch, httpx, torchvision, huggingface_hub, timm\n",
      "\n",
      "   ----------------------------------------  0/38 [mpmath]\n",
      "   - --------------------------------------  1/38 [typing-extensions]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ---- -----------------------------------  4/38 [sympy]\n",
      "   ------- --------------------------------  7/38 [setuptools]\n",
      "   ------- --------------------------------  7/38 [setuptools]\n",
      "   ------- --------------------------------  7/38 [setuptools]\n",
      "   ------- --------------------------------  7/38 [setuptools]\n",
      "   ------- --------------------------------  7/38 [setuptools]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   -------- -------------------------------  8/38 [scipy]\n",
      "   ------------ --------------------------- 12/38 [pillow]\n",
      "   ------------ --------------------------- 12/38 [pillow]\n",
      "   ------------- -------------------------- 13/38 [networkx]\n",
      "   ------------- -------------------------- 13/38 [networkx]\n",
      "   ------------- -------------------------- 13/38 [networkx]\n",
      "   ------------- -------------------------- 13/38 [networkx]\n",
      "   ------------- -------------------------- 13/38 [networkx]\n",
      "   ------------- -------------------------- 13/38 [networkx]\n",
      "   ------------- -------------------------- 13/38 [networkx]\n",
      "   ------------- -------------------------- 13/38 [networkx]\n",
      "   -------------- ------------------------- 14/38 [MarkupSafe]\n",
      "   ---------------- ----------------------- 16/38 [joblib]\n",
      "   ------------------ --------------------- 18/38 [hf-xet]\n",
      "   --------------------- ------------------ 20/38 [fsspec]\n",
      "   ---------------------- ----------------- 21/38 [fonttools]\n",
      "   ---------------------- ----------------- 21/38 [fonttools]\n",
      "   ---------------------- ----------------- 21/38 [fonttools]\n",
      "   ---------------------- ----------------- 21/38 [fonttools]\n",
      "   ---------------------- ----------------- 21/38 [fonttools]\n",
      "   -------------------------- ------------- 25/38 [click]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ----------------------------- ---------- 28/38 [scikit-learn]\n",
      "   ------------------------------ --------- 29/38 [matplotlib]\n",
      "   ------------------------------ --------- 29/38 [matplotlib]\n",
      "   ------------------------------ --------- 29/38 [matplotlib]\n",
      "   ------------------------------ --------- 29/38 [matplotlib]\n",
      "   ------------------------------ --------- 29/38 [matplotlib]\n",
      "   ------------------------------ --------- 29/38 [matplotlib]\n",
      "   ------------------------------ --------- 29/38 [matplotlib]\n",
      "   ------------------------------ --------- 29/38 [matplotlib]\n",
      "   ------------------------------ --------- 29/38 [matplotlib]\n",
      "   ------------------------------ --------- 29/38 [matplotlib]\n",
      "   ------------------------------- -------- 30/38 [jinja2]\n",
      "   --------------------------------- ------ 32/38 [anyio]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ---------------------------------- ----- 33/38 [torch]\n",
      "   ------------------------------------ --- 35/38 [torchvision]\n",
      "   ------------------------------------ --- 35/38 [torchvision]\n",
      "   ------------------------------------ --- 35/38 [torchvision]\n",
      "   ------------------------------------ --- 35/38 [torchvision]\n",
      "   ------------------------------------- -- 36/38 [huggingface_hub]\n",
      "   -------------------------------------- - 37/38 [timm]\n",
      "   -------------------------------------- - 37/38 [timm]\n",
      "   -------------------------------------- - 37/38 [timm]\n",
      "   -------------------------------------- - 37/38 [timm]\n",
      "   -------------------------------------- - 37/38 [timm]\n",
      "   ---------------------------------------- 38/38 [timm]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 anyio-4.11.0 certifi-2025.10.5 click-8.3.0 contourpy-1.3.3 cycler-0.12.1 filelock-3.20.0 fonttools-4.60.1 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface_hub-1.0.1 idna-3.11 jinja2-3.1.6 joblib-1.5.2 kiwisolver-1.4.9 matplotlib-3.10.7 mpmath-1.3.0 networkx-3.5 pillow-12.0.0 pyparsing-3.2.5 pyyaml-6.0.3 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.3 setuptools-80.9.0 shellingham-1.5.4 sniffio-1.3.1 sympy-1.14.0 threadpoolctl-3.6.0 timm-1.0.22 torch-2.9.0 torchvision-0.24.0 tqdm-4.67.1 typer-slim-0.20.0 typing-extensions-4.15.0\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install timm matplotlib pillow tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad73ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
      "Requirement already satisfied: torch in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from torchvision) (2.3.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\pycharmprojects\\deeplearning-term-proj\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60825b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m.cuda.is_available()\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e94e940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ë””ë°”ì´ìŠ¤: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0284e790",
   "metadata": {},
   "source": [
    "## GPU í™˜ê²½ ì§„ë‹¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707366a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ\n",
    "base_dir = r'c:\\Users\\USER\\PycharmProjects\\DeepLearning-Term-Proj'\n",
    "train_dir = os.path.join(base_dir, 'data', 'imgs', 'train')\n",
    "test_dir = os.path.join(base_dir, 'data', 'imgs', 'test')\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "img_size = 299  # Inception V4 ì…ë ¥ í¬ê¸°\n",
    "batch_size = 32\n",
    "num_classes = 10  # c0 ~ c9\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "num_workers = 0\n",
    "\n",
    "print(f\"Train directory: {train_dir}\")\n",
    "print(f\"Test directory: {test_dir}\")\n",
    "print(f\"ì´ë¯¸ì§€ í¬ê¸°: {img_size}x{img_size}\")\n",
    "print(f\"ë°°ì¹˜ í¬ê¸°: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriverDataset(Dataset):\n",
    "    \"\"\"ìš´ì „ì í–‰ë™ ë°ì´í„°ì…‹\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, transform=None, is_test=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        if is_test:\n",
    "            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” test í´ë” ì§ì ‘ ì‚¬ìš©\n",
    "            test_images_dir = os.path.join(data_dir, 'test')\n",
    "            if os.path.exists(test_images_dir):\n",
    "                for img_name in os.listdir(test_images_dir):\n",
    "                    if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                        self.images.append(os.path.join(test_images_dir, img_name))\n",
    "            else:\n",
    "                # test í´ë”ê°€ ì—†ìœ¼ë©´ ìƒìœ„ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "                for img_name in os.listdir(data_dir):\n",
    "                    if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                        self.images.append(os.path.join(data_dir, img_name))\n",
    "        else:\n",
    "            # í•™ìŠµ ë°ì´í„°ëŠ” c0~c9 í´ë”ì—ì„œ ë¡œë“œ\n",
    "            for class_idx in range(10):\n",
    "                class_name = f'c{class_idx}'\n",
    "                class_path = os.path.join(data_dir, class_name)\n",
    "                \n",
    "                if not os.path.exists(class_path):\n",
    "                    print(f\"ê²½ê³ : {class_path} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                    continue\n",
    "                \n",
    "                for img_name in os.listdir(class_path):\n",
    "                    if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                        img_path = os.path.join(class_path, img_name)\n",
    "                        self.images.append(img_path)\n",
    "                        self.labels.append(class_idx)\n",
    "        \n",
    "        print(f\"{'í…ŒìŠ¤íŠ¸' if is_test else 'í•™ìŠµ'} ë°ì´í„°: {len(self.images)}ê°œ ì´ë¯¸ì§€\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image, os.path.basename(img_path)\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de85129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline w/o data augmentation ver.\n",
    "# ë°ì´í„° ì¦ê°• - í•™ìŠµìš©\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomRotation(15),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet ì •ê·œí™” -> ì¶”í›„ ìš°ë¦¬ ë°ì´í„°ì…‹ìœ¼ë¡œ ì •ê·œí™” ì§„í–‰ ì˜ˆì •\n",
    "])\n",
    "\n",
    "# ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© (ì¦ê°• ì—†ìŒ)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"ë°ì´í„° ë³€í™˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb6b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ í•™ìŠµ ë°ì´í„° ë¡œë“œ\n",
    "full_dataset = DriverDataset(train_dir, transform=train_transform, is_test=False)\n",
    "\n",
    "# í•™ìŠµ/ê²€ì¦ ë¶„í•  (80% í•™ìŠµ, 20% ê²€ì¦)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ëŠ” ì¦ê°• ì—†ì´ ì‚¬ìš©í•˜ê¸° ìœ„í•´ transform ë³€ê²½\n",
    "val_dataset.dataset = DriverDataset(train_dir, transform=val_transform, is_test=False)\n",
    "val_indices = val_dataset.indices\n",
    "val_dataset = torch.utils.data.Subset(val_dataset.dataset, val_indices)\n",
    "\n",
    "# ë°ì´í„° ë¡œë”\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=0,  # Windowsì—ì„œëŠ” 0 ê¶Œì¥\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"í•™ìŠµ ìƒ˜í”Œ: {len(train_dataset)}ê°œ\")\n",
    "print(f\"ê²€ì¦ ìƒ˜í”Œ: {len(val_dataset)}ê°œ\")\n",
    "print(f\"í•™ìŠµ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
    "print(f\"ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "298b076b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ê°€ëŠ¥í•œ Inception V4 ëª¨ë¸:\n",
      "  - inception_v4.tf_in1k\n"
     ]
    }
   ],
   "source": [
    "# timmì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ Inception V4 ëª¨ë¸ í™•ì¸\n",
    "print(\"ì‚¬ìš© ê°€ëŠ¥í•œ Inception V4 ëª¨ë¸:\")\n",
    "inception_models = timm.list_models('*inception_v4*', pretrained=True)\n",
    "for model_name in inception_models:\n",
    "    print(f\"  - {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ceee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception V4 pretrained ëª¨ë¸ ìƒì„±\n",
    "print(\"\\nInception V4 pretrained ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "model = timm.create_model(\n",
    "    'inception_v4',  # ìˆœìˆ˜ Inception V4 (Inception-ResNet-V2ê°€ ì•„ë‹˜!)\n",
    "    pretrained=True,  # ImageNet pretrained ê°€ì¤‘ì¹˜ ì‚¬ìš©\n",
    "    num_classes=num_classes  # ìš°ë¦¬ ë°ì´í„°ì…‹ì— ë§ê²Œ ì¶œë ¥ ë ˆì´ì–´ ë³€ê²½\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "print(f\"âœ“ Inception V4 ëª¨ë¸ì´ {device}ì— ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ëª¨ë¸ ì •ë³´ ì¶œë ¥\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"ì „ì²´ íŒŒë¼ë¯¸í„°: {num_params:,}\")\n",
    "print(f\"í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {num_trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì†ì‹¤ í•¨ìˆ˜\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ (ì„±ëŠ¥ì´ í–¥ìƒë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµë¥  ê°ì†Œ)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',  # validation accuracyë¥¼ ëª¨ë‹ˆí„°ë§\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"1 ì—í­ í•™ìŠµ\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # í†µê³„\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # ì§„í–‰ë¥  í‘œì‹œ\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100. * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"ê²€ì¦\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation')\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100. * correct / total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"í•™ìŠµ/ê²€ì¦ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69467d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ íˆìŠ¤í† ë¦¬ ì €ì¥\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "best_val_acc = 0.0\n",
    "best_model_path = 'best_inception_v4_model.pth'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"í•™ìŠµ ì‹œì‘: {num_epochs} ì—í­\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "    print('-' * 70)\n",
    "    \n",
    "    # í•™ìŠµ\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # ê²€ì¦\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # íˆìŠ¤í† ë¦¬ ì €ì¥\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f'\\nğŸ“Š Epoch {epoch+1} ê²°ê³¼:')\n",
    "    print(f'  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "    print(f'  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%')\n",
    "    \n",
    "    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "        }, best_model_path)\n",
    "        print(f'  âœ“ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥! (Val Acc: {val_acc:.2f}%)')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.2f}%\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss ê·¸ë˜í”„\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss', marker='o', linewidth=2)\n",
    "plt.plot(history['val_loss'], label='Validation Loss', marker='s', linewidth=2)\n",
    "plt.title('Model Loss', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy ê·¸ë˜í”„\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train Accuracy', marker='o', linewidth=2)\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy', marker='s', linewidth=2)\n",
    "plt.title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"ìµœê³  Train Accuracy: {max(history['train_acc']):.2f}%\")\n",
    "print(f\"ìµœê³  Validation Accuracy: {max(history['val_acc']):.2f}%\")\n",
    "print(f\"ìµœì¢… Train Accuracy: {history['train_acc'][-1]:.2f}%\")\n",
    "print(f\"ìµœì¢… Validation Accuracy: {history['val_acc'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c097ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"âœ“ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Epoch {checkpoint['epoch']+1}, Val Acc: {checkpoint['val_acc']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371a30ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ë¡œë” ìƒì„±\n",
    "test_dataset = DriverDataset(test_dir, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(test_dataset)}ê°œ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°°ì¹˜ ìˆ˜: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66dbc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...\")\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "img_names = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(test_loader, desc='Predicting')\n",
    "    for images, filenames in pbar:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # ì˜ˆì¸¡\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)  # í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜\n",
    "        \n",
    "        predictions.append(probs.cpu().numpy())\n",
    "        img_names.extend(filenames)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ í•©ì¹˜ê¸°\n",
    "predictions = np.vstack(predictions)\n",
    "print(f\"âœ“ ì˜ˆì¸¡ ì™„ë£Œ: {len(img_names)}ê°œ ì´ë¯¸ì§€\")\n",
    "print(f\"ì˜ˆì¸¡ shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cd03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission íŒŒì¼ ìƒì„±\n",
    "submission = pd.DataFrame({\n",
    "    'img': img_names,\n",
    "    'c0': predictions[:, 0],\n",
    "    'c1': predictions[:, 1],\n",
    "    'c2': predictions[:, 2],\n",
    "    'c3': predictions[:, 3],\n",
    "    'c4': predictions[:, 4],\n",
    "    'c5': predictions[:, 5],\n",
    "    'c6': predictions[:, 6],\n",
    "    'c7': predictions[:, 7],\n",
    "    'c8': predictions[:, 8],\n",
    "    'c9': predictions[:, 9]\n",
    "})\n",
    "\n",
    "# CSV íŒŒì¼ ì €ì¥\n",
    "submission_file = 'inception_v4_submission.csv'\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"âœ“ Submission íŒŒì¼ ìƒì„± ì™„ë£Œ: {submission_file}\")\n",
    "print(f\"âœ“ ì´ {len(submission)}ê°œ ì´ë¯¸ì§€ ì˜ˆì¸¡\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ìƒ˜í”Œ ì¶œë ¥\n",
    "print(\"\\nğŸ“‹ Submission íŒŒì¼ ìƒ˜í”Œ:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "# í†µê³„\n",
    "print(\"\\nğŸ“Š ì˜ˆì¸¡ í†µê³„:\")\n",
    "for i in range(10):\n",
    "    col_name = f'c{i}'\n",
    "    print(f\"  {col_name}: mean={submission[col_name].mean():.4f}, \"\n",
    "          f\"std={submission[col_name].std():.4f}, \"\n",
    "          f\"max={submission[col_name].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d3c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ì™€ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\n",
    "def show_predictions(num_samples=8):\n",
    "    \"\"\"ìƒ˜í”Œ ì´ë¯¸ì§€ì™€ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    \n",
    "    # ëœë¤ ìƒ˜í”Œ ì„ íƒ\n",
    "    indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, sample_idx in enumerate(indices):\n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        img_path = test_dataset.images[sample_idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # ì˜ˆì¸¡ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
    "        img_name = os.path.basename(img_path)\n",
    "        pred_idx = img_names.index(img_name)\n",
    "        pred_probs = predictions[pred_idx]\n",
    "        pred_class = np.argmax(pred_probs)\n",
    "        pred_conf = pred_probs[pred_class]\n",
    "        \n",
    "        # ì‹œê°í™”\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(\n",
    "            f'Predicted: c{pred_class}\\nConfidence: {pred_conf:.2%}',\n",
    "            fontsize=10,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(8)\n",
    "print(\"âœ“ ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6086d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ëª¨ë¸ ì €ì¥\n",
    "final_model_path = 'inception_v4_final.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'history': history,\n",
    "    'best_val_acc': best_val_acc,\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"âœ“ ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {final_model_path}\")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ ë°©ë²•\n",
    "print(\"\\nğŸ“Œ ëª¨ë¸ ë¡œë“œ ë°©ë²•:\")\n",
    "print(f\"\"\"\n",
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import timm\n",
    "import torch\n",
    "\n",
    "model = timm.create_model('inception_v4', pretrained=False, num_classes={num_classes})\n",
    "checkpoint = torch.load('{final_model_path}')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc3623",
   "metadata": {},
   "source": [
    "## ì™„ë£Œ! ğŸ‰\n",
    "\n",
    "- âœ… timmì—ì„œ ìˆœìˆ˜ **Inception V4** pretrained ëª¨ë¸ ì‚¬ìš©\n",
    "- âœ… ImageNet ê°€ì¤‘ì¹˜ë¡œ ì „ì´ í•™ìŠµ\n",
    "- âœ… ë°ì´í„° ì¦ê°• ë° í•™ìŠµ/ê²€ì¦ ë¶„í• \n",
    "- âœ… í•™ìŠµ ê²°ê³¼ ì‹œê°í™”\n",
    "- âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "- âœ… **Submission íŒŒì¼ ìƒì„±** (`inception_v4_submission.csv`)\n",
    "- âœ… ëª¨ë¸ ì €ì¥ ë° ë¡œë“œ ë°©ë²•\n",
    "\n",
    "ìƒì„±ëœ íŒŒì¼:\n",
    "- `best_inception_v4_model.pth` - ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "- `inception_v4_final.pth` - ìµœì¢… ëª¨ë¸\n",
    "- `inception_v4_submission.csv` - ì œì¶œ íŒŒì¼\n",
    "- `training_history.png` - í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„\n",
    "- `sample_predictions.png` - ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
