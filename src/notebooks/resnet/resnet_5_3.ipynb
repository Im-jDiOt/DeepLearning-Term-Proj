{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42258a5e",
   "metadata": {},
   "source": [
    "# Resnet 5_2.\n",
    "5_2ì— cleansing dataset(p81)ì„ ì§€ì›Œë³´ì.. ë‚˜ë¨¸ì§€ëŠ” ë™ì¼í•˜ê²Œ  \n",
    "ìŒ color jitterë§Œ ì¶”ê°€.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b5c48",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e94e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b485182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ============================================================\n",
    "# ì¬í˜„ì„± ë³´ì¥ (Reproducibility)\n",
    "# ============================================================\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    \"\"\"ëª¨ë“  ë‚œìˆ˜ ìƒì„±ê¸°ì˜ ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ ì¬í˜„ì„± ë³´ì¥\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # multi-GPU\n",
    "    \n",
    "    # CUDA ê²°ì •ë¡ ì  ë™ì‘ í™œì„±í™”\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # PyTorch ê²°ì •ë¡ ì  ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© (PyTorch 1.8+)\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    \n",
    "    print(f\"âœ… Random Seed ê³ ì • ì™„ë£Œ: {seed}\")\n",
    "    print(f\"   - Python random: {seed}\")\n",
    "    print(f\"   - NumPy: {seed}\")\n",
    "    print(f\"   - PyTorch: {seed}\")\n",
    "    print(f\"   - CUDA: {seed}\")\n",
    "    print(f\"   - cuDNN Deterministic: True\")\n",
    "    print(f\"   - cuDNN Benchmark: False\")\n",
    "    print(f\"   - PyTorch Deterministic Algorithms: True\")\n",
    "\n",
    "# Seed ì ìš©\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import multiprocessing\n",
    "\n",
    "# # Windows í™˜ê²½ì—ì„œ num_workers > 0 ì‚¬ìš©ì„ ìœ„í•œ í•„ìˆ˜ ì„¤ì •\n",
    "# try:\n",
    "#     # 'spawn' ë°©ì‹ì„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì•ˆì „í•œ í”„ë¡œì„¸ìŠ¤ ìƒì„±ì„ ìœ ë„\n",
    "#     torch.multiprocessing.set_start_method('spawn', force=True) \n",
    "#     print(\"PyTorch multiprocessing start method set to 'spawn'.\")\n",
    "# except RuntimeError as e:\n",
    "#     # ì´ë¯¸ ì„¤ì •ëœ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì˜ˆì™¸ ì²˜ë¦¬\n",
    "#     print(f\"Start method already set or error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a066304",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707366a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "img_size = 256\n",
    "batch_size = 48\n",
    "num_classes = 10\n",
    "num_epochs = 50\n",
    "# learning_rate = 0.0003 -> train section\n",
    "num_workers = 0\n",
    "version = \"5_2\"\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ\n",
    "base_dir = r'c:\\Users\\USER\\PycharmProjects\\DeepLearning-Term-Proj'\n",
    "driver_csv_path = os.path.join(base_dir, 'data', 'driver_imgs_list.csv')\n",
    "train_dir = os.path.join(base_dir, 'data', 'imgs', 'train')\n",
    "test_dir = os.path.join(base_dir, 'data', 'imgs', 'test')\n",
    "name = f'resnet_{version}'\n",
    "\n",
    "print(f\"Train directory: {train_dir}\")\n",
    "print(f\"Test directory: {test_dir}\")\n",
    "print(f\"ì´ë¯¸ì§€ í¬ê¸°: {img_size}x{img_size}\")\n",
    "print(f\"ë°°ì¹˜ í¬ê¸°: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_df = pd.read_csv(driver_csv_path)\n",
    "\n",
    "print(f\"ê³ ìœ  ìš´ì „ì ìˆ˜: {driver_df['subject'].nunique()}ëª…\")\n",
    "print(f\"ìš´ì „ì ëª©ë¡: {sorted(driver_df['subject'].unique())}\")\n",
    "\n",
    "# driver_counts = driver_df['subject'].value_counts().sort_index()\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(driver_counts.index.astype(str), driver_counts.values, color='C0', alpha=0.9)\n",
    "# plt.xlabel('Driver')\n",
    "# plt.ylabel('Image Count')\n",
    "# plt.title('Images per Driver')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.grid(axis='y', alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25840507",
   "metadata": {},
   "source": [
    "## data cleansing\n",
    "p81ì´ ì „ë°˜ì ìœ¼ë¡œ c9ì— ëŒ€í•œ ë…¸ì´ì¦ˆë¥¼ ìƒì„±í•¨ì„ í™•ì¸í•¨. (ë‹¤ë¥¸ í´ë˜ìŠ¤ì—ì„œë„ ê³„ì† ì¡°ìˆ˜ì„ì„ ë°”ë¼ë´„!!!!!)\n",
    "ë”°ë¼ì„œ ê·¸ëƒ¥ p81ì€ ì§€ìš°ê¸°ë¡œ ê²°ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_df = driver_df[driver_df['subject'] != 'p081'].reset_index(drop=True)\n",
    "driver_df['subject'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a060b1",
   "metadata": {},
   "source": [
    "## offline prepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def apply_clahe_to_folder(src_root, dst_root, clip=2.0, tile=8, is_test=False):\n",
    "    os.makedirs(dst_root, exist_ok=True)\n",
    "    \n",
    "    if is_test:\n",
    "        process_images(src_root, dst_root, clip, tile, desc=\"Test Images\")\n",
    "        return\n",
    "    \n",
    "    for label in sorted(os.listdir(src_root)):\n",
    "        src_dir = os.path.join(src_root, label)\n",
    "        dst_dir = os.path.join(dst_root, label)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        \n",
    "        process_images(src_dir, dst_dir, clip, tile, desc=f\"Class {label}\")\n",
    "\n",
    "\n",
    "def process_images(src_dir, dst_dir, clip, tile, desc=\"Processing\"):\n",
    "    \"\"\"ê°œë³„ ì´ë¯¸ì§€ì— CLAHE ì ìš©\"\"\"\n",
    "    img_files = [f for f in os.listdir(src_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for img_name in tqdm(sorted(img_files), desc=desc):\n",
    "        src_path = os.path.join(src_dir, img_name)\n",
    "        dst_path = os.path.join(dst_dir, img_name)\n",
    "        \n",
    "        if os.path.exists(dst_path):\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(src_path)\n",
    "        if img is None:\n",
    "            print(f\"âš ï¸ ì½ê¸° ì‹¤íŒ¨: {src_path}\")\n",
    "            continue\n",
    "        \n",
    "        img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(img_lab)\n",
    "        \n",
    "        clahe = cv2.createCLAHE(clipLimit=clip, tileGridSize=(tile, tile))\n",
    "        l_clahe = clahe.apply(l)\n",
    "        \n",
    "        img_clahe = cv2.merge([l_clahe, a, b])\n",
    "        img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_LAB2BGR)\n",
    "        \n",
    "        cv2.imwrite(dst_path, img_clahe)\n",
    "\n",
    "apply_clahe_to_folder(\n",
    "    src_root=os.path.join(base_dir, 'data', 'imgs', 'train'),\n",
    "    dst_root=os.path.join(base_dir, 'data', 'clahe_imgs', 'train'),\n",
    "    clip=2.0,\n",
    "    tile=8\n",
    ")\n",
    "\n",
    "apply_clahe_to_folder(\n",
    "    src_root=os.path.join(base_dir, 'data', 'imgs', 'test'),\n",
    "    dst_root=os.path.join(base_dir, 'data', 'clahe_imgs', 'test'),\n",
    "    clip=2.0,\n",
    "    tile=8,\n",
    "\tis_test = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe_train_dir = os.path.join(base_dir, 'data', 'clahe_imgs', 'train')\n",
    "clahe_test_dir = os.path.join(base_dir, 'data', 'clahe_imgs', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10c8b8",
   "metadata": {},
   "source": [
    "# 5-Fold Cross Validation\n",
    "foldë³„ ìš´ì „ì ëª©ë¡ì„ ë¯¸ë¦¬ ë‚˜ëˆ„ê¸´ í•˜ë˜ ì´ˆê¸° ì‹¤í—˜ ë‹¨ê³„ì—ì„œëŠ” í•œ í´ë“œ(fold 2, í•™ìŠµ ë°ì´í„°ê°€ ê°€ì¥ ë§ì•„ì„œ..)ë§Œ ì‚¬ìš©í•˜ê³  ì´í›„ ë§ˆë¬´ë¦¬ ë‹¨ê³„ì—ì„œ ì „ì²´ í´ë“œ ë‹¤ ëŒë ¤ì„œ ì¼ë°˜í™” ì„±ëŠ¥ ëŒì–´ì˜¬ë¦¬ëŠ” ë°©í–¥ìœ¼ë¡œ ì§„í–‰."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa684f",
   "metadata": {},
   "source": [
    "## split train data into 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7536ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drivers = sorted(driver_df['subject'].unique())\n",
    "\n",
    "n_folds = 5\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_splits = []\n",
    "for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(all_drivers)):\n",
    "\ttrain_drivers = [all_drivers[i] for i in train_indices]\n",
    "\tval_drivers = [all_drivers[i] for i in val_indices]\n",
    "\n",
    "\tfold_splits.append({\n",
    "\t\t'fold': fold_idx+1,\n",
    "\t\t'train_drivers': train_drivers,\n",
    "\t\t'val_drivers': val_drivers\n",
    "\t})\n",
    "\n",
    "\tprint(\"Fold\", fold_idx+1)\n",
    "\tprint(\"train:\", train_drivers, \"val:\", val_drivers)\n",
    "\t\n",
    "\ttrain_imgs = driver_df[driver_df['subject'].isin(train_drivers)]\n",
    "\tval_imgs = driver_df[driver_df['subject'].isin(val_drivers)]\n",
    "\tprint(f\"í•™ìŠµ ì´ë¯¸ì§€: {len(train_imgs)}ê°œ\")\n",
    "\tprint(f\"ê²€ì¦ ì´ë¯¸ì§€: {len(val_imgs)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ddc81",
   "metadata": {},
   "source": [
    "## define DraiverDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriverDataset(Dataset):\n",
    "    \"\"\"ìš´ì „ì í–‰ë™ ë°ì´í„°ì…‹\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, driver_df, driver_list, transform=None, is_test=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        if is_test:\n",
    "            test_images_dir = data_dir\n",
    "            for img_name in os.listdir(test_images_dir):\n",
    "                self.images.append(os.path.join(test_images_dir, img_name))\n",
    "        else: #is_train\n",
    "            driver_subset = driver_df[driver_df['subject'].isin(driver_list)]\n",
    "\n",
    "            for _, row in driver_subset.iterrows():\n",
    "                class_name = row['classname']\n",
    "                img_name = row['img']\n",
    "                img_path = os.path.join(data_dir, class_name, img_name)\n",
    "\n",
    "                self.images.append(img_path)\n",
    "                class_idx = int(class_name[1:])\n",
    "                self.labels.append(class_idx)\n",
    "        print(f\"{'í…ŒìŠ¤íŠ¸' if is_test else 'ìš´ì „ì' + str(len(driver_list))+'ëª…'}, ë°ì´í„° {len(self.images)}ê°œ ì´ë¯¸ì§€\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image, os.path.basename(img_path)\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b8b549",
   "metadata": {},
   "source": [
    "## define online transform\n",
    "ì„œí˜„ë‹˜ ì˜¨ë¼ì¸ ì¦ê°• ì¶”ê°€. clahe ì ìš©í•œ ê±¸ë¡œ ëŒë¦¬ê¸°ì— color jitterë§Œ ì œì™¸í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de85129",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size, scale=(0.85, 1.0)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_eval = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451010f0",
   "metadata": {},
   "source": [
    "## define model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb822b",
   "metadata": {},
   "source": [
    "### define custom resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, log_loss\n",
    "from tqdm import tqdm\n",
    "\n",
    "EMBED_DIM = 512\n",
    "DROPOUT = 0.4\n",
    "DROP_PATH = 0.1\n",
    "EARLY_STOP_PATIENCE = 10 \n",
    "\n",
    "class ResNetDWithHead(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim=512, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            'resnet50d',\n",
    "            pretrained=True,\n",
    "            num_classes=0,\n",
    "            global_pool='',\n",
    "            drop_path_rate=DROP_PATH,\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        in_ch = self.backbone.num_features\n",
    "\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, in_ch, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(in_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Flatten(1),\n",
    "            nn.Linear(in_ch, embed_dim),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward_features_map(self, x):\n",
    "        return self.backbone.forward_features(x)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.forward_features_map(x)\n",
    "        x = self.embed(x)\n",
    "        x = self.pool(x).flatten(1)\n",
    "        x = self.proj(x)\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b055b",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f55cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"DataLoader workerì˜ ì¬í˜„ì„± ë³´ì¥\"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee783da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(fold_idx, train_drivers, val_drivers):\n",
    "    print(f\"==== Fold {fold_idx}/{n_folds} ====\")\n",
    "\n",
    "    # ===== ë°ì´í„°ì…‹ & ë¡œë” =====\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(SEED)\n",
    "\n",
    "    train_dataset = DriverDataset(\n",
    "        clahe_train_dir, driver_df, train_drivers,\n",
    "        transform=transform_train, is_test=False\n",
    "    )\n",
    "    val_dataset = DriverDataset(\n",
    "        clahe_train_dir, driver_df, val_drivers,\n",
    "        transform=transform_eval, is_test=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=True,\n",
    "                              worker_init_fn=worker_init_fn, generator=g)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=num_workers, pin_memory=True,\n",
    "                            worker_init_fn=worker_init_fn, generator=g)\n",
    "\n",
    "    print(f\"í•™ìŠµ ë°°ì¹˜ ìˆ˜: {len(train_loader)}\")\n",
    "    print(f\"ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}\")\n",
    "\n",
    "    # ===== ëª¨ë¸ =====\n",
    "    model = ResNetDWithHead(\n",
    "        num_classes=num_classes,\n",
    "        embed_dim=EMBED_DIM,\n",
    "        dropout=DROPOUT,\n",
    "    ).to(device)\n",
    "\n",
    "    # # ---- layer1ê¹Œì§€ ë™ê²° (stem~layer1 freeze) ----\n",
    "    # for n, p in model.backbone.named_parameters():\n",
    "    #     if n.startswith('layer2') or n.startswith('layer3') or n.startswith('layer4'):\n",
    "    #         p.requires_grad = True\n",
    "    #     else:\n",
    "    #         p.requires_grad = False\n",
    "    # # headëŠ” í•™ìŠµ\n",
    "    # for p in model.embed.parameters(): p.requires_grad = True\n",
    "    # for p in model.proj.parameters(): p.requires_grad = True\n",
    "    # for p in model.classifier.parameters(): p.requires_grad = True\n",
    "\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° í†µê³„\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"  ì „ì²´ íŒŒë¼ë¯¸í„°:      {total_params:>15,}\")\n",
    "    print(f\"  í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°:  {trainable_params:>15,} ({100*trainable_params/total_params:>6.2f}%)\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    # ===== ì†ì‹¤/ì˜µí‹°ë§ˆ/ìŠ¤ì¼€ì¤„ëŸ¬ =====\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    # optimizer = optim.AdamW(\n",
    "    #     filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    #     lr=3e-4,\n",
    "    #     weight_decay=5e-2\n",
    "    # )\n",
    "    optimizer = optim.AdamW( # ì„œí˜„ë‹˜ ì„¤ì • ìœ ì§€\n",
    "        model.parameters(),\n",
    "        lr=3e-4,\n",
    "        weight_decay=5e-2\n",
    "    )\n",
    "    warmup_epochs = 5\n",
    "    cosine_epochs = max(1, num_epochs - warmup_epochs)\n",
    "    scheduler = SequentialLR(\n",
    "        optimizer,\n",
    "        schedulers=[\n",
    "            LinearLR(optimizer, start_factor=0.01, end_factor=1.0, total_iters=warmup_epochs),\n",
    "            CosineAnnealingLR(optimizer, T_max=cosine_epochs)\n",
    "        ],\n",
    "        milestones=[warmup_epochs]\n",
    "    )\n",
    "\n",
    "    # ===== ê¸°ë¡ =====\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],\n",
    "               'val_macro_f1': [], 'val_logloss': [], 'learning_rates': []}\n",
    "\n",
    "    # ===== Early Stopping =====\n",
    "    early_stop_patience = EARLY_STOP_PATIENCE\n",
    "    patience_counter = 0\n",
    "    best_metric = float('inf')\n",
    "    best_model_path = f'models/{name}.pth'\n",
    "\n",
    "    print(f\"\\nâ±ï¸ Early Stopping Patience (val logloss ê¸°ì¤€): {early_stop_patience} ep\\n\")\n",
    "    print(\"=\"*70); print(\"ğŸš€ í•™ìŠµ ì‹œì‘\"); print(\"=\"*70)\n",
    "\n",
    "    def eval_on_loader(model, loader, criterion):\n",
    "        model.eval()\n",
    "        total, correct, running_loss = 0, 0, 0.0\n",
    "        all_probs, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(loader, desc='Validating', leave=False)\n",
    "            for images, labels in pbar:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                logits = model(images)\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                running_loss += loss.item() * labels.size(0)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                probs = logits.softmax(dim=1).detach().cpu().numpy()\n",
    "                all_probs.append(probs)\n",
    "                all_labels.append(labels.detach().cpu().numpy())\n",
    "                pbar.set_postfix({'loss': f'{loss.item():.4f}',\n",
    "                                  'acc': f'{100.0*correct/max(1,total):.2f}%'})\n",
    "\n",
    "        avg_loss = running_loss / max(1, total)\n",
    "        acc = 100.0 * correct / max(1, total)\n",
    "        all_probs = np.concatenate(all_probs, axis=0)\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        macro_f1 = f1_score(all_labels, np.argmax(all_probs, axis=1), average='macro')\n",
    "        mlogloss = log_loss(all_labels, all_probs, labels=list(range(num_classes)))\n",
    "        return avg_loss, acc, macro_f1, mlogloss\n",
    "\n",
    "    # ===== ì—í­ ë£¨í”„ =====\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\n{\"=\"*70}')\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'{\"=\"*70}')\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        history['learning_rates'].append(current_lr)\n",
    "\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "        pbar = tqdm(train_loader, desc='Training', leave=False)\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits = model(images)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * labels.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}',\n",
    "                              'acc': f'{100.0*train_correct/max(1,train_total):.2f}%',\n",
    "                              'lr': f'{current_lr:.6f}'})\n",
    "\n",
    "        epoch_train_loss = train_loss / max(1, train_total)\n",
    "        epoch_train_acc = 100.0 * train_correct / max(1, train_total)\n",
    "\n",
    "        # ---- Validate ----\n",
    "        val_loss, val_acc, val_macro_f1, val_logloss = eval_on_loader(model, val_loader, criterion)\n",
    "        scheduler.step()\n",
    "\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_macro_f1'].append(val_macro_f1)\n",
    "        history['val_logloss'].append(val_logloss)\n",
    "\n",
    "        print(f'\\nğŸ“Š Epoch {epoch+1} ê²°ê³¼:')\n",
    "        print(f'  Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc:.2f}%')\n",
    "        print(f'  Val   Loss: {val_loss:.4f} | Val Acc:   {val_acc:.2f}%')\n",
    "        print(f'  Val Macro-F1: {val_macro_f1:.4f} | Val LogLoss: {val_logloss:.4f}')\n",
    "        print(f'  LR: {current_lr:.6f}')\n",
    "\n",
    "        # ---- Best / Early Stop ----\n",
    "        if val_logloss < best_metric:\n",
    "            best_metric = val_logloss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'fold': fold_idx,\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'history': history,\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc,\n",
    "                'val_macro_f1': val_macro_f1,\n",
    "                'val_logloss': val_logloss,\n",
    "                'model_name': name,\n",
    "                'freeze_mode': 'freeze_to_layer1',\n",
    "                'drop_path_rate': DROP_PATH,\n",
    "                'trainable_params': trainable_params,\n",
    "                'total_params': total_params,\n",
    "                'seed': SEED\n",
    "            }, best_model_path)\n",
    "            print(f'  âœ… ìµœê³  ì„±ëŠ¥(val_logloss) ëª¨ë¸ ì €ì¥! (val_logloss: {val_logloss:.4f})')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f'  â³ Early Stopping ì¹´ìš´í„°: {patience_counter}/{EARLY_STOP_PATIENCE}')\n",
    "            if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "                print(f'\\n{\"=\"*70}')\n",
    "                print(f'ğŸ›‘ Early Stopping ë°œë™! (Epoch {epoch+1}) â€” val_logloss ê°œì„  ì—†ìŒ')\n",
    "                print(f'   ìµœê³  val_logloss: {best_metric:.4f}')\n",
    "                print(f'   ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {best_model_path}')\n",
    "                print(f'{\"=\"*70}')\n",
    "                break\n",
    "\n",
    "    final_epoch = epoch + 1\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"âœ… Fold {fold_idx} í•™ìŠµ ì™„ë£Œ! (EXP-1+)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"  ì´ í•™ìŠµ ì—í­: {final_epoch}/{num_epochs}\")\n",
    "    print(f\"  ìµœê³  Macro-F1: {max(history['val_macro_f1']):.4f}\")\n",
    "    print(f\"  ìµœì € Val Loss: {min(history['val_loss']):.4f}\")\n",
    "    print(f\"  ìµœì € LogLoss:  {min(history['val_logloss']):.4f}\")\n",
    "    print(f\"  ìµœê³  Val Acc:  {max(history['val_acc']):.2f}%\")\n",
    "    print(f\"  ëª¨ë¸ ì €ì¥: {best_model_path}\")\n",
    "    print(f\"  í•™ìŠµ íŒŒë¼ë¯¸í„°: {trainable_params:,} / {total_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    return {\n",
    "        'fold': fold_idx,\n",
    "        'history': history,\n",
    "        'best_macro_f1': max(history['val_macro_f1']),\n",
    "        'best_val_loss': min(history['val_loss']),\n",
    "        'best_val_logloss': min(history['val_logloss']),\n",
    "        'best_val_acc': max(history['val_acc']),\n",
    "        'model_path': best_model_path,\n",
    "        'stopped_epoch': final_epoch,\n",
    "        'model_name': name,\n",
    "        'freeze_mode': 'freeze_to_layer1',\n",
    "        'trainable_params': trainable_params,\n",
    "        'total_params': total_params,\n",
    "        'seed':SEED\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb6b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Fold 2 í•™ìŠµ (Inception-Cë¶€í„° Fine-tuning) ==========\n",
    "\n",
    "all_fold_results = []\n",
    "\n",
    "fold_info = fold_splits[1]  # Fold 2\n",
    "fold_idx = fold_info['fold']\n",
    "train_drivers = fold_info['train_drivers']\n",
    "val_drivers = fold_info['val_drivers']\n",
    "\n",
    "\n",
    "print(f\"==== {name} ====\")\n",
    "\n",
    "\n",
    "fold_result = train_fold(\n",
    "    fold_idx, \n",
    "    train_drivers, \n",
    "    val_drivers,\n",
    ")\n",
    "\n",
    "all_fold_results.append(fold_result)\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ğŸ“Š ìµœì¢… ê²°ê³¼\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Fold: {fold_result['fold']}\")\n",
    "print(f\"  ìµœì € Val Loss: {fold_result['best_val_loss']:.4f}\")\n",
    "print(f\"  í•´ë‹¹ Val Acc: {fold_result['best_val_acc']:.2f}%\")\n",
    "print(f\"  í•™ìŠµ ì™„ë£Œ ì—í­: {fold_result['stopped_epoch']}\")\n",
    "print(f\"  Freeze ëª¨ë“œ: {fold_result['freeze_mode']}\")\n",
    "print(f\"  í•™ìŠµ íŒŒë¼ë¯¸í„°: {fold_result['trainable_params']:,} / {fold_result['total_params']:,}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4580a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== í•™ìŠµ ê³¡ì„  ì‹œê°í™” (4ê°œ ê·¸ë˜í”„) ==========\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "for result in all_fold_results:\n",
    "    fold_idx = result['fold']\n",
    "    history = result['history']\n",
    "    stopped_epoch = result['stopped_epoch']\n",
    "    best_val_loss = result['best_val_loss']\n",
    "    \n",
    "    # 1. Loss ê·¸ë˜í”„\n",
    "    ax1 = axes[0, 0]\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    ax1.plot(epochs, history['train_loss'], label='Train Loss', \n",
    "             marker='o', linewidth=2, alpha=0.8, color='#1f77b4')\n",
    "    ax1.plot(epochs, history['val_loss'], label='Val Loss', \n",
    "             marker='s', linewidth=2, alpha=0.8, color='#ff7f0e')\n",
    "    \n",
    "    # ìµœì € Val Loss ì§€ì  í‘œì‹œ\n",
    "    best_epoch = np.argmin(history['val_loss']) + 1\n",
    "    ax1.scatter(best_epoch, best_val_loss, color='red', s=250, zorder=5, \n",
    "                marker='*', edgecolors='black', linewidths=2,\n",
    "                label=f'Best (Epoch {best_epoch})')\n",
    "    \n",
    "    # Early Stopping ì§€ì  í‘œì‹œ\n",
    "    if stopped_epoch < num_epochs:\n",
    "        ax1.axvline(stopped_epoch, color='red', linestyle='--', \n",
    "                   linewidth=2, alpha=0.5, label=f'Early Stop (E{stopped_epoch})')\n",
    "    \n",
    "    ax1.set_title(f'Fold {fold_idx} - Loss (Multiclass Log Loss)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.legend(loc='best', fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Accuracy ê·¸ë˜í”„\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(epochs, history['train_acc'], label='Train Acc', \n",
    "             marker='o', linewidth=2, alpha=0.8, color='#2ca02c')\n",
    "    ax2.plot(epochs, history['val_acc'], label='Val Acc', \n",
    "             marker='s', linewidth=2, alpha=0.8, color='#d62728')\n",
    "    \n",
    "    # ìµœê³  Val Acc ì§€ì  í‘œì‹œ\n",
    "    best_acc_epoch = np.argmax(history['val_acc']) + 1\n",
    "    best_val_acc = max(history['val_acc'])\n",
    "    ax2.scatter(best_acc_epoch, best_val_acc, color='green', s=250, zorder=5,\n",
    "                marker='*', edgecolors='black', linewidths=2,\n",
    "                label=f'Best (Epoch {best_acc_epoch})')\n",
    "    \n",
    "    if stopped_epoch < num_epochs:\n",
    "        ax2.axvline(stopped_epoch, color='red', linestyle='--', \n",
    "                   linewidth=2, alpha=0.5, label=f'Early Stop (E{stopped_epoch})')\n",
    "    \n",
    "    ax2.set_title(f'Fold {fold_idx} - Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax2.legend(loc='best', fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Learning Rate ê·¸ë˜í”„\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(epochs, history['learning_rates'], marker='o', linewidth=2, \n",
    "             color='purple', alpha=0.8, label='Learning Rate')\n",
    "    ax3.set_title(f'Fold {fold_idx} - Learning Rate Schedule', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Epoch', fontsize=12)\n",
    "    ax3.set_ylabel('Learning Rate', fontsize=12)\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.legend(loc='best', fontsize=10)\n",
    "    ax3.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    if stopped_epoch < num_epochs:\n",
    "        ax3.axvline(stopped_epoch, color='red', linestyle='--', \n",
    "                   linewidth=2, alpha=0.5)\n",
    "    \n",
    "    # 4. Train vs Val ë¹„êµ (Loss & Acc)\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Loss ì°¨ì´\n",
    "    loss_diff = np.array(history['train_loss']) - np.array(history['val_loss'])\n",
    "    ax4_twin = ax4.twinx()\n",
    "    \n",
    "    ax4.plot(epochs, loss_diff, marker='o', linewidth=2, \n",
    "            color='#e377c2', alpha=0.7, label='Loss Diff (Train - Val)')\n",
    "    ax4.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "    ax4.set_xlabel('Epoch', fontsize=12)\n",
    "    ax4.set_ylabel('Loss Difference', fontsize=12, color='#e377c2')\n",
    "    ax4.tick_params(axis='y', labelcolor='#e377c2')\n",
    "    \n",
    "    # Accuracy ì°¨ì´\n",
    "    acc_diff = np.array(history['train_acc']) - np.array(history['val_acc'])\n",
    "    ax4_twin.plot(epochs, acc_diff, marker='s', linewidth=2,\n",
    "                 color='#bcbd22', alpha=0.7, label='Acc Diff (Train - Val)')\n",
    "    ax4_twin.set_ylabel('Accuracy Difference (%)', fontsize=12, color='#bcbd22')\n",
    "    ax4_twin.tick_params(axis='y', labelcolor='#bcbd22')\n",
    "    \n",
    "    ax4.set_title(f'Fold {fold_idx} - Overfitting ëª¨ë‹ˆí„°ë§', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Legend í†µí•©\n",
    "    lines1, labels1 = ax4.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax4_twin.get_legend_handles_labels()\n",
    "    ax4.legend(lines1 + lines2, labels1 + labels2, loc='best', fontsize=9)\n",
    "    \n",
    "    if stopped_epoch < num_epochs:\n",
    "        ax4.axvline(stopped_epoch, color='red', linestyle='--', \n",
    "                   linewidth=2, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs(f'./plots/{name}', exist_ok=True)\n",
    "plt.savefig(f'./plots/{name}/{name}_losscurve_detailed.png', \n",
    "           dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ========== í†µê³„ ì¶œë ¥ ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"ğŸ“ˆ {name} í•™ìŠµ í†µê³„ ìƒì„¸\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ì´ˆê¸° Train Loss: {history['train_loss'][0]:.4f}\")\n",
    "print(f\"ìµœì¢… Train Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"ìµœì € Train Loss: {min(history['train_loss']):.4f} (Epoch {np.argmin(history['train_loss'])+1})\")\n",
    "print(f\"\\nì´ˆê¸° Val Loss: {history['val_loss'][0]:.4f}\")\n",
    "print(f\"ìµœì¢… Val Loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"ìµœì € Val Loss: {min(history['val_loss']):.4f} (Epoch {np.argmin(history['val_loss'])+1})\")\n",
    "print(f\"\\nì´ˆê¸° Train Acc: {history['train_acc'][0]:.2f}%\")\n",
    "print(f\"ìµœì¢… Train Acc: {history['train_acc'][-1]:.2f}%\")\n",
    "print(f\"ìµœê³  Train Acc: {max(history['train_acc']):.2f}% (Epoch {np.argmax(history['train_acc'])+1})\")\n",
    "print(f\"\\nì´ˆê¸° Val Acc: {history['val_acc'][0]:.2f}%\")\n",
    "print(f\"ìµœì¢… Val Acc: {history['val_acc'][-1]:.2f}%\")\n",
    "print(f\"ìµœê³  Val Acc: {max(history['val_acc']):.2f}% (Epoch {np.argmax(history['val_acc'])+1})\")\n",
    "print(f\"\\nì´ˆê¸° LR: {history['learning_rates'][0]:.6f}\")\n",
    "print(f\"ìµœì¢… LR: {history['learning_rates'][-1]:.6f}\")\n",
    "print(f\"LR ë³€ê²½ íšŸìˆ˜: {len(set(history['learning_rates'])) - 1}íšŒ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ========== Overfitting ë¶„ì„ ==========\n",
    "final_loss_gap = history['train_loss'][-1] - history['val_loss'][-1]\n",
    "final_acc_gap = history['train_acc'][-1] - history['val_acc'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” Overfitting ë¶„ì„\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ìµœì¢… Loss ì°¨ì´ (Train - Val): {final_loss_gap:+.4f}\")\n",
    "print(f\"ìµœì¢… Acc ì°¨ì´ (Train - Val): {final_acc_gap:+.2f}%\")\n",
    "\n",
    "if final_acc_gap > 10:\n",
    "    print(\"âš ï¸ ê²½ê³ : ì‹¬ê°í•œ Overfitting ê°ì§€! (Acc ì°¨ì´ > 10%)\")\n",
    "elif final_acc_gap > 5:\n",
    "    print(\"âš ï¸ ì£¼ì˜: ì•½ê°„ì˜ Overfitting ê°ì§€ (Acc ì°¨ì´ > 5%)\")\n",
    "else:\n",
    "    print(\"âœ… ì–‘í˜¸: Overfittingì´ ì˜ ì œì–´ë˜ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80840b6",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ab894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Submission íŒŒì¼ ìƒì„± (í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©) ==========\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì‹œì‘\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±\n",
    "test_dataset = DriverDataset(\n",
    "    clahe_test_dir, driver_df, [], \n",
    "    transform=transform_eval, is_test=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(test_dataset)}ê°œ\")\n",
    "\n",
    "# 2. ëª¨ë¸ ìƒì„±\n",
    "model = ResNetDWithHead(\n",
    "    num_classes=num_classes,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    dropout=DROPOUT,\n",
    ").to(device)\n",
    "\n",
    "# 3. ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "best_model_path = f'models/{name}.pth'\n",
    "print(f\"\\nğŸ“ ëª¨ë¸ ë¡œë“œ ì¤‘: {best_model_path}...\")\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(best_model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # ë¡œë“œëœ ëª¨ë¸ ì •ë³´ ì¶œë ¥\n",
    "    print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "    print(f\"   - Fold: {checkpoint.get('fold', 'N/A')}\")\n",
    "    print(f\"   - Epoch: {checkpoint.get('epoch', 'N/A')+1}\")\n",
    "    print(f\"   - Val Loss: {checkpoint.get('val_loss', 'N/A'):.4f}\")\n",
    "    print(f\"   - Val logLoss: {checkpoint.get('val_logloss', 'N/A'):.4f}\")\n",
    "    print(f\"   - Val Acc: {checkpoint.get('val_acc', 'N/A'):.2f}%\")\n",
    "    print(f\"   - Val Macro-F1: {checkpoint.get('val_macro_f1', 'N/A'):.4f}\")\n",
    "    print(f\"   - Val LogLoss: {checkpoint.get('val_logloss', 'N/A'):.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ğŸš¨ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    raise\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 4. ì˜ˆì¸¡ ì‹¤í–‰\n",
    "predictions = []\n",
    "img_names = []\n",
    "\n",
    "print(\"\\nğŸ”® ì˜ˆì¸¡ ì§„í–‰ ì¤‘...\")\n",
    "with torch.no_grad():\n",
    "    for images, filenames in tqdm(test_loader, desc='ì˜ˆì¸¡'):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 5. í™•ë¥  (Softmax) ê³„ì‚°\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        predictions.append(probs.cpu().numpy())\n",
    "        img_names.extend(filenames)\n",
    "\n",
    "final_predictions = np.vstack(predictions)\n",
    "print(f\"\\nâœ… ì˜ˆì¸¡ ì™„ë£Œ: {final_predictions.shape}\")\n",
    "\n",
    "# 6. Submission íŒŒì¼ ìƒì„±\n",
    "class_cols = [f'c{i}' for i in range(num_classes)]\n",
    "\n",
    "submission_data = {'img': img_names}\n",
    "for i, col in enumerate(class_cols):\n",
    "    submission_data[col] = final_predictions[:, i]\n",
    "\n",
    "submission = pd.DataFrame(submission_data)\n",
    "\n",
    "# 7. íŒŒì¼ ì €ì¥\n",
    "os.makedirs('./submissions', exist_ok=True)\n",
    "submission.to_csv(f\"./submissions/{name}_submission.csv\", index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"âœ… Submission íŒŒì¼ ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"ğŸ“ ì €ì¥ ê²½ë¡œ: ./submissions/{name}_submission.csv\")\n",
    "print(f\"ğŸ“Š ì´ ì˜ˆì¸¡ ì´ë¯¸ì§€: {len(submission)}ê°œ\")\n",
    "print(f\"ğŸ“‹ í´ë˜ìŠ¤ë³„ í‰ê·  í™•ë¥ :\")\n",
    "for col in class_cols:\n",
    "    print(f\"   {col}: {submission[col].mean():.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nğŸ“‹ Submission ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):\")\n",
    "print(submission.head())\n",
    "\n",
    "print(\"\\nğŸ“‹ Submission ìƒ˜í”Œ (ë§ˆì§€ë§‰ 5ê°œ):\")\n",
    "print(submission.tail())\n",
    "\n",
    "# 8. í™•ë¥  ë¶„í¬ ê²€ì¦ (í•©ì´ 1ì¸ì§€ í™•ì¸)\n",
    "prob_sums = submission[class_cols].sum(axis=1)\n",
    "print(f\"\\nâœ… í™•ë¥  í•© ê²€ì¦: min={prob_sums.min():.6f}, max={prob_sums.max():.6f}, mean={prob_sums.mean():.6f}\")\n",
    "if not np.allclose(prob_sums, 1.0, atol=1e-5):\n",
    "    print(\"âš ï¸ ê²½ê³ : ì¼ë¶€ ìƒ˜í”Œì˜ í™•ë¥  í•©ì´ 1ì´ ì•„ë‹™ë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"âœ… ëª¨ë“  ìƒ˜í”Œì˜ í™•ë¥  í•©ì´ 1ì…ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c18454",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6120e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì…€ ì¶”ê°€: Confusion Matrix ë¶„ì„\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_predictions(model, val_loader, device):\n",
    "    \"\"\"ê²€ì¦ ë°ì´í„°ë¡œ ìƒì„¸ ë¶„ì„\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc='ì˜ˆì¸¡ ì¤‘'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images, labels)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    all_probs = np.vstack(all_probs)\n",
    "    return np.array(all_labels), np.array(all_preds), all_probs\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model = ResNetDWithHead(\n",
    "    num_classes=num_classes,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    dropout=DROPOUT,\n",
    ").to(device)\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "fold_info = fold_splits[1] \n",
    "\n",
    "fold_idx = fold_info['fold']\n",
    "train_drivers = fold_info['train_drivers']\n",
    "val_drivers = fold_info['val_drivers']\n",
    "\n",
    "val_dataset = DriverDataset(\n",
    "    train_dir, driver_df, val_drivers,\n",
    "    transform=transform_eval, is_test=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "y_true, y_pred, y_probs = analyze_predictions(model, val_loader, device)\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "class_names = [f'c{i}' for i in range(10)]\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./plots/{name}/confusion_matrix_{name}.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 2. Normalized Confusion Matrix (ë¹„ìœ¨)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='YlOrRd',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Normalized Confusion Matrix (%)', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "os.makedirs(f'plots/{name}', exist_ok=True)\n",
    "plt.savefig(f'plots/{name}/confusion_matrix_normalized_{name}.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 3. Classification Report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š Classification Report\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "if 'y_true' not in globals() or 'y_pred' not in globals() or 'y_probs' not in globals():\n",
    "    print(\"y_true/y_pred/y_probsê°€ ì—†ìŒ â€” analyze_predictions ì‹¤í–‰ ì¤‘...\")\n",
    "    y_true, y_pred, y_probs = analyze_predictions(model, val_loader, device)\n",
    "else:\n",
    "    print(\"y_true/y_pred/y_probs ì´ë¯¸ ì¡´ì¬, ì¬ê³„ì‚° ìƒëµ\")\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_true, y_pred, average=None\n",
    ")\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬\n",
    "class_performance = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support,\n",
    "    'Accuracy': [accuracy_score(y_true[y_true==i], y_pred[y_true==i]) \n",
    "                 if np.sum(y_true==i) > 0 else 0 for i in range(10)]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥\")\n",
    "print(\"=\"*70)\n",
    "print(class_performance.to_string(index=False))\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Precision\n",
    "axes[0, 0].bar(class_names, precision, color='skyblue', alpha=0.8)\n",
    "axes[0, 0].set_title('Precision by Class', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Precision')\n",
    "axes[0, 0].set_ylim([0, 1.1])\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[0, 1].bar(class_names, recall, color='lightcoral', alpha=0.8)\n",
    "axes[0, 1].set_title('Recall by Class', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Recall')\n",
    "axes[0, 1].set_ylim([0, 1.1])\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# F1-Score\n",
    "axes[1, 0].bar(class_names, f1, color='lightgreen', alpha=0.8)\n",
    "axes[1, 0].set_title('F1-Score by Class', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('F1-Score')\n",
    "axes[1, 0].set_ylim([0, 1.1])\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Support\n",
    "axes[1, 1].bar(class_names, support, color='plum', alpha=0.8)\n",
    "axes[1, 1].set_title('Support (Sample Count) by Class', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs(f'plots/{name}', exist_ok=True)\n",
    "plt.savefig(f'plots/{name}/class_performance_{name}.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24862329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve ë¶„ì„\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# One-hot encoding\n",
    "y_true_bin = label_binarize(y_true, classes=range(10))\n",
    "\n",
    "# ê° í´ë˜ìŠ¤ë³„ ROC Curve\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{class_names[i]} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves (Multi-class)', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'plots/{name}/roc_curves_{name}.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71559815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM êµ¬í˜„\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"Grad-CAM (ResNet í˜¸í™˜)\"\"\"\n",
    "    def __init__(self, model, target_module=None):\n",
    "        self.model = model\n",
    "        self.target_module = target_module\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        # target_moduleì´ Noneì´ë©´ ëª¨ë¸ì—ì„œ ë§ˆì§€ë§‰ Conv2dë¥¼ ì°¾ì•„ ì‚¬ìš©\n",
    "        if self.target_module is None:\n",
    "            self.target_module, _ = get_last_conv_layer_resnet(self.model)\n",
    "            if self.target_module is None:\n",
    "                raise RuntimeError(\"ë§ˆì§€ë§‰ Conv ë ˆì´ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        # í›… ë“±ë¡ (forward / backward)\n",
    "        self.target_module.register_forward_hook(self._save_activation)\n",
    "        # ìµœì‹  PyTorchì—ì„œëŠ” register_full_backward_hook ê¶Œì¥, ì—†ìœ¼ë©´ register_backward_hook ì‚¬ìš©\n",
    "        if hasattr(self.target_module, \"register_full_backward_hook\"):\n",
    "            self.target_module.register_full_backward_hook(self._save_gradient)\n",
    "        else:\n",
    "            # êµ¬ë²„ì „ í˜¸í™˜\n",
    "            self.target_module.register_backward_hook(self._save_gradient)\n",
    "\n",
    "    def _save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def _save_gradient(self, module, grad_input, grad_output):\n",
    "        # grad_outputëŠ” tuple\n",
    "        self.gradients = grad_output[0].detach()\n",
    "\n",
    "    def generate_cam(self, input_tensor, target_class=None):\n",
    "        \"\"\"\n",
    "        input_tensor: [1, C, H, W] (ì´ë¯¸ ì •ê·œí™”ëœ í…ì„œ)`\n",
    "        target_class: int or None (Noneì´ë©´ argmax ì‚¬ìš©)\n",
    "        returns: cam (H, W) float numpy [0..1], logits tensor\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        logits = self.model(input_tensor)  # ì¼ë°˜ forward\n",
    "\n",
    "        if target_class is None:\n",
    "            target_class = int(logits.argmax(dim=1)[0])\n",
    "\n",
    "        # backward on the score of target_class\n",
    "        self.model.zero_grad()\n",
    "        score = logits[0, target_class]\n",
    "        score.backward(retain_graph=True)\n",
    "\n",
    "        if self.gradients is None or self.activations is None:\n",
    "            raise RuntimeError(\"Gradients or activations not recorded. Check hooks.\")\n",
    "\n",
    "        # gradients: [1, C, H, W] -> use [C, H, W]\n",
    "        gradients = self.gradients[0].cpu()\n",
    "        activations = self.activations[0].cpu()\n",
    "\n",
    "        # global average pooling of gradients -> weights [C]\n",
    "        weights = gradients.mean(dim=(1, 2))  # [C]\n",
    "\n",
    "        # weighted sum of activations\n",
    "        cam = (weights[:, None, None] * activations).sum(dim=0)  # [H, W]\n",
    "        cam = F.relu(cam)\n",
    "        cam = cam - cam.min()\n",
    "        if cam.max() > 0:\n",
    "            cam = cam / cam.max()\n",
    "        cam_np = cam.numpy().astype(np.float32)\n",
    "\n",
    "        return cam_np, logits\n",
    "\n",
    "def get_last_conv_layer_resnet(model):\n",
    "    \"\"\"\n",
    "    ResNet ê³„ì—´ ëª¨ë¸ì—ì„œ ë§ˆì§€ë§‰ nn.Conv2d ëª¨ë“ˆì„ ì°¾ì•„ ë°˜í™˜\n",
    "    ë°˜í™˜: (module, name) ë˜ëŠ” (None, None)\n",
    "    \"\"\"\n",
    "    for name, module in reversed(list(model.named_modules())):\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            return module, name\n",
    "    return None, None\n",
    "\n",
    "def visualize_gradcam(model, image, true_label, pred_label, device):\n",
    "    \"\"\"Grad-CAM ì‹œê°í™” (ResNet)\"\"\"\n",
    "    # target layer ì°¾ê¸°/ì„¤ì •\n",
    "    target_module, target_name = get_last_conv_layer_resnet(model)\n",
    "    if target_module is None:\n",
    "        print(\"âš ï¸ ë§ˆì§€ë§‰ Conv ë ˆì´ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    gradcam = GradCAM(model, target_module)\n",
    "\n",
    "    # ì´ë¯¸ì§€ëŠ” [C, H, W] (ì •ê·œí™”ëœ í…ì„œ)\n",
    "    input_tensor = image.unsqueeze(0).to(device)\n",
    "    cam, output = gradcam.generate_cam(input_tensor, target_class=pred_label)\n",
    "\n",
    "    # ì›ë³¸ ì´ë¯¸ì§€ ë³µì› (ì •ê·œí™” ì—­ë³€í™˜)\n",
    "    img_np = image.cpu().numpy().transpose(1, 2, 0)\n",
    "    img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img_np = np.clip(img_np, 0, 1)\n",
    "\n",
    "    # camì€ [H, W], float [0..1] -> uint8ë¡œ ë³€í™˜ í›„ PIL ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    H, W = img_np.shape[:2]\n",
    "    cam_uint8 = np.uint8(255 * cam)\n",
    "    cam_pil = Image.fromarray(cam_uint8).resize((W, H), Image.BILINEAR)\n",
    "    cam_resized = np.array(cam_pil) / 255.0\n",
    "\n",
    "    # ì‹œê°í™”\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    axes[0].imshow(img_np)\n",
    "    axes[0].set_title(f'Original\\nTrue: c{true_label}', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(img_np)\n",
    "    axes[1].imshow(cam_resized, cmap='jet', alpha=0.5)\n",
    "    axes[1].set_title(f'Grad-CAM\\nPred: c{pred_label}', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(cam_resized, cmap='jet')\n",
    "    axes[2].set_title('Heatmap', fontsize=12)\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ì— Grad-CAM ì ìš©\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”¥ Grad-CAM ì‹œê°í™”\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ (ResNetDWithHead ë˜í¼ ì‚¬ìš©)\n",
    "model = ResNetDWithHead(\n",
    "    num_classes=num_classes,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    dropout=DROPOUT,\n",
    ").to(device)\n",
    "\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ì¶”ì¶œ (ì •ë‹µ/ì˜¤ë‹µ ê°ê°)\n",
    "correct_samples = []\n",
    "incorrect_samples = []\n",
    "\n",
    "for i, (images, labels) in enumerate(tqdm(val_loader)):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    for j in range(len(images)):\n",
    "        if preds[j] == labels[j]:\n",
    "            correct_samples.append((images[j], labels[j].item(), preds[j].item()))\n",
    "        elif preds[j] != labels[j]:\n",
    "            incorrect_samples.append((images[j], labels[j].item(), preds[j].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ì •ë‹µ ì˜ˆì¸¡ ìƒ˜í”Œ (ê° í´ë˜ìŠ¤ ë³„ 5ê°œ)\")\n",
    "corr_class_samples = {i: [] for i in range(10)}\n",
    "max_samples = 5\n",
    "os.makedirs(f'plots/{name}/gradcam_correct', exist_ok=True)\n",
    "\n",
    "for img, true_label, pred_label in correct_samples:\n",
    "\tcurr = corr_class_samples[true_label]\n",
    "\tif len(curr) < max_samples:\n",
    "\t\tcurr.append((img, true_label, pred_label))\n",
    "\n",
    "for class_idx in range(10):\n",
    "\tif corr_class_samples[class_idx]:\n",
    "\t\tprint(f\"{class_idx} grad cam\")\n",
    "\t\tfor idx, (img, true_label, pred_label) in enumerate(corr_class_samples[class_idx]):\n",
    "\t\t\tfig = visualize_gradcam(model, img, true_label, pred_label, device)\n",
    "\t\t\tplt.savefig(f'plots/{name}/gradcam_correct/gradcam_correct_c{class_idx}_{idx}_{name}.png', dpi=300, bbox_inches='tight')\n",
    "\t\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ì •ë‹µ ì˜ˆì¸¡ ìƒ˜í”Œ (ê° í´ë˜ìŠ¤ ë³„ 5ê°œ)\")\n",
    "incorr_class_samples = {i: [] for i in range(10)}\n",
    "max_samples = 5\n",
    "os.makedirs(f'plots/{name}/gradcam_incorrect', exist_ok=True)\n",
    "\n",
    "for img, true_label, pred_label in incorrect_samples:\n",
    "\tcurr = incorr_class_samples[true_label]\n",
    "\tif len(curr) < max_samples:\n",
    "\t\tcurr.append((img, true_label, pred_label))\n",
    "\n",
    "for class_idx in range(10):\n",
    "\tif incorr_class_samples[class_idx]:\n",
    "\t\tprint(f\"{class_idx} grad cam\")\n",
    "\t\tfor idx, (img, true_label, pred_label) in enumerate(incorr_class_samples[class_idx]):\n",
    "\t\t\tfig = visualize_gradcam(model, img, true_label, pred_label, device)\n",
    "\t\t\tplt.savefig(f'plots/{name}/gradcam_incorrect/gradcam_incorrect_c{class_idx}_{idx}_{name}.png', dpi=300, bbox_inches='tight')\n",
    "\t\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'resnet_{version}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Map ì¶”ì¶œ ë° ì‹œê°í™”\n",
    "class FeatureExtractor:\n",
    "    \"\"\"ì¤‘ê°„ ë ˆì´ì–´ì˜ Feature Map ì¶”ì¶œ\"\"\"\n",
    "    \n",
    "    def __init__(self, model, layer_names):\n",
    "        self.model = model\n",
    "        self.layer_names = layer_names\n",
    "        self.features = {}\n",
    "        \n",
    "        # Hook ë“±ë¡\n",
    "        for name, layer in model.named_modules():\n",
    "            if name in layer_names:\n",
    "                layer.register_forward_hook(self.save_feature(name))\n",
    "    \n",
    "    def save_feature(self, name):\n",
    "        def hook(module, input, output):\n",
    "            self.features[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    def extract(self, x):\n",
    "        self.features = {}\n",
    "        _ = self.model(x)\n",
    "        return self.features\n",
    "\n",
    "def visualize_feature_maps(features, layer_name, max_channels=16):\n",
    "    \"\"\"Feature Map ì‹œê°í™”\"\"\"\n",
    "    feature = features[layer_name][0]  # ì²« ë²ˆì§¸ ë°°ì¹˜\n",
    "    num_channels = min(feature.shape[0], max_channels)\n",
    "    \n",
    "    # Grid í¬ê¸° ê³„ì‚°\n",
    "    grid_size = int(np.ceil(np.sqrt(num_channels)))\n",
    "    \n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_channels):\n",
    "        fmap = feature[i].cpu().numpy()\n",
    "        axes[i].imshow(fmap, cmap='viridis')\n",
    "        axes[i].set_title(f'Ch {i}', fontsize=8)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # ë¹ˆ subplot ìˆ¨ê¸°ê¸°\n",
    "    for i in range(num_channels, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Feature Maps: {layer_name}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Inception V4ì˜ ì£¼ìš” ë ˆì´ì–´ ì´ë¦„ í™•ì¸\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” ëª¨ë¸ êµ¬ì¡° íƒìƒ‰\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for n, module in model.named_modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        print(f\"Conv Layer: {n}\")\n",
    "\n",
    "# ì£¼ìš” ë ˆì´ì–´ ì„ íƒ (ì˜ˆì‹œ)\n",
    "target_layers = [\n",
    "    'backbone.conv1.6',\n",
    "    'backbone.layer1.0.conv3',\n",
    "    'backbone.layer2.0.conv3',\n",
    "    'backbone.layer4.0.conv3',\n",
    "    'backbone.layer4.2.conv3'\n",
    "\n",
    "]\n",
    "\n",
    "# ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ Feature Map ì¶”ì¶œ\n",
    "sample_image, sample_label = next(iter(val_loader))\n",
    "sample_image = sample_image[0:1].to(device)  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€\n",
    "\n",
    "extractor = FeatureExtractor(model, target_layers)\n",
    "features = extractor.extract(sample_image)\n",
    "\n",
    "# ê° ë ˆì´ì–´ ì‹œê°í™”\n",
    "for layer_name in target_layers:\n",
    "    if layer_name in features:\n",
    "        fig = visualize_feature_maps(features, layer_name, max_channels=16)\n",
    "        plt.savefig(f'plots/{name}/feature_map_{layer_name.replace(\".\", \"_\")}.png', dpi=300)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE/UMAPìœ¼ë¡œ ì„ë² ë”© ì‹œê°í™”\n",
    "from sklearn.manifold import TSNE\n",
    "# pip install umap-learn\n",
    "# from umap import UMAP\n",
    "\n",
    "def extract_embeddings(model, dataloader, device):\n",
    "    \"\"\"ë§ˆì§€ë§‰ FC ë ˆì´ì–´ ì´ì „ì˜ ì„ë² ë”© ì¶”ì¶œ\"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    \n",
    "    # FC ë ˆì´ì–´ ì´ì „ ì¶œë ¥ ì¶”ì¶œì„ ìœ„í•œ Hook\n",
    "    features = []\n",
    "    def hook(module, input, output):\n",
    "        features.append(input[0].detach())\n",
    "    \n",
    "\n",
    "    handle = model.classifier.register_forward_hook(hook)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, lbls in tqdm(dataloader, desc='ì„ë² ë”© ì¶”ì¶œ'):\n",
    "            images = images.to(device)\n",
    "            _ = model(images)\n",
    "            \n",
    "            embeddings.append(features[-1].cpu().numpy())\n",
    "            labels.extend(lbls.numpy())\n",
    "            features.clear()\n",
    "    \n",
    "    handle.remove()\n",
    "    \n",
    "    embeddings = np.vstack(embeddings)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return embeddings, labels\n",
    "\n",
    "# ì„ë² ë”© ì¶”ì¶œ\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ§¬ ì„ë² ë”© ì¶”ì¶œ ì¤‘...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "embeddings, labels = extract_embeddings(model, val_loader, device)\n",
    "print(f\"ì„ë² ë”© shape: {embeddings.shape}\")\n",
    "\n",
    "# t-SNE ì‹œê°í™”\n",
    "print(\"\\nğŸ“Š t-SNE ê³„ì‚° ì¤‘...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "scatter = plt.scatter(\n",
    "    embeddings_2d[:, 0], \n",
    "    embeddings_2d[:, 1], \n",
    "    c=labels, \n",
    "    cmap='tab10', \n",
    "    s=10, \n",
    "    alpha=0.6\n",
    ")\n",
    "plt.colorbar(scatter, label='Class', ticks=range(10))\n",
    "plt.title('t-SNE Visualization of Learned Embeddings', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'plots/{name}/tsne_embeddings.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ë¡œ ìƒ‰ìƒ êµ¬ë¶„í•˜ì—¬ Legend ì¶”ê°€\n",
    "plt.figure(figsize=(16, 12))\n",
    "for class_idx in range(10):\n",
    "    mask = labels == class_idx\n",
    "    plt.scatter(\n",
    "        embeddings_2d[mask, 0],\n",
    "        embeddings_2d[mask, 1],\n",
    "        label=f'c{class_idx}',\n",
    "        s=20,\n",
    "        alpha=0.7\n",
    "    )\n",
    "plt.title('t-SNE Visualization by Class', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'plots/{name}/tsne_embeddings_by_class.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563b0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5aede7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
