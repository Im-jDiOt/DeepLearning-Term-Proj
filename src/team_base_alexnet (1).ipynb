{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ 0. Kaggle Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú ÏÑ§Ï†ï\n",
        "!pip install --upgrade kaggle --force-reinstall -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1F8FbWPKE7A",
        "outputId": "66643001-e27f-4086-bb9a-e9b98767d82f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/57.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m164.4/164.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # kaggle.json ÌååÏùº ÏßÅÏ†ë ÏóÖÎ°úÎìú"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "id": "P7goOBEhKJHP",
        "outputId": "a11e9634-3ab0-4a5b-d629-21730d4cabce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8a705f4c-c94c-449b-bc7e-629ce8556722\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8a705f4c-c94c-449b-bc7e-629ce8556722\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"icdi050227\",\"key\":\"6738515dc0795c218ea602dfa0ddc433\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mkdir -p /root/.config/kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!cp kaggle.json /root/.config/kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.config/kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "LPGy2Y_LKOnj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Kaggle Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú\n",
        "!kaggle competitions download -c state-farm-distracted-driver-detection -q\n"
      ],
      "metadata": {
        "id": "Zy7Z9FcqKSzL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -oq /content/state-farm-distracted-driver-detection.zip -d /content/statefarm_data\n"
      ],
      "metadata": {
        "id": "Jq47jBNIM79H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ‚úÖ 1. ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò Î∞è GPU ÏÑ§Ï†ï\n",
        "# ============================================================\n",
        "!pip install timm -q\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "h6-9UbU9KbEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ‚úÖ 2. GPU ÌôïÏù∏\n",
        "# ============================================================\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: {device}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU Ïù¥Î¶Ñ: {torch.cuda.get_device_name(0)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDOovDweKdjN",
        "outputId": "da8e6d09-eaae-4d60-d547-87e48e03f1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: cuda\n",
            "GPU Ïù¥Î¶Ñ: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ‚úÖ 3. Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°ú ÏÑ§Ï†ï (Kaggle Îã§Ïö¥Î°úÎìú Í∏∞Ï§Ä)\n",
        "# ============================================================\n",
        "base_dir = \"/content/statefarm_data\"\n",
        "driver_csv_path = os.path.join(base_dir, \"driver_imgs_list.csv\")\n",
        "train_dir = os.path.join(base_dir, \"imgs\", \"train\")\n",
        "test_dir = os.path.join(base_dir, \"imgs\", \"test\")\n",
        "\n",
        "print(\"CSV Ï°¥Ïû¨?\", os.path.exists(driver_csv_path))\n",
        "print(\"Train Ìè¥Îçî Ï°¥Ïû¨?\", os.path.exists(train_dir))\n",
        "print(\"Test Ìè¥Îçî Ï°¥Ïû¨?\", os.path.exists(test_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9_ye8K8Kfyn",
        "outputId": "eb2a47ce-7bd1-4652-bd76-e180b7fde8bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Ï°¥Ïû¨? True\n",
            "Train Ìè¥Îçî Ï°¥Ïû¨? True\n",
            "Test Ìè¥Îçî Ï°¥Ïû¨? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ‚úÖ 4. ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
        "# ============================================================\n",
        "img_size = 224\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "num_epochs = 40\n",
        "learning_rate = 0.001\n",
        "num_workers = 2"
      ],
      "metadata": {
        "id": "ZvOo6FgLKhta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================\n",
        "# ‚úÖ 5. Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
        "# ============================================================\n",
        "driver_df = pd.read_csv(driver_csv_path)\n",
        "all_drivers = sorted(driver_df['subject'].unique())\n",
        "n_folds = 5\n",
        "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "-87M2NPqKjaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ‚úÖ 6. Dataset Ï†ïÏùò\n",
        "# ============================================================\n",
        "class DriverDataset(Dataset):\n",
        "    def __init__(self, data_dir, driver_df, driver_list, transform=None, is_test=False):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.images, self.labels = [], []\n",
        "\n",
        "        if is_test:\n",
        "            for img_name in os.listdir(data_dir):\n",
        "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    self.images.append(os.path.join(data_dir, img_name))\n",
        "        else:\n",
        "            driver_subset = driver_df[driver_df['subject'].isin(driver_list)]\n",
        "            for _, row in driver_subset.iterrows():\n",
        "                class_name = row['classname']\n",
        "                img_name = row['img']\n",
        "                img_path = os.path.join(data_dir, class_name, img_name)\n",
        "                self.images.append(img_path)\n",
        "                self.labels.append(int(class_name[1:]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx]).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.is_test:\n",
        "            return image, os.path.basename(self.images[idx])\n",
        "        else:\n",
        "            return image, self.labels[idx]\n"
      ],
      "metadata": {
        "id": "9PykCMaYKngr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ‚úÖ 7. Transform ÏÑ§Ï†ï\n",
        "# ============================================================\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_eval = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "oBljEjleKrVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ‚úÖ 8. ÌïôÏäµ / Í≤ÄÏ¶ù Ìï®Ïàò\n",
        "# ============================================================\n",
        "def train_epoch(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for inputs, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return total_loss/total, 100*correct/total\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(loader, desc=\"Validating\", leave=False):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return total_loss/total, 100*correct/total"
      ],
      "metadata": {
        "id": "T9tVA3dIKuvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Fold ÌïôÏäµ Ìï®Ïàò (‚úÖ Fine-tuning + ÏûêÎèô Ï†ÄÏû• Í∏∞Îä• Ìè¨Ìï®)\n",
        "# --------------------------------------------------\n",
        "def train_fold(fold_idx, train_drivers, val_drivers):\n",
        "    print(f\"\\n========== Fold {fold_idx}/{n_folds} ==========\")\n",
        "    train_dataset = DriverDataset(train_dir, driver_df, train_drivers, transform_train)\n",
        "    val_dataset = DriverDataset(train_dir, driver_df, val_drivers, transform_eval)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # ‚úÖ torchvision AlexNet fine-tuning\n",
        "    from torchvision import models\n",
        "    model = models.alexnet(pretrained=True)\n",
        "\n",
        "    # (1) Ï∂úÎ†• Î†àÏù¥Ïñ¥ ÍµêÏ≤¥\n",
        "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "\n",
        "    # (2) ÌäπÏßï Ï∂îÏ∂úÎ∂Ä ÎèôÍ≤∞\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # (3) ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞Îßå optimizerÏóê Ï†ÑÎã¨\n",
        "    optimizer = optim.Adam(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=learning_rate\n",
        "    )\n",
        "\n",
        "    # (4) ÏÜêÏã§Ìï®Ïàò & device ÏÑ§Ï†ï\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model = model.to(device)\n",
        "\n",
        "    # ‚úÖ (Ï∂îÍ∞Ä) ÌïôÏäµ Í∏∞Î°ù Î∞è Î™®Îç∏ Ï†ÄÏû• Í¥ÄÎ†® Ï¥àÍ∏∞Ìôî\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "    best_val_loss = float('inf')\n",
        "    model_path = f'alexnet_fold{fold_idx}_best.pth'\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # Epoch Î£®ÌîÑ\n",
        "    # --------------------------------------------------\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
        "        print(f'Train Loss {train_loss:.4f}, Acc {train_acc:.2f}% | Val Loss {val_loss:.4f}, Acc {val_acc:.2f}%')\n",
        "\n",
        "        # üîπ ÌïôÏäµ Ïù¥Î†• Í∏∞Î°ù\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        # üîπ 5 epochÎßàÎã§ ÏûÑÏãú Ï†ÄÏû•\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            temp_path = f'alexnet_fold{fold_idx}_epoch{epoch+1}.pth'\n",
        "            torch.save(model.state_dict(), temp_path)\n",
        "            print(f\"üü¢ {epoch+1} epochÍπåÏßÄ ÏûÑÏãú Ï†ÄÏû• ÏôÑÎ£å ‚Üí {temp_path}\")\n",
        "\n",
        "        # üîπ ÏµúÏ†Å Î™®Îç∏ Ï†ÄÏû• (Val Loss Í∏∞Ï§Ä)\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(f\"‚úÖ ÏÉàÎ°úÏö¥ ÏµúÍ≥† Î™®Îç∏ Í∞±Ïã†! {model_path} (Val Loss={val_loss:.4f})\")\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # ÌïôÏäµ ÏôÑÎ£å ÌõÑ Í≤∞Í≥º Ï†ÄÏû•\n",
        "    # --------------------------------------------------\n",
        "    final_model_path = f'alexnet_fold{fold_idx}_final.pth'\n",
        "    torch.save(model.state_dict(), final_model_path)\n",
        "    print(f\"\\nüíæ ÌïôÏäµ ÏôÑÎ£å! ÏµúÏ¢Ö Î™®Îç∏ Ï†ÄÏû•: {final_model_path}\")\n",
        "\n",
        "    # üîπ ÌïôÏäµ Ïù¥Î†• CSV Ï†ÄÏû•\n",
        "    import pandas as pd\n",
        "    history_df = pd.DataFrame(history)\n",
        "    history_csv = f'alexnet_fold{fold_idx}_history.csv'\n",
        "    history_df.to_csv(history_csv, index=False)\n",
        "    print(f\"üìà ÌïôÏäµ Ïù¥Î†• Ï†ÄÏû• ÏôÑÎ£å: {history_csv}\")\n",
        "\n",
        "    return model_path, history\n"
      ],
      "metadata": {
        "id": "UnMRyA9kKy2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ‚úÖ 10. Fold 2 ÌïôÏäµ ÏòàÏãú (ÏûêÎèô Ï†ÄÏû• Í∏∞Îä• Ìè¨Ìï®)\n",
        "# ============================================================\n",
        "\n",
        "# Fold Ï†ïÎ≥¥ ÏÑ§Ï†ï\n",
        "fold_info = list(kfold.split(all_drivers))[1]\n",
        "train_drivers = [all_drivers[i] for i in fold_info[0]]\n",
        "val_drivers = [all_drivers[i] for i in fold_info[1]]\n",
        "\n",
        "# Î™®Îç∏ ÌïôÏäµ Î∞è Ï†ÄÏû• Ìï®Ïàò Ïã§Ìñâ\n",
        "model_path, history = train_fold(2, train_drivers, val_drivers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsshaYu6K1yK",
        "outputId": "1dd1d65b-f4a5-4212-d835-d3ef6d4f93d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== Fold 2/5 ==========\n",
            "\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.7232, Acc 75.05% | Val Loss 1.2292, Acc 67.12%\n",
            "‚úÖ ÏÉàÎ°úÏö¥ ÏµúÍ≥† Î™®Îç∏ Í∞±Ïã†! alexnet_fold2_best.pth (Val Loss=1.2292)\n",
            "\n",
            "Epoch 2/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.2801, Acc 90.82% | Val Loss 1.1968, Acc 68.22%\n",
            "‚úÖ ÏÉàÎ°úÏö¥ ÏµúÍ≥† Î™®Îç∏ Í∞±Ïã†! alexnet_fold2_best.pth (Val Loss=1.1968)\n",
            "\n",
            "Epoch 3/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.2416, Acc 92.40% | Val Loss 1.1125, Acc 68.57%\n",
            "‚úÖ ÏÉàÎ°úÏö¥ ÏµúÍ≥† Î™®Îç∏ Í∞±Ïã†! alexnet_fold2_best.pth (Val Loss=1.1125)\n",
            "\n",
            "Epoch 4/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.2093, Acc 93.62% | Val Loss 1.7595, Acc 60.01%\n",
            "\n",
            "Epoch 5/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1955, Acc 94.15% | Val Loss 1.4873, Acc 68.82%\n",
            "üü¢ 5 epochÍπåÏßÄ ÏûÑÏãú Ï†ÄÏû• ÏôÑÎ£å ‚Üí alexnet_fold2_epoch5.pth\n",
            "\n",
            "Epoch 6/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1915, Acc 94.62% | Val Loss 1.2109, Acc 70.14%\n",
            "\n",
            "Epoch 7/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1775, Acc 94.92% | Val Loss 1.3181, Acc 72.19%\n",
            "\n",
            "Epoch 8/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1585, Acc 95.42% | Val Loss 1.7544, Acc 58.19%\n",
            "\n",
            "Epoch 9/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1559, Acc 95.57% | Val Loss 2.1921, Acc 62.01%\n",
            "\n",
            "Epoch 10/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1615, Acc 95.61% | Val Loss 1.4955, Acc 66.40%\n",
            "üü¢ 10 epochÍπåÏßÄ ÏûÑÏãú Ï†ÄÏû• ÏôÑÎ£å ‚Üí alexnet_fold2_epoch10.pth\n",
            "\n",
            "Epoch 11/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1465, Acc 96.03% | Val Loss 1.7691, Acc 63.75%\n",
            "\n",
            "Epoch 12/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1296, Acc 96.45% | Val Loss 1.4179, Acc 66.65%\n",
            "\n",
            "Epoch 13/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1440, Acc 96.25% | Val Loss 1.0150, Acc 73.49%\n",
            "‚úÖ ÏÉàÎ°úÏö¥ ÏµúÍ≥† Î™®Îç∏ Í∞±Ïã†! alexnet_fold2_best.pth (Val Loss=1.0150)\n",
            "\n",
            "Epoch 14/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1294, Acc 96.46% | Val Loss 1.5891, Acc 69.65%\n",
            "\n",
            "Epoch 15/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1171, Acc 96.89% | Val Loss 1.0978, Acc 71.07%\n",
            "üü¢ 15 epochÍπåÏßÄ ÏûÑÏãú Ï†ÄÏû• ÏôÑÎ£å ‚Üí alexnet_fold2_epoch15.pth\n",
            "\n",
            "Epoch 16/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1278, Acc 96.67% | Val Loss 1.8725, Acc 59.56%\n",
            "\n",
            "Epoch 17/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1275, Acc 96.68% | Val Loss 1.5940, Acc 65.28%\n",
            "\n",
            "Epoch 18/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1220, Acc 97.00% | Val Loss 1.7544, Acc 60.63%\n",
            "\n",
            "Epoch 19/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1150, Acc 97.02% | Val Loss 1.5768, Acc 60.43%\n",
            "\n",
            "Epoch 20/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1079, Acc 97.29% | Val Loss 2.5038, Acc 61.41%\n",
            "üü¢ 20 epochÍπåÏßÄ ÏûÑÏãú Ï†ÄÏû• ÏôÑÎ£å ‚Üí alexnet_fold2_epoch20.pth\n",
            "\n",
            "Epoch 21/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1181, Acc 97.04% | Val Loss 1.3806, Acc 71.89%\n",
            "\n",
            "Epoch 22/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1135, Acc 97.19% | Val Loss 1.3503, Acc 72.69%\n",
            "\n",
            "Epoch 23/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1128, Acc 97.15% | Val Loss 1.5349, Acc 65.68%\n",
            "\n",
            "Epoch 24/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1021, Acc 97.49% | Val Loss 1.5109, Acc 67.40%\n",
            "\n",
            "Epoch 25/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.1100, Acc 97.33% | Val Loss 2.1210, Acc 60.33%\n",
            "üü¢ 25 epochÍπåÏßÄ ÏûÑÏãú Ï†ÄÏû• ÏôÑÎ£å ‚Üí alexnet_fold2_epoch25.pth\n",
            "\n",
            "Epoch 26/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0913, Acc 97.67% | Val Loss 2.0544, Acc 61.91%\n",
            "\n",
            "Epoch 27/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0937, Acc 97.64% | Val Loss 1.1760, Acc 69.67%\n",
            "\n",
            "Epoch 28/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0688, Acc 98.18% | Val Loss 1.7151, Acc 65.78%\n",
            "\n",
            "Epoch 29/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0936, Acc 97.64% | Val Loss 1.3613, Acc 70.44%\n",
            "\n",
            "Epoch 30/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0809, Acc 98.00% | Val Loss 1.6910, Acc 64.85%\n",
            "üü¢ 30 epochÍπåÏßÄ ÏûÑÏãú Ï†ÄÏû• ÏôÑÎ£å ‚Üí alexnet_fold2_epoch30.pth\n",
            "\n",
            "Epoch 31/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0834, Acc 97.91% | Val Loss 1.2953, Acc 71.64%\n",
            "\n",
            "Epoch 32/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0851, Acc 97.88% | Val Loss 1.9727, Acc 61.01%\n",
            "\n",
            "Epoch 33/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0800, Acc 97.95% | Val Loss 1.3999, Acc 67.80%\n",
            "\n",
            "Epoch 34/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0905, Acc 98.00% | Val Loss 1.2236, Acc 72.42%\n",
            "\n",
            "Epoch 35/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0603, Acc 98.37% | Val Loss 1.5147, Acc 67.55%\n",
            "üü¢ 35 epochÍπåÏßÄ ÏûÑÏãú Ï†ÄÏû• ÏôÑÎ£å ‚Üí alexnet_fold2_epoch35.pth\n",
            "\n",
            "Epoch 36/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0773, Acc 98.15% | Val Loss 1.5456, Acc 67.00%\n",
            "\n",
            "Epoch 37/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0892, Acc 97.89% | Val Loss 1.2146, Acc 71.87%\n",
            "\n",
            "Epoch 38/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0865, Acc 97.95% | Val Loss 0.9363, Acc 76.59%\n",
            "‚úÖ ÏÉàÎ°úÏö¥ ÏµúÍ≥† Î™®Îç∏ Í∞±Ïã†! alexnet_fold2_best.pth (Val Loss=0.9363)\n",
            "\n",
            "Epoch 39/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0778, Acc 98.08% | Val Loss 1.2228, Acc 72.62%\n",
            "\n",
            "Epoch 40/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss 0.0833, Acc 97.99% | Val Loss 1.5284, Acc 68.12%\n",
            "üü¢ 40 epochÍπåÏßÄ ÏûÑÏãú Ï†ÄÏû• ÏôÑÎ£å ‚Üí alexnet_fold2_epoch40.pth\n",
            "\n",
            "üíæ ÌïôÏäµ ÏôÑÎ£å! ÏµúÏ¢Ö Î™®Îç∏ Ï†ÄÏû•: alexnet_fold2_final.pth\n",
            "üìà ÌïôÏäµ Ïù¥Î†• Ï†ÄÏû• ÏôÑÎ£å: alexnet_fold2_history.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8617ccd3-9a98-4dcb-fc8f-ec04363526ca",
        "id": "aak0oL_3KVSc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì¢ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÏòàÏ∏° ÏãúÏûë...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1246/1246 [06:30<00:00,  3.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ± ÏôÑÎ£å: /content/alexnet_fold2_submission.csv\n",
            "             img            c0            c1            c2            c3  \\\n",
            "0  img_16561.jpg  2.537672e-03  2.256016e-02  1.699504e-03  4.996450e-05   \n",
            "1  img_77002.jpg  1.628776e-03  1.781334e-05  7.400337e-05  9.857650e-01   \n",
            "2  img_88996.jpg  6.426714e-02  6.894591e-01  9.172354e-02  1.969100e-02   \n",
            "3  img_15767.jpg  5.953398e-02  1.280020e-01  1.932308e-02  1.573110e-02   \n",
            "4  img_53781.jpg  7.088267e-26  1.631518e-40  1.298115e-31  2.203908e-33   \n",
            "\n",
            "             c4        c5            c6            c7            c8  \\\n",
            "0  7.280873e-05  0.000455  1.858340e-03  6.374775e-01  4.482256e-02   \n",
            "1  4.458329e-03  0.007002  2.063563e-06  4.166032e-04  1.693458e-04   \n",
            "2  4.567990e-03  0.005871  1.872620e-02  2.959376e-02  3.614706e-02   \n",
            "3  1.148526e-02  0.010449  2.306456e-02  2.384050e-02  6.107399e-01   \n",
            "4  8.775504e-27  1.000000  1.608425e-27  7.172655e-30  1.107024e-18   \n",
            "\n",
            "             c9  \n",
            "0  2.884669e-01  \n",
            "1  4.659258e-04  \n",
            "2  3.995321e-02  \n",
            "3  9.783062e-02  \n",
            "4  1.232497e-21  \n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ‚úÖ 11. ÌÖåÏä§Ìä∏ ÏòàÏ∏° + Ï†úÏ∂ú CSV ÏÉùÏÑ±\n",
        "# ============================================================\n",
        "print(\"\\nüì¢ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÏòàÏ∏° ÏãúÏûë...\")\n",
        "\n",
        "test_dataset = DriverDataset(test_dir, driver_df, [], transform_eval, is_test=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# ‚úÖ timm ÎåÄÏã† torchvisionÏúºÎ°ú Î≥ÄÍ≤Ω\n",
        "from torchvision import models\n",
        "\n",
        "model = models.alexnet(pretrained=False)\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "\n",
        "# ‚úÖ ÌïôÏäµÎêú ÌååÎùºÎØ∏ÌÑ∞ Î°úÎìú\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "predictions, filenames = [], []\n",
        "with torch.no_grad():\n",
        "    for images, names in tqdm(test_loader, desc=\"Predicting\"):\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        predictions.append(probs.cpu().numpy())\n",
        "        filenames.extend(names)\n",
        "\n",
        "preds = np.vstack(predictions)\n",
        "class_cols = [f'c{i}' for i in range(num_classes)]\n",
        "submission = pd.DataFrame(preds, columns=class_cols)\n",
        "submission.insert(0, 'img', filenames)\n",
        "\n",
        "submission_file = '/content/alexnet_fold2_submission.csv'\n",
        "submission.to_csv(submission_file, index=False)\n",
        "print(f\"\\n‚úÖ Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ± ÏôÑÎ£å: {submission_file}\")\n",
        "print(submission.head())\n"
      ]
    }
  ]
}