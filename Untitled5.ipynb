{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Im-jDiOt/DeepLearning-Term-Proj/blob/feature-inception/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train í´ë” ì••ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì´ ì‘ì—…ì€ 1~2ì‹œê°„ ì´ìƒ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë©ˆì¶”ì§€ ë§ˆì„¸ìš”!)\")\n",
        "\n",
        "!zip -r -q \"/content/drive/MyDrive/Colab Notebooks/train.zip\" \"/content/drive/MyDrive/Colab Notebooks/train\"\n",
        "\n",
        "print(\"train.zip ìƒì„± ì™„ë£Œ!\")\n",
        "print(\"test í´ë” ì••ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì´ ì‘ì—…ì€ 1~2ì‹œê°„ ì´ìƒ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë©ˆì¶”ì§€ ë§ˆì„¸ìš”!)\")\n",
        "\n",
        "!zip -r -q \"/content/drive/MyDrive/Colab Notebooks/test.zip\" \"/content/drive/MyDrive/Colab Notebooks/test\"\n",
        "\n",
        "print(\"test.zip ìƒì„± ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaRNP_SCKJRl",
        "outputId": "20bd1006-1c23-4a8a-c765-5f876fb6b430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train í´ë” ì••ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì´ ì‘ì—…ì€ 1~2ì‹œê°„ ì´ìƒ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë©ˆì¶”ì§€ ë§ˆì„¸ìš”!)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBYrCzXvBVMH",
        "outputId": "c4cf7d57-5ac1-4074-fdc5-9aee919eb728"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# í›ˆë ¨ ì‹œì‘ ì „, Colab ë¡œì»¬ ë””ìŠ¤í¬ë¡œ ë°ì´í„° ë³µì‚¬ (ì•½ 2~3ë¶„ ì†Œìš”)\n",
        "print(\"ì••ì¶• í‘¸ëŠ” ì¤‘... (train.zip)\")\n",
        "!unzip -q \"/content/drive/MyDrive/Colab Notebooks/train.zip\" -d /content/\n",
        "\n",
        "print(\"ì••ì¶• í‘¸ëŠ” ì¤‘... (test.zip)\")\n",
        "!unzip -q \"/content/drive/MyDrive/Colab Notebooks/test.zip\" -d /content/\n",
        "\n",
        "print(\"ë°ì´í„° ë³µì‚¬ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWDhCJwQBYZI",
        "outputId": "6bd7effb-1396-4146-da21-3320b2648525"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train í´ë” ì••ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì´ ì‘ì—…ì€ 1~2ì‹œê°„ ì´ìƒ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë©ˆì¶”ì§€ ë§ˆì„¸ìš”!)\n",
            "\n",
            "\n",
            "zip error: Interrupted (aborting)\n",
            "train.zip ìƒì„± ì™„ë£Œ!\n",
            "test í´ë” ì••ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì´ ì‘ì—…ì€ 1~2ì‹œê°„ ì´ìƒ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë©ˆì¶”ì§€ ë§ˆì„¸ìš”!)\n",
            "test.zip ìƒì„± ì™„ë£Œ!\n",
            "ì••ì¶• í‘¸ëŠ” ì¤‘... (train.zip)\n",
            "unzip:  cannot find or open /content/drive/MyDrive/Colab Notebooks/train.zip, /content/drive/MyDrive/Colab Notebooks/train.zip.zip or /content/drive/MyDrive/Colab Notebooks/train.zip.ZIP.\n",
            "ì••ì¶• í‘¸ëŠ” ì¤‘... (test.zip)\n",
            "ë°ì´í„° ë³µì‚¬ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode # [ìˆ˜ì •] import ë°©ì‹ ë³€ê²½\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "# --- 1. í™˜ê²½ ì„¤ì • (Configuration) ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# ë°ì´í„° ê²½ë¡œ\n",
        "DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
        "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
        "CSV_PATH = os.path.join(DATA_DIR, \"driver_imgs_list.csv\")\n",
        "SUBMISSION_FILE = \"submission_kfold_resnet50.csv\"\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 16\n",
        "IMG_SIZE = 128\n",
        "EPOCHS_PHASE1 = 5   # (ì–¼ë¦¬ ìŠ¤íƒ‘í•‘ì´ ìˆìœ¼ë¯€ë¡œ, ìµœëŒ€ì¹˜ë¡œ ì„¤ì •)\n",
        "# EPOCHS_PHASE2 = 15  # [ì„ì‹œ ì œê±°]\n",
        "LR_PHASE1 = 1e-3\n",
        "# LR_PHASE2 = 1e-5  # [ì„ì‹œ ì œê±°]\n",
        "DROPOUT_P = 0.3\n",
        "\n",
        "# --- K-Fold êµì°¨ ê²€ì¦ ì„¤ì • ---\n",
        "N_FOLDS = 5\n",
        "BASE_SEED = 42\n",
        "\n",
        "random.seed(BASE_SEED)\n",
        "np.random.seed(BASE_SEED)\n",
        "torch.manual_seed(BASE_SEED)\n",
        "\n",
        "\n",
        "# --- [ìˆ˜ì •] 2. EarlyStopping í´ë˜ìŠ¤ ì •ì˜ ---\n",
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Validation lossê°€ patience íšŸìˆ˜ë§Œí¼ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í›ˆë ¨ì„ ì¡°ê¸° ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): Validation lossê°€ ê°œì„ ë˜ì§€ ì•Šì•„ë„ ê¸°ë‹¤ë¦´ ì—í¬í¬ ìˆ˜\n",
        "            verbose (bool): ì–¼ë¦¬ ìŠ¤íƒ‘í•‘ ë©”ì‹œì§€ ì¶œë ¥ ì—¬ë¶€\n",
        "            delta (float): ê°œì„ ìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ loss ê°ì†ŒëŸ‰\n",
        "            path (str): ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì €ì¥í•  ê²½ë¡œ\n",
        "            trace_func (function): ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        # [ìˆ˜ì •] np.Inf ëŒ€ì‹  float('inf')ë¥¼ ì‚¬ìš© (NumPy 2.0 í˜¸í™˜)\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            # ê°œì„ ë˜ì§€ ì•ŠìŒ\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            # ê°œì„ ë¨\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''ìµœì € val_lossë¥¼ ê¸°ë¡í•œ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "# --- 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦ê°• (Transforms) ---\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC), # [ìˆ˜ì •] import ì˜¤ë¥˜ í•´ê²°\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomPerspective(distortion_scale=0.1, p=0.2),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC), # [ìˆ˜ì •] import ì˜¤ë¥˜ í•´ê²°\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "# --- 4. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ (Custom Dataset) ---\n",
        "class StateFarmDataset(Dataset):\n",
        "    \"\"\" í›ˆë ¨ ë° ê²€ì¦ìš© ë°ì´í„°ì…‹ (CSV ê¸°ë°˜, ìš´ì „ì ë¶„ë¦¬ìš©) \"\"\"\n",
        "    def __init__(self, df, root_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_to_int = {f\"c{i}\": i for i in range(NUM_CLASSES)}\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        class_name = row['classname']\n",
        "        img_name = row['img']\n",
        "        img_path = os.path.join(self.root_dir, class_name, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.class_to_int[class_name]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class StateFarmTestDataset(Dataset):\n",
        "    \"\"\" í…ŒìŠ¤íŠ¸(ì œì¶œ)ìš© ë°ì´í„°ì…‹ (os.listdir ìˆ˜ì •ë³¸) \"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        try:\n",
        "            all_files = os.listdir(root_dir)\n",
        "            self.img_paths = [os.path.join(root_dir, f) for f in all_files if f.endswith('.jpg')]\n",
        "            print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹: {len(self.img_paths)}ê°œ íŒŒì¼ ì°¾ìŒ.\")\n",
        "        except OSError as e:\n",
        "            print(f\"ERROR: í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬({root_dir}) ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
        "            self.img_paths = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img_name = os.path.basename(img_path)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_name\n",
        "\n",
        "# --- 5. ëª¨ë¸ ì •ì˜ (ì „ì´ í•™ìŠµ ResNet-50) ---\n",
        "def build_transfer_resnet50(num_classes=NUM_CLASSES, dropout_p=DROPOUT_P, pretrained=True):\n",
        "    weights = models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "    model = models.resnet50(weights=weights)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(p=dropout_p),\n",
        "        nn.Linear(num_ftrs, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- 6. í•™ìŠµ ë° ê²€ì¦ ë£¨í”„ (Training & Validation) ---\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device, fold_num, epoch_num, total_epochs, phase_name):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    desc = f\"Fold {fold_num} | {phase_name} | Epoch {epoch_num}/{total_epochs} (Train)\"\n",
        "    for images, labels in tqdm(loader, desc=desc):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "def validate(model, loader, criterion, device, fold_num, epoch_num, total_epochs, phase_name):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    desc = f\"Fold {fold_num} | {phase_name} | Epoch {epoch_num}/{total_epochs} (Val)\"\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=desc):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "# --- 7. [ìˆ˜ì •] ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ (Fine-Tuning ì„ì‹œ ì œê±°) ---\n",
        "\n",
        "def main():\n",
        "    # --- ë°ì´í„° ì¤€ë¹„ ---\n",
        "    print(\"... ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘ ...\")\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "    drivers = df['subject'].unique() # ëª¨ë“  ìš´ì „ì\n",
        "\n",
        "    # --- K-Fold ì„¤ì • ---\n",
        "    kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=BASE_SEED)\n",
        "\n",
        "    all_fold_losses = [] # ëª¨ë“  í´ë“œì˜ (ìµœì¢… ì†ì‹¤)ì„ ì €ì¥\n",
        "\n",
        "    # ====================================================\n",
        "    # K-Fold í›ˆë ¨ ë£¨í”„ ì‹œì‘\n",
        "    # ====================================================\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(drivers), 1):\n",
        "\n",
        "        # --- Foldë³„ ì‹œë“œ ê³ ì • ---\n",
        "        seed = BASE_SEED + fold\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        if DEVICE == 'cuda':\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "        # --- ìš´ì „ì ë¶„ë¦¬ ---\n",
        "        train_drivers = drivers[train_idx]\n",
        "        val_drivers   = drivers[val_idx]\n",
        "\n",
        "        train_df = df[df['subject'].isin(train_drivers)]\n",
        "        val_df   = df[df['subject'].isin(val_drivers)]\n",
        "\n",
        "        print(f\"\\n===== Fold {fold}/{N_FOLDS} =====\")\n",
        "        print(f\"Train drivers: {len(train_drivers)}ëª… | Val drivers: {len(val_drivers)}ëª…\")\n",
        "        print(f\"Train images: {len(train_df)} | Val images: {len(val_df)}\")\n",
        "\n",
        "\n",
        "        # --- [ì¶”ê°€] ì´ ë‘ ì¤„ì˜ ì½”ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤! ---\n",
        "        train_dataset = StateFarmDataset(train_df, TRAIN_DIR, transform=train_transforms)\n",
        "        val_dataset   = StateFarmDataset(val_df, TRAIN_DIR, transform=val_test_transforms)\n",
        "        # --- ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ ---\n",
        "\n",
        "        # --- ë°ì´í„°ì…‹ ë° ë¡œë” ---\n",
        "        # [ìˆ˜ì •] num_workers=0 (Colab ë©ˆì¶¤ í˜„ìƒ í•´ê²°)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
        "        val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "        # --- ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜ ---\n",
        "        model = build_transfer_resnet50(pretrained=True).to(DEVICE)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        BEST_MODEL_PATH = f\"best_model_fold_{fold}.pth\"\n",
        "\n",
        "        # --- [ìˆ˜ì •] Early Stopping ì´ˆê¸°í™” (Phase 1ìš©) ---\n",
        "        early_stopping_p1 = EarlyStopping(patience=3, verbose=True, path=BEST_MODEL_PATH)\n",
        "\n",
        "        # --- í•™ìŠµ ë‹¨ê³„ 1: íŠ¹ì§• ì¶”ì¶œ (ì´ê²ƒë§Œ ì‹¤í–‰) ---\n",
        "        print(f\"\\n--- [Fold {fold}] í•™ìŠµ ë‹¨ê³„ 1: Feature Extraction ì‹œì‘ ---\")\n",
        "        for name, param in model.named_parameters():\n",
        "            if \"fc\" not in name:\n",
        "                param.requires_grad = False\n",
        "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR_PHASE1)\n",
        "\n",
        "        for epoch in range(1, EPOCHS_PHASE1 + 1):\n",
        "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, fold, epoch, EPOCHS_PHASE1, \"Phase 1\")\n",
        "            val_loss, val_acc = validate(model, val_loader, criterion, DEVICE, fold, epoch, EPOCHS_PHASE1, \"Phase 1\")\n",
        "            print(f\"  Fold {fold}, Phase 1, Epoch {epoch}: Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "            early_stopping_p1(val_loss, model)\n",
        "            if early_stopping_p1.early_stop:\n",
        "                print(\"Early stopping (Phase 1)\")\n",
        "                break\n",
        "\n",
        "        # --- [ì„ì‹œ ì œê±°] í•™ìŠµ ë‹¨ê³„ 2: ë¯¸ì„¸ ì¡°ì • (Fine-Tuning) ---\n",
        "        #\n",
        "        # print(f\"\\n--- [Fold {fold}] í•™ìŠµ ë‹¨ê³„ 2: Fine-Tuning ì‹œì‘ ---\")\n",
        "        # model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
        "        # for param in model.parameters():\n",
        "        #     param.requires_grad = True\n",
        "        # optimizer = optim.AdamW(model.parameters(), lr=LR_PHASE2)\n",
        "        # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_PHASE2, eta_min=1e-7)\n",
        "        # early_stopping_p2 = EarlyStopping(patience=5, verbose=True, path=BEST_MODEL_PATH)\n",
        "        # early_stopping_p2.val_loss_min = early_stopping_p1.val_loss_min\n",
        "        # early_stopping_p2.best_score = -early_stopping_p1.val_loss_min\n",
        "        #\n",
        "        # for epoch in range(1, EPOCHS_PHASE2 + 1):\n",
        "        #     train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, fold, epoch, EPOCHS_PHASE2, \"Phase 2\")\n",
        "        #     val_loss, val_acc = validate(model, val_loader, criterion, DEVICE, fold, epoch, EPOCHS_PHASE2, \"Phase 2\")\n",
        "        #     scheduler.step()\n",
        "        #     print(f\"  Fold {fold}, Phase 2, Epoch {epoch}: Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        #     early_stopping_p2(val_loss, model)\n",
        "        #     if early_stopping_p2.early_stop:\n",
        "        #         print(\"Early stopping (Phase 2)\")\n",
        "        #         break\n",
        "        #\n",
        "        # final_best_loss = early_stopping_p2.val_loss_min\n",
        "        # --- Fine-Tuning ë¶€ë¶„ ë ---\n",
        "\n",
        "\n",
        "        # [ìˆ˜ì •] Phase 1ì˜ ìµœì¢… ê²°ê³¼ë¡œ ì ìˆ˜ ì§‘ê³„\n",
        "        final_best_loss = early_stopping_p1.val_loss_min\n",
        "        print(f\"ğŸ¯ Fold {fold} ì™„ë£Œ! Best Validation Loss: {final_best_loss:.4f}\")\n",
        "        all_fold_losses.append(final_best_loss)\n",
        "\n",
        "    # ====================================================\n",
        "    # K-Fold í›ˆë ¨ ë£¨í”„ ì¢…ë£Œ\n",
        "    # ====================================================\n",
        "\n",
        "    print(\"\\n\\n==================== K-Fold í›ˆë ¨ ìš”ì•½ ====================\")\n",
        "    for i, loss in enumerate(all_fold_losses):\n",
        "        print(f\"Fold {i+1} Best Val Loss: {loss:.4f}\")\n",
        "\n",
        "    print(f\"\\nğŸ”¥ K-Fold í‰ê·  Val Loss: {np.mean(all_fold_losses):.4f} Â± {np.std(all_fold_losses):.4f}\")\n",
        "\n",
        "\n",
        "    # --- 8. ì˜ˆì¸¡ (Inference) ë° K-Fold ì•™ìƒë¸” ---\n",
        "    print(\"\\n\\n\" + \"=\" * 70)\n",
        "    print(\"ğŸ”® 5-Fold ì•™ìƒë¸” ì˜ˆì¸¡\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # (1) í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ë¡œë”\n",
        "    test_dataset = StateFarmTestDataset(TEST_DIR, transform=val_test_transforms)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0) # [ìˆ˜ì •] num_workers=0\n",
        "\n",
        "    # (2) ê° Fold ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    all_fold_probs = []\n",
        "    all_img_names = []\n",
        "\n",
        "    for fold in range(1, N_FOLDS + 1):\n",
        "        model_path = f\"best_model_fold_{fold}.pth\"\n",
        "        print(f\"\\nğŸ“ Fold {fold} ëª¨ë¸ ì˜ˆì¸¡ ì¤‘... ({model_path})\")\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"WARNING: {model_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì´ FoldëŠ” ì•™ìƒë¸”ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "        model = build_transfer_resnet50(pretrained=False).to(DEVICE)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        fold_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, img_names in tqdm(test_loader, desc=f'Predicting Fold {fold}'):\n",
        "                images = images.to(DEVICE)\n",
        "                outputs = model(images)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                fold_probs.append(probs.cpu().numpy())\n",
        "\n",
        "                if fold == 1:\n",
        "                    all_img_names.extend(img_names)\n",
        "\n",
        "        all_fold_probs.append(np.concatenate(fold_probs, axis=0))\n",
        "\n",
        "    # --- ì•™ìƒë¸” (í‰ê· ) ---\n",
        "    if not all_fold_probs:\n",
        "        print(\"ERROR: í›ˆë ¨ëœ ëª¨ë¸ì´ í•˜ë‚˜ë„ ì—†ì–´ ì˜ˆì¸¡ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n... ëª¨ë“  Foldì˜ ì˜ˆì¸¡ í™•ë¥ ì„ í‰ê· (ì•™ìƒë¸”) ì¤‘ ...\")\n",
        "    final_probs = np.mean(all_fold_probs, axis=0)\n",
        "\n",
        "    # --- ì œì¶œ íŒŒì¼ ìƒì„± ---\n",
        "    submission_df = pd.DataFrame(final_probs, columns=[f\"c{i}\" for i in range(NUM_CLASSES)])\n",
        "    submission_df['img'] = all_img_names\n",
        "    submission_df = submission_df[['img'] + [f\"c{i}\" for i in range(NUM_CLASSES)]]\n",
        "\n",
        "    submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
        "    print(f\"\\nâœ… K-Fold ì•™ìƒë¸” ì œì¶œ íŒŒì¼ '{SUBMISSION_FILE}' ìƒì„± ì™„ë£Œ!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "8104fbe9-8600-4d18-e350-75246602a40f",
        "id": "u7i7Wl9J5uBa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "... ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘ ...\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "Train drivers: 20ëª… | Val drivers: 6ëª…\n",
            "Train images: 17446 | Val images: 4978\n",
            "\n",
            "--- [Fold 1] í•™ìŠµ ë‹¨ê³„ 1: Feature Extraction ì‹œì‘ ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold 1 | Phase 1 | Epoch 1/5 (Train):   0%|          | 0/1091 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/train/c1/img_93448.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-589297172.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-589297172.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS_PHASE1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS_PHASE1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Phase 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS_PHASE1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Phase 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Fold {fold}, Phase 1, Epoch {epoch}: Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-589297172.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optimizer, device, fold_num, epoch_num, total_epochs, phase_name)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Fold {fold_num} | {phase_name} | Epoch {epoch_num}/{total_epochs} (Train)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-589297172.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3513\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3514\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3515\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train/c1/img_93448.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode # [ìˆ˜ì •] import ë°©ì‹ ë³€ê²½\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "# --- 1. í™˜ê²½ ì„¤ì • (Configuration) ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# ë°ì´í„° ê²½ë¡œ\n",
        "DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
        "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
        "CSV_PATH = os.path.join(DATA_DIR, \"driver_imgs_list.csv\")\n",
        "SUBMISSION_FILE = \"submission_kfold_resnet50.csv\"\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 16\n",
        "IMG_SIZE = 128\n",
        "EPOCHS_PHASE1 = 5   # (ì–¼ë¦¬ ìŠ¤íƒ‘í•‘ì´ ìˆìœ¼ë¯€ë¡œ, ìµœëŒ€ì¹˜ë¡œ ì„¤ì •)\n",
        "# EPOCHS_PHASE2 = 15  # [ì„ì‹œ ì œê±°]\n",
        "LR_PHASE1 = 1e-3\n",
        "# LR_PHASE2 = 1e-5  # [ì„ì‹œ ì œê±°]\n",
        "DROPOUT_P = 0.3\n",
        "\n",
        "# --- K-Fold êµì°¨ ê²€ì¦ ì„¤ì • ---\n",
        "N_FOLDS = 5\n",
        "BASE_SEED = 42\n",
        "\n",
        "random.seed(BASE_SEED)\n",
        "np.random.seed(BASE_SEED)\n",
        "torch.manual_seed(BASE_SEED)\n",
        "\n",
        "\n",
        "# --- [ìˆ˜ì •] 2. EarlyStopping í´ë˜ìŠ¤ ì •ì˜ ---\n",
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Validation lossê°€ patience íšŸìˆ˜ë§Œí¼ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í›ˆë ¨ì„ ì¡°ê¸° ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): Validation lossê°€ ê°œì„ ë˜ì§€ ì•Šì•„ë„ ê¸°ë‹¤ë¦´ ì—í¬í¬ ìˆ˜\n",
        "            verbose (bool): ì–¼ë¦¬ ìŠ¤íƒ‘í•‘ ë©”ì‹œì§€ ì¶œë ¥ ì—¬ë¶€\n",
        "            delta (float): ê°œì„ ìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ loss ê°ì†ŒëŸ‰\n",
        "            path (str): ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì €ì¥í•  ê²½ë¡œ\n",
        "            trace_func (function): ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        # [ìˆ˜ì •] np.Inf ëŒ€ì‹  float('inf')ë¥¼ ì‚¬ìš© (NumPy 2.0 í˜¸í™˜)\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            # ê°œì„ ë˜ì§€ ì•ŠìŒ\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            # ê°œì„ ë¨\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''ìµœì € val_lossë¥¼ ê¸°ë¡í•œ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "# --- 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦ê°• (Transforms) ---\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC), # [ìˆ˜ì •] import ì˜¤ë¥˜ í•´ê²°\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomPerspective(distortion_scale=0.1, p=0.2),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC), # [ìˆ˜ì •] import ì˜¤ë¥˜ í•´ê²°\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "# --- 4. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ (Custom Dataset) ---\n",
        "class StateFarmDataset(Dataset):\n",
        "    \"\"\" í›ˆë ¨ ë° ê²€ì¦ìš© ë°ì´í„°ì…‹ (CSV ê¸°ë°˜, ìš´ì „ì ë¶„ë¦¬ìš©) \"\"\"\n",
        "    def __init__(self, df, root_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_to_int = {f\"c{i}\": i for i in range(NUM_CLASSES)}\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        class_name = row['classname']\n",
        "        img_name = row['img']\n",
        "        img_path = os.path.join(self.root_dir, class_name, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.class_to_int[class_name]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class StateFarmTestDataset(Dataset):\n",
        "    \"\"\" í…ŒìŠ¤íŠ¸(ì œì¶œ)ìš© ë°ì´í„°ì…‹ (os.listdir ìˆ˜ì •ë³¸) \"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        try:\n",
        "            all_files = os.listdir(root_dir)\n",
        "            self.img_paths = [os.path.join(root_dir, f) for f in all_files if f.endswith('.jpg')]\n",
        "            print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹: {len(self.img_paths)}ê°œ íŒŒì¼ ì°¾ìŒ.\")\n",
        "        except OSError as e:\n",
        "            print(f\"ERROR: í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬({root_dir}) ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
        "            self.img_paths = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img_name = os.path.basename(img_path)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_name\n",
        "\n",
        "# --- 5. ëª¨ë¸ ì •ì˜ (ì „ì´ í•™ìŠµ ResNet-50) ---\n",
        "def build_transfer_resnet50(num_classes=NUM_CLASSES, dropout_p=DROPOUT_P, pretrained=True):\n",
        "    weights = models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "    model = models.resnet50(weights=weights)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(p=dropout_p),\n",
        "        nn.Linear(num_ftrs, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- 6. í•™ìŠµ ë° ê²€ì¦ ë£¨í”„ (Training & Validation) ---\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device, fold_num, epoch_num, total_epochs, phase_name):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    desc = f\"Fold {fold_num} | {phase_name} | Epoch {epoch_num}/{total_epochs} (Train)\"\n",
        "    for images, labels in tqdm(loader, desc=desc):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "def validate(model, loader, criterion, device, fold_num, epoch_num, total_epochs, phase_name):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    desc = f\"Fold {fold_num} | {phase_name} | Epoch {epoch_num}/{total_epochs} (Val)\"\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=desc):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "# --- 7. [ìˆ˜ì •] ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ (Fine-Tuning ì„ì‹œ ì œê±°) ---\n",
        "\n",
        "def main():\n",
        "    # --- ë°ì´í„° ì¤€ë¹„ ---\n",
        "    print(\"... ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘ ...\")\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "    drivers = df['subject'].unique() # ëª¨ë“  ìš´ì „ì\n",
        "\n",
        "    # --- K-Fold ì„¤ì • ---\n",
        "    kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=BASE_SEED)\n",
        "\n",
        "    all_fold_losses = [] # ëª¨ë“  í´ë“œì˜ (ìµœì¢… ì†ì‹¤)ì„ ì €ì¥\n",
        "\n",
        "    # ====================================================\n",
        "    # K-Fold í›ˆë ¨ ë£¨í”„ ì‹œì‘\n",
        "    # ====================================================\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(drivers), 1):\n",
        "\n",
        "        # --- Foldë³„ ì‹œë“œ ê³ ì • ---\n",
        "        seed = BASE_SEED + fold\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        if DEVICE == 'cuda':\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "        # --- ìš´ì „ì ë¶„ë¦¬ ---\n",
        "        train_drivers = drivers[train_idx]\n",
        "        val_drivers   = drivers[val_idx]\n",
        "\n",
        "        train_df = df[df['subject'].isin(train_drivers)]\n",
        "        val_df   = df[df['subject'].isin(val_drivers)]\n",
        "\n",
        "        print(f\"\\n===== Fold {fold}/{N_FOLDS} =====\")\n",
        "        print(f\"Train drivers: {len(train_drivers)}ëª… | Val drivers: {len(val_drivers)}ëª…\")\n",
        "        print(f\"Train images: {len(train_df)} | Val images: {len(val_df)}\")\n",
        "\n",
        "\n",
        "        # --- [ì¶”ê°€] ì´ ë‘ ì¤„ì˜ ì½”ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤! ---\n",
        "        train_dataset = StateFarmDataset(train_df, TRAIN_DIR, transform=train_transforms)\n",
        "        val_dataset   = StateFarmDataset(val_df, TRAIN_DIR, transform=val_test_transforms)\n",
        "        # --- ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ ---\n",
        "\n",
        "        # --- ë°ì´í„°ì…‹ ë° ë¡œë” ---\n",
        "        # [ìˆ˜ì •] num_workers=0 (Colab ë©ˆì¶¤ í˜„ìƒ í•´ê²°)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
        "        val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "        # --- ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜ ---\n",
        "        model = build_transfer_resnet50(pretrained=True).to(DEVICE)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        BEST_MODEL_PATH = f\"best_model_fold_{fold}.pth\"\n",
        "\n",
        "        # --- [ìˆ˜ì •] Early Stopping ì´ˆê¸°í™” (Phase 1ìš©) ---\n",
        "        early_stopping_p1 = EarlyStopping(patience=3, verbose=True, path=BEST_MODEL_PATH)\n",
        "\n",
        "        # --- í•™ìŠµ ë‹¨ê³„ 1: íŠ¹ì§• ì¶”ì¶œ (ì´ê²ƒë§Œ ì‹¤í–‰) ---\n",
        "        print(f\"\\n--- [Fold {fold}] í•™ìŠµ ë‹¨ê³„ 1: Feature Extraction ì‹œì‘ ---\")\n",
        "        for name, param in model.named_parameters():\n",
        "            if \"fc\" not in name:\n",
        "                param.requires_grad = False\n",
        "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR_PHASE1)\n",
        "\n",
        "        for epoch in range(1, EPOCHS_PHASE1 + 1):\n",
        "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, fold, epoch, EPOCHS_PHASE1, \"Phase 1\")\n",
        "            val_loss, val_acc = validate(model, val_loader, criterion, DEVICE, fold, epoch, EPOCHS_PHASE1, \"Phase 1\")\n",
        "            print(f\"  Fold {fold}, Phase 1, Epoch {epoch}: Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "            early_stopping_p1(val_loss, model)\n",
        "            if early_stopping_p1.early_stop:\n",
        "                print(\"Early stopping (Phase 1)\")\n",
        "                break\n",
        "\n",
        "        # --- [ì„ì‹œ ì œê±°] í•™ìŠµ ë‹¨ê³„ 2: ë¯¸ì„¸ ì¡°ì • (Fine-Tuning) ---\n",
        "        #\n",
        "        # print(f\"\\n--- [Fold {fold}] í•™ìŠµ ë‹¨ê³„ 2: Fine-Tuning ì‹œì‘ ---\")\n",
        "        # model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
        "        # for param in model.parameters():\n",
        "        #     param.requires_grad = True\n",
        "        # optimizer = optim.AdamW(model.parameters(), lr=LR_PHASE2)\n",
        "        # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_PHASE2, eta_min=1e-7)\n",
        "        # early_stopping_p2 = EarlyStopping(patience=5, verbose=True, path=BEST_MODEL_PATH)\n",
        "        # early_stopping_p2.val_loss_min = early_stopping_p1.val_loss_min\n",
        "        # early_stopping_p2.best_score = -early_stopping_p1.val_loss_min\n",
        "        #\n",
        "        # for epoch in range(1, EPOCHS_PHASE2 + 1):\n",
        "        #     train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, fold, epoch, EPOCHS_PHASE2, \"Phase 2\")\n",
        "        #     val_loss, val_acc = validate(model, val_loader, criterion, DEVICE, fold, epoch, EPOCHS_PHASE2, \"Phase 2\")\n",
        "        #     scheduler.step()\n",
        "        #     print(f\"  Fold {fold}, Phase 2, Epoch {epoch}: Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        #     early_stopping_p2(val_loss, model)\n",
        "        #     if early_stopping_p2.early_stop:\n",
        "        #         print(\"Early stopping (Phase 2)\")\n",
        "        #         break\n",
        "        #\n",
        "        # final_best_loss = early_stopping_p2.val_loss_min\n",
        "        # --- Fine-Tuning ë¶€ë¶„ ë ---\n",
        "\n",
        "\n",
        "        # [ìˆ˜ì •] Phase 1ì˜ ìµœì¢… ê²°ê³¼ë¡œ ì ìˆ˜ ì§‘ê³„\n",
        "        final_best_loss = early_stopping_p1.val_loss_min\n",
        "        print(f\"ğŸ¯ Fold {fold} ì™„ë£Œ! Best Validation Loss: {final_best_loss:.4f}\")\n",
        "        all_fold_losses.append(final_best_loss)\n",
        "\n",
        "    # ====================================================\n",
        "    # K-Fold í›ˆë ¨ ë£¨í”„ ì¢…ë£Œ\n",
        "    # ====================================================\n",
        "\n",
        "    print(\"\\n\\n==================== K-Fold í›ˆë ¨ ìš”ì•½ ====================\")\n",
        "    for i, loss in enumerate(all_fold_losses):\n",
        "        print(f\"Fold {i+1} Best Val Loss: {loss:.4f}\")\n",
        "\n",
        "    print(f\"\\nğŸ”¥ K-Fold í‰ê·  Val Loss: {np.mean(all_fold_losses):.4f} Â± {np.std(all_fold_losses):.4f}\")\n",
        "\n",
        "\n",
        "    # --- 8. ì˜ˆì¸¡ (Inference) ë° K-Fold ì•™ìƒë¸” ---\n",
        "    print(\"\\n\\n\" + \"=\" * 70)\n",
        "    print(\"ğŸ”® 5-Fold ì•™ìƒë¸” ì˜ˆì¸¡\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # (1) í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ë¡œë”\n",
        "    test_dataset = StateFarmTestDataset(TEST_DIR, transform=val_test_transforms)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0) # [ìˆ˜ì •] num_workers=0\n",
        "\n",
        "    # (2) ê° Fold ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    all_fold_probs = []\n",
        "    all_img_names = []\n",
        "\n",
        "    for fold in range(1, N_FOLDS + 1):\n",
        "        model_path = f\"best_model_fold_{fold}.pth\"\n",
        "        print(f\"\\nğŸ“ Fold {fold} ëª¨ë¸ ì˜ˆì¸¡ ì¤‘... ({model_path})\")\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"WARNING: {model_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì´ FoldëŠ” ì•™ìƒë¸”ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "        model = build_transfer_resnet50(pretrained=False).to(DEVICE)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        fold_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, img_names in tqdm(test_loader, desc=f'Predicting Fold {fold}'):\n",
        "                images = images.to(DEVICE)\n",
        "                outputs = model(images)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                fold_probs.append(probs.cpu().numpy())\n",
        "\n",
        "                if fold == 1:\n",
        "                    all_img_names.extend(img_names)\n",
        "\n",
        "        all_fold_probs.append(np.concatenate(fold_probs, axis=0))\n",
        "\n",
        "    # --- ì•™ìƒë¸” (í‰ê· ) ---\n",
        "    if not all_fold_probs:\n",
        "        print(\"ERROR: í›ˆë ¨ëœ ëª¨ë¸ì´ í•˜ë‚˜ë„ ì—†ì–´ ì˜ˆì¸¡ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n... ëª¨ë“  Foldì˜ ì˜ˆì¸¡ í™•ë¥ ì„ í‰ê· (ì•™ìƒë¸”) ì¤‘ ...\")\n",
        "    final_probs = np.mean(all_fold_probs, axis=0)\n",
        "\n",
        "    # --- ì œì¶œ íŒŒì¼ ìƒì„± ---\n",
        "    submission_df = pd.DataFrame(final_probs, columns=[f\"c{i}\" for i in range(NUM_CLASSES)])\n",
        "    submission_df['img'] = all_img_names\n",
        "    submission_df = submission_df[['img'] + [f\"c{i}\" for i in range(NUM_CLASSES)]]\n",
        "\n",
        "    submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
        "    print(f\"\\nâœ… K-Fold ì•™ìƒë¸” ì œì¶œ íŒŒì¼ '{SUBMISSION_FILE}' ìƒì„± ì™„ë£Œ!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "lE54B0IC1mD9",
        "outputId": "17d3cb1c-390e-4563-fd85-e058eab62431"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "... ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘ ...\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "Train drivers: 20ëª… | Val drivers: 6ëª…\n",
            "Train images: 17446 | Val images: 4978\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 177MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- [Fold 1] í•™ìŠµ ë‹¨ê³„ 1: Feature Extraction ì‹œì‘ ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold 1 | Phase 1 | Epoch 1/5 (Train):   1%|          | 10/1091 [02:33<4:35:55, 15.32s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1449509952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1449509952.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS_PHASE1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS_PHASE1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Phase 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS_PHASE1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Phase 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Fold {fold}, Phase 1, Epoch {epoch}: Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1449509952.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optimizer, device, fold_num, epoch_num, total_epochs, phase_name)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Fold {fold_num} | {phase_name} | Epoch {epoch_num}/{total_epochs} (Train)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1449509952.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3522\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3524\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import random # [ì¶”ê°€]\n",
        "from sklearn.model_selection import train_test_split, KFold # [KFold ì¶”ê°€]\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "# --- 1. í™˜ê²½ ì„¤ì • (Configuration) ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# ë°ì´í„° ê²½ë¡œ\n",
        "DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
        "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
        "CSV_PATH = os.path.join(DATA_DIR, \"driver_imgs_list.csv\")\n",
        "SUBMISSION_FILE = \"submission_kfold_resnet50.csv\"\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 16  # (VGG, ResNet ë“± ë¬´ê±°ìš´ ëª¨ë¸ì„ ìœ„í•´ 16ìœ¼ë¡œ ê¶Œì¥)\n",
        "IMG_SIZE = 128\n",
        "EPOCHS_PHASE1 = 5   # (ì–¼ë¦¬ ìŠ¤íƒ‘í•‘ì´ ìˆìœ¼ë¯€ë¡œ, ìµœëŒ€ì¹˜ë¡œ ì„¤ì •)\n",
        "EPOCHS_PHASE2 = 10  # (ì–¼ë¦¬ ìŠ¤íƒ‘í•‘ì´ ìˆìœ¼ë¯€ë¡œ, ìµœëŒ€ì¹˜ë¡œ ì„¤ì •)\n",
        "LR_PHASE1 = 1e-3\n",
        "LR_PHASE2 = 1e-5\n",
        "DROPOUT_P = 0.3\n",
        "\n",
        "# --- K-Fold êµì°¨ ê²€ì¦ ì„¤ì • (íŒ€ì› ì „ëµ) ---\n",
        "N_FOLDS = 5 # 5-Fold êµì°¨ ê²€ì¦\n",
        "BASE_SEED = 42 # íŒ€ ê³µí†µ SEED ê¸°ì¤€\n",
        "\n",
        "# (ì‹œë“œ ê³ ì • - ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ ì‹œ í•œ ë²ˆ)\n",
        "random.seed(BASE_SEED)\n",
        "np.random.seed(BASE_SEED)\n",
        "torch.manual_seed(BASE_SEED)\n",
        "\n",
        "\n",
        "# --- [ì¶”ê°€] 2. EarlyStopping í´ë˜ìŠ¤ ì •ì˜ ---\n",
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Validation lossê°€ patience íšŸìˆ˜ë§Œí¼ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í›ˆë ¨ì„ ì¡°ê¸° ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): Validation lossê°€ ê°œì„ ë˜ì§€ ì•Šì•„ë„ ê¸°ë‹¤ë¦´ ì—í¬í¬ ìˆ˜\n",
        "            verbose (bool): ì–¼ë¦¬ ìŠ¤íƒ‘í•‘ ë©”ì‹œì§€ ì¶œë ¥ ì—¬ë¶€\n",
        "            delta (float): ê°œì„ ìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ loss ê°ì†ŒëŸ‰\n",
        "            path (str): ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì €ì¥í•  ê²½ë¡œ\n",
        "            trace_func (function): ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss # lossëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ìŒìˆ˜(-)ë¥¼ ì·¨í•´ scoreë¡œ ì‚¬ìš©\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            # ê°œì„ ë˜ì§€ ì•ŠìŒ\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            # ê°œì„ ë¨\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''ìµœì € val_lossë¥¼ ê¸°ë¡í•œ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "# --- 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦ê°• (Transforms) ---\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(\n",
        "        (IMG_SIZE, IMG_SIZE),\n",
        "        interpolation=transforms.InterpolationMode.BICUBIC\n",
        "   ),# [ìˆ˜ì •]\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomPerspective(distortion_scale=0.1, p=0.2),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize(\n",
        "        (IMG_SIZE, IMG_SIZE),\n",
        "        interpolation=transforms.InterpolationMode.BICUBIC # [ìˆ˜ì •]\n",
        "    ),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "# --- 4. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ (Custom Dataset) ---\n",
        "class StateFarmDataset(Dataset):\n",
        "    \"\"\" í›ˆë ¨ ë° ê²€ì¦ìš© ë°ì´í„°ì…‹ (CSV ê¸°ë°˜, ìš´ì „ì ë¶„ë¦¬ìš©) \"\"\"\n",
        "    def __init__(self, df, root_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_to_int = {f\"c{i}\": i for i in range(NUM_CLASSES)}\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        class_name = row['classname']\n",
        "        img_name = row['img']\n",
        "        img_path = os.path.join(self.root_dir, class_name, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.class_to_int[class_name]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class StateFarmTestDataset(Dataset):\n",
        "    \"\"\" í…ŒìŠ¤íŠ¸(ì œì¶œ)ìš© ë°ì´í„°ì…‹ (os.listdir ìˆ˜ì •ë³¸) \"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        try:\n",
        "            all_files = os.listdir(root_dir)\n",
        "            self.img_paths = [os.path.join(root_dir, f) for f in all_files if f.endswith('.jpg')]\n",
        "            print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹: {len(self.img_paths)}ê°œ íŒŒì¼ ì°¾ìŒ.\")\n",
        "        except OSError as e:\n",
        "            print(f\"ERROR: í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬({root_dir}) ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
        "            self.img_paths = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img_name = os.path.basename(img_path)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_name\n",
        "\n",
        "# --- 5. ëª¨ë¸ ì •ì˜ (ì „ì´ í•™ìŠµ ResNet-50) ---\n",
        "def build_transfer_resnet50(num_classes=NUM_CLASSES, dropout_p=DROPOUT_P, pretrained=True):\n",
        "    weights = models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "    model = models.resnet50(weights=weights)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(p=dropout_p),\n",
        "        nn.Linear(num_ftrs, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- 6. í•™ìŠµ ë° ê²€ì¦ ë£¨í”„ (Training & Validation) ---\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device, fold_num, epoch_num, total_epochs, phase_name):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    desc = f\"Fold {fold_num} | {phase_name} | Epoch {epoch_num}/{total_epochs} (Train)\"\n",
        "    for images, labels in tqdm(loader, desc=desc):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "def validate(model, loader, criterion, device, fold_num, epoch_num, total_epochs, phase_name):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    desc = f\"Fold {fold_num} | {phase_name} | Epoch {epoch_num}/{total_epochs} (Val)\"\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=desc):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "# --- 7. [ìˆ˜ì •] ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ (Early Stopping ì ìš©) ---\n",
        "\n",
        "def main():\n",
        "    # --- ë°ì´í„° ì¤€ë¹„ ---\n",
        "    print(\"... ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘ ...\")\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "    drivers = df['subject'].unique() # ëª¨ë“  ìš´ì „ì\n",
        "\n",
        "    # --- K-Fold ì„¤ì • ---\n",
        "    kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=BASE_SEED)\n",
        "\n",
        "    all_fold_losses = [] # ëª¨ë“  í´ë“œì˜ (ìµœì¢… ì†ì‹¤)ì„ ì €ì¥\n",
        "\n",
        "    # ====================================================\n",
        "    # K-Fold í›ˆë ¨ ë£¨í”„ ì‹œì‘\n",
        "    # ====================================================\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(drivers), 1):\n",
        "\n",
        "        # --- Foldë³„ ì‹œë“œ ê³ ì • ---\n",
        "        seed = BASE_SEED + fold\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        if DEVICE == 'cuda':\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "        # --- ìš´ì „ì ë¶„ë¦¬ ---\n",
        "        train_drivers = drivers[train_idx]\n",
        "        val_drivers   = drivers[val_idx]\n",
        "\n",
        "        train_df = df[df['subject'].isin(train_drivers)]\n",
        "        val_df   = df[df['subject'].isin(val_drivers)]\n",
        "\n",
        "        print(f\"\\n===== Fold {fold}/{N_FOLDS} =====\")\n",
        "        print(f\"Train drivers: {len(train_drivers)}ëª… | Val drivers: {len(val_drivers)}ëª…\")\n",
        "        print(f\"Train images: {len(train_df)} | Val images: {len(val_df)}\")\n",
        "\n",
        "        # --- ë°ì´í„°ì…‹ ë° ë¡œë” ---\n",
        "        train_dataset = StateFarmDataset(train_df, TRAIN_DIR, transform=train_transforms)\n",
        "        val_dataset   = StateFarmDataset(val_df, TRAIN_DIR, transform=val_test_transforms)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "        # --- ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜ ---\n",
        "        model = build_transfer_resnet50(pretrained=True).to(DEVICE)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        BEST_MODEL_PATH = f\"best_model_fold_{fold}.pth\"\n",
        "\n",
        "        # --- [ìˆ˜ì •] Early Stopping ì´ˆê¸°í™” (Phase 1ìš©) ---\n",
        "        # patience=3 -> 3 ì—í¬í¬ ë™ì•ˆ val_loss ê°œì„  ì—†ìœ¼ë©´ ì¤‘ì§€\n",
        "        early_stopping_p1 = EarlyStopping(patience=3, verbose=True, path=BEST_MODEL_PATH)\n",
        "\n",
        "\n",
        "        # --- [ìˆ˜ì •] í•™ìŠµ ë‹¨ê³„ 1: íŠ¹ì§• ì¶”ì¶œ (Early Stopping ì ìš©) ---\n",
        "        print(f\"\\n--- [Fold {fold}] í•™ìŠµ ë‹¨ê³„ 1: Feature Extraction ì‹œì‘ ---\")\n",
        "        for name, param in model.named_parameters():\n",
        "            if \"fc\" not in name:\n",
        "                param.requires_grad = False\n",
        "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR_PHASE1)\n",
        "\n",
        "        for epoch in range(1, EPOCHS_PHASE1 + 1):\n",
        "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, fold, epoch, EPOCHS_PHASE1, \"Phase 1\")\n",
        "            val_loss, val_acc = validate(model, val_loader, criterion, DEVICE, fold, epoch, EPOCHS_PHASE1, \"Phase 1\")\n",
        "            print(f\"  Fold {fold}, Phase 1, Epoch {epoch}: Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "            # --- [ìˆ˜ì •] EarlyStopping í˜¸ì¶œ ---\n",
        "            early_stopping_p1(val_loss, model)\n",
        "            if early_stopping_p1.early_stop:\n",
        "                print(\"Early stopping (Phase 1)\")\n",
        "                break # ì´ ì—í¬í¬ ë£¨í”„ë¥¼ íƒˆì¶œ\n",
        "            # --- EarlyStopping ë ---\n",
        "\n",
        "        # --- [ìˆ˜ì •] í•™ìŠµ ë‹¨ê³„ 2: ë¯¸ì„¸ ì¡°ì • (Early Stopping ì ìš©) ---\n",
        "        print(f\"\\n--- [Fold {fold}] í•™ìŠµ ë‹¨ê³„ 2: Fine-Tuning ì‹œì‘ ---\")\n",
        "\n",
        "        # [ìˆ˜ì •] EarlyStoppingì´ ì €ì¥í•œ ìµœê³  ëª¨ë¸ ë¡œë“œ\n",
        "        model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
        "\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = True\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=LR_PHASE2)\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_PHASE2, eta_min=1e-7)\n",
        "\n",
        "        # --- [ìˆ˜ì •] Early Stopping ì´ˆê¸°í™” (Phase 2ìš©) ---\n",
        "        # (patience=5 -> 5 ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¤‘ì§€)\n",
        "        # Phase 1ì˜ val_loss_min ê°’ì„ ì´ì–´ë°›ì•„ ì‹œì‘\n",
        "        early_stopping_p2 = EarlyStopping(patience=5, verbose=True, path=BEST_MODEL_PATH)\n",
        "        early_stopping_p2.val_loss_min = early_stopping_p1.val_loss_min\n",
        "        early_stopping_p2.best_score = -early_stopping_p1.val_loss_min\n",
        "\n",
        "        for epoch in range(1, EPOCHS_PHASE2 + 1):\n",
        "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, fold, epoch, EPOCHS_PHASE2, \"Phase 2\")\n",
        "            val_loss, val_acc = validate(model, val_loader, criterion, DEVICE, fold, epoch, EPOCHS_PHASE2, \"Phase 2\")\n",
        "            scheduler.step()\n",
        "            print(f\"  Fold {fold}, Phase 2, Epoch {epoch}: Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "            # --- [ìˆ˜ì •] EarlyStopping í˜¸ì¶œ ---\n",
        "            early_stopping_p2(val_loss, model)\n",
        "            if early_stopping_p2.early_stop:\n",
        "                print(\"Early stopping (Phase 2)\")\n",
        "                break # ì´ ì—í¬í¬ ë£¨í”„ë¥¼ íƒˆì¶œ\n",
        "            # --- EarlyStopping ë ---\n",
        "\n",
        "        # [ìˆ˜ì •] ì´ Foldì˜ ìµœì¢… ìµœê³  ì†ì‹¤ì€ EarlyStopping ê°ì²´ê°€ ê¸°ì–µí•˜ê³  ìˆìŒ\n",
        "        final_best_loss = early_stopping_p2.val_loss_min\n",
        "        print(f\"ğŸ¯ Fold {fold} ì™„ë£Œ! Best Validation Loss: {final_best_loss:.4f}\")\n",
        "        all_fold_losses.append(final_best_loss)\n",
        "\n",
        "    # ====================================================\n",
        "    # K-Fold í›ˆë ¨ ë£¨í”„ ì¢…ë£Œ\n",
        "    # ====================================================\n",
        "\n",
        "    print(\"\\n\\n==================== K-Fold í›ˆë ¨ ìš”ì•½ ====================\")\n",
        "    for i, loss in enumerate(all_fold_losses):\n",
        "        print(f\"Fold {i+1} Best Val Loss: {loss:.4f}\")\n",
        "\n",
        "    print(f\"\\nğŸ”¥ K-Fold í‰ê·  Val Loss: {np.mean(all_fold_losses):.4f} Â± {np.std(all_fold_losses):.4f}\")\n",
        "\n",
        "\n",
        "    # --- 8. ì˜ˆì¸¡ (Inference) ë° K-Fold ì•™ìƒë¸” ---\n",
        "    print(\"\\n\\n\" + \"=\" * 70)\n",
        "    print(\"ğŸ”® 5-Fold ì•™ìƒë¸” ì˜ˆì¸¡\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # (1) í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ë¡œë”\n",
        "    test_dataset = StateFarmTestDataset(TEST_DIR, transform=val_test_transforms)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "    # (2) ê° Fold ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    all_fold_probs = []\n",
        "    all_img_names = []\n",
        "\n",
        "    for fold in range(1, N_FOLDS + 1):\n",
        "        model_path = f\"best_model_fold_{fold}.pth\"\n",
        "        print(f\"\\nğŸ“ Fold {fold} ëª¨ë¸ ì˜ˆì¸¡ ì¤‘... ({model_path})\")\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"WARNING: {model_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì´ FoldëŠ” ì•™ìƒë¸”ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "        # (3) ResNet-50 ëª¨ë¸ ë¼ˆëŒ€ ìƒì„±\n",
        "        model = build_transfer_resnet50(pretrained=False).to(DEVICE)\n",
        "\n",
        "        # (4) state_dict ë¡œë“œ\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        fold_probs = [] # ì´ í´ë“œì˜ ì˜ˆì¸¡ í™•ë¥ \n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, img_names in tqdm(test_loader, desc=f'Predicting Fold {fold}'):\n",
        "                images = images.to(DEVICE)\n",
        "                outputs = model(images)\n",
        "                probs = F.softmax(outputs, dim=1) # í™•ë¥ ë¡œ ë³€í™˜\n",
        "                fold_probs.append(probs.cpu().numpy())\n",
        "\n",
        "                if fold == 1: # ì²« ë²ˆì§¸ í´ë“œì—ì„œë§Œ íŒŒì¼ëª… ì €ì¥\n",
        "                    all_img_names.extend(img_names)\n",
        "\n",
        "        all_fold_probs.append(np.concatenate(fold_probs, axis=0))\n",
        "\n",
        "    # --- ì•™ìƒë¸” (í‰ê· ) ---\n",
        "    if not all_fold_probs:\n",
        "        print(\"ERROR: í›ˆë ¨ëœ ëª¨ë¸ì´ í•˜ë‚˜ë„ ì—†ì–´ ì˜ˆì¸¡ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n... ëª¨ë“  Foldì˜ ì˜ˆì¸¡ í™•ë¥ ì„ í‰ê· (ì•™ìƒë¸”) ì¤‘ ...\")\n",
        "    final_probs = np.mean(all_fold_probs, axis=0)\n",
        "\n",
        "    # --- ì œì¶œ íŒŒì¼ ìƒì„± ---\n",
        "    submission_df = pd.DataFrame(final_probs, columns=[f\"c{i}\" for i in range(NUM_CLASSES)])\n",
        "    submission_df['img'] = all_img_names\n",
        "    submission_df = submission_df[['img'] + [f\"c{i}\" for i in range(NUM_CLASSES)]]\n",
        "\n",
        "    submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
        "    print(f\"\\nâœ… K-Fold ì•™ìƒë¸” ì œì¶œ íŒŒì¼ '{SUBMISSION_FILE}' ìƒì„± ì™„ë£Œ!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "7O8Nk0JtzSZ3",
        "outputId": "6a5954a7-27ca-4064-fd08-618c0f7c0cdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "... ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘ ...\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "Train drivers: 20ëª… | Val drivers: 6ëª…\n",
            "Train images: 17446 | Val images: 4978\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 108MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "`np.Inf` was removed in the NumPy 2.0 release. Use `np.inf` instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-205439890.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-205439890.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# --- [ìˆ˜ì •] Early Stopping ì´ˆê¸°í™” (Phase 1ìš©) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m# patience=3 -> 3 ì—í¬í¬ ë™ì•ˆ val_loss ê°œì„  ì—†ìœ¼ë©´ ì¤‘ì§€\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mearly_stopping_p1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBEST_MODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-205439890.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, patience, verbose, delta, path, trace_func)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__expired_attributes__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    398\u001b[0m                 \u001b[0;34mf\"`np.{attr}` was removed in the NumPy 2.0 release. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0;34mf\"{__expired_attributes__[attr]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: `np.Inf` was removed in the NumPy 2.0 release. Use `np.inf` instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBTWOsB_SH0Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "# --- 1. í™˜ê²½ ì„¤ì • (Configuration) ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# ë°ì´í„° ê²½ë¡œ\n",
        "DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
        "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
        "CSV_PATH = os.path.join(DATA_DIR, \"driver_imgs_list.csv\")\n",
        "SUBMISSION_FILE = \"submission.csv\"\n",
        "\n",
        "# --- [ìˆ˜ì •ë¨] í•˜ì´í¼íŒŒë¼ë¯¸í„° (íŒ€ íšŒì˜ ê²°ê³¼ ì ìš©) ---\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 32  # 16 -> 32ë¡œ ë³€ê²½\n",
        "IMG_SIZE = 128   # 224 -> 128ë¡œ ë³€ê²½\n",
        "# (ë‚˜ë¨¸ì§€ íŒŒë¼ë¯¸í„°ëŠ” ë™ì¼)\n",
        "EPOCHS_PHASE1 = 5\n",
        "EPOCHS_PHASE2 = 15\n",
        "LR_PHASE1 = 1e-3\n",
        "LR_PHASE2 = 1e-5\n",
        "DROPOUT_P = 0.3\n",
        "\n",
        "# --- 2. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦ê°• (Transforms) ---\n",
        "# ImageNet ì •ê·œí™” ê°’\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "#\n",
        "# í›ˆë ¨ ë°ì´í„° ì¦ê°•: ResNet í¬ê¸°ì— ë§ì¶”ê³  ë‹¤ì–‘í•œ ë³€í˜• ì ìš©\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomRotation(15),      # ì•½ê°„ì˜ íšŒì „\n",
        "    transforms.RandomHorizontalFlip(),    # ì¢Œìš° ë°˜ì „\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2), # ë°ê¸°/ëŒ€ë¹„ ì¡°ì ˆ\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "# ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°: í¬ê¸° ì¡°ì •ê³¼ ì •ê·œí™”ë§Œ ì ìš©\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "# --- 3. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ (Custom Dataset) ---\n",
        "\n",
        "class StateFarmDataset(Dataset):\n",
        "    \"\"\" í›ˆë ¨ ë° ê²€ì¦ìš© ë°ì´í„°ì…‹ \"\"\"\n",
        "    def __init__(self, df, root_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        # í´ë˜ìŠ¤ ì´ë¦„(c0 ~ c9)ì„ ì •ìˆ˜(0 ~ 9)ë¡œ ë§¤í•‘\n",
        "        self.class_to_int = {f\"c{i}\": i for i in range(NUM_CLASSES)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        class_name = row['classname']\n",
        "        img_name = row['img']\n",
        "\n",
        "        # ì´ë¯¸ì§€ ê²½ë¡œ: ./data/train/c0/img_1000.jpg\n",
        "        img_path = os.path.join(self.root_dir, class_name, img_name)\n",
        "\n",
        "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # ë ˆì´ë¸” (ì •ìˆ˜)\n",
        "        label = self.class_to_int[class_name]\n",
        "\n",
        "        # ë³€í˜• ì ìš©\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class StateFarmTestDataset(Dataset):\n",
        "    \"\"\" í…ŒìŠ¤íŠ¸(ì œì¶œ)ìš© ë°ì´í„°ì…‹ \"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # --- [ìˆ˜ì •ëœ í•µì‹¬ ë¡œì§] ---\n",
        "        # 1. os.listdir()ë¡œ í•´ë‹¹ í´ë”ì˜ ëª¨ë“  íŒŒì¼/í´ë” ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
        "        all_files = os.listdir(root_dir)\n",
        "\n",
        "        # 2. ì´ ì¤‘ì—ì„œ '.jpg'ë¡œ ëë‚˜ëŠ” íŒŒì¼ ì´ë¦„ë§Œ ê³¨ë¼ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
        "        # 3. os.path.joinìœ¼ë¡œ íŒŒì¼ ì´ë¦„ì— ì „ì²´ ê²½ë¡œ(root_dir)ë¥¼ ë¶™ì—¬ì¤ë‹ˆë‹¤.\n",
        "        self.img_paths = [\n",
        "            os.path.join(root_dir, f)\n",
        "            for f in all_files\n",
        "            if f.endswith('.jpg')\n",
        "        ]\n",
        "\n",
        "        print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹: {len(self.img_paths)}ê°œ íŒŒì¼ ì°¾ìŒ.\") # (ì§„ë‹¨ìš©)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img_name = os.path.basename(img_path) # \"img_1.jpg\"\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # ì´ë¯¸ì§€ì™€ í•¨ê»˜ íŒŒì¼ ì´ë¦„ì„ ë°˜í™˜ (ì œì¶œ íŒŒì¼ ìƒì„± ì‹œ í•„ìš”)\n",
        "        return image, img_name\n",
        "\n",
        "# --- 4. ëª¨ë¸ ì •ì˜ (ì „ì´ í•™ìŠµ ResNet-50) ---\n",
        "\n",
        "def build_transfer_resnet50(num_classes=NUM_CLASSES, dropout_p=DROPOUT_P, pretrained=True):\n",
        "    \"\"\"\n",
        "    ì‚¬ì „ í•™ìŠµëœ ResNet-50ì„ ë¶ˆëŸ¬ì˜¤ê³ , ë¶„ë¥˜ê¸°ë¥¼ Dropout + Linearë¡œ êµì²´\n",
        "    \"\"\"\n",
        "    weights = models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "    model = models.resnet50(weights=weights)\n",
        "\n",
        "    num_ftrs = model.fc.in_features # (2048)\n",
        "\n",
        "    # ë§ˆì§€ë§‰ ë ˆì´ì–´ë¥¼ Dropout + Linearë¡œ êµì²´\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(p=dropout_p),\n",
        "        nn.Linear(num_ftrs, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- 5. í•™ìŠµ ë° ê²€ì¦ ë£¨í”„ (Training & Validation) ---\n",
        "\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    \"\"\" 1 ì—í¬í¬ í›ˆë ¨ \"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # tqdmìœ¼ë¡œ ì§„í–‰ë¥  í‘œì‹œ\n",
        "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # ìˆœì „íŒŒ\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # ì—­ì „íŒŒ ë° ìµœì í™”\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "def validate(model, loader, criterion, device):\n",
        "    \"\"\" 1 ì—í¬í¬ ê²€ì¦ \"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad(): # ê²€ì¦ ì‹œì—ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¶ˆí•„ìš”\n",
        "        for images, labels in tqdm(loader, desc=\"Validation\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # ì •í™•ë„ ê³„ì‚°\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# --- 6. ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ (Main Execution) ---\n",
        "\n",
        "def main():\n",
        "    # --- ë°ì´í„° ì¤€ë¹„ ---\n",
        "    print(\"... ë°ì´í„° ë¡œë“œ ë° ë¶„í•  ì¤‘ ...\")\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "    # !ì¤‘ìš”!: ë°ì´í„° ìœ ì¶œì„ ë§‰ê¸° ìœ„í•´ 'ìš´ì „ì(subject)' ê¸°ì¤€ìœ¼ë¡œ í›ˆë ¨/ê²€ì¦ ë¶„ë¦¬\n",
        "    drivers = df['subject'].unique()\n",
        "    train_drivers, val_drivers = train_test_split(drivers, test_size=0.1, random_state=42)\n",
        "\n",
        "    train_df = df[df['subject'].isin(train_drivers)]\n",
        "    val_df = df[df['subject'].isin(val_drivers)]\n",
        "\n",
        "    print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_df)}ì¥, ê²€ì¦ ë°ì´í„°: {len(val_df)}ì¥\")\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ìƒì„±\n",
        "    train_dataset = StateFarmDataset(train_df, TRAIN_DIR, transform=train_transforms)\n",
        "    val_dataset = StateFarmDataset(val_df, TRAIN_DIR, transform=val_test_transforms)\n",
        "\n",
        "    # ë°ì´í„°ë¡œë” ìƒì„±\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # --- ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ---\n",
        "    model = build_transfer_resnet50(pretrained=True).to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss() # (CrossEntropyLossê°€ LogLossë¥¼ ìµœì í™”)\n",
        "\n",
        "    best_val_loss = float('inf') # ìµœê³  ì„±ëŠ¥(ìµœì € ì†ì‹¤) ì €ì¥ì„ ìœ„í•¨\n",
        "    BEST_MODEL_PATH = \"best_model.pth\"\n",
        "\n",
        "    # --- í•™ìŠµ ë‹¨ê³„ 1: íŠ¹ì§• ì¶”ì¶œ (Feature Extraction) ---\n",
        "    print(\"\\n===== [í•™ìŠµ ë‹¨ê³„ 1: Feature Extraction] ì‹œì‘ =====\")\n",
        "\n",
        "    # (1) ë¶„ë¥˜ê¸°(fc) ì™¸ ëª¨ë“  ë ˆì´ì–´ ë™ê²°\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"fc\" not in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # (2) ì˜µí‹°ë§ˆì´ì € (í•™ìŠµí•  íŒŒë¼ë¯¸í„°ë§Œ ì „ë‹¬)\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR_PHASE1)\n",
        "\n",
        "    for epoch in range(EPOCHS_PHASE1):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{EPOCHS_PHASE1} ---\")\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
        "\n",
        "        print(f\"Phase 1 - Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # (3) ìµœê³  ëª¨ë¸ ì €ì¥\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "            print(f\"  -> ëª¨ë¸ ì €ì¥ ì™„ë£Œ (Val Loss: {val_loss:.4f})\")\n",
        "\n",
        "    # --- í•™ìŠµ ë‹¨ê³„ 2: ë¯¸ì„¸ ì¡°ì • (Fine-Tuning) ---\n",
        "    print(\"\\n===== [í•™ìŠµ ë‹¨ê³„ 2: Fine-Tuning] ì‹œì‘ =====\")\n",
        "\n",
        "    # (1) ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
        "\n",
        "    # (2) ëª¨ë“  ë ˆì´ì–´ ë™ê²° í•´ì œ\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # (3) ì˜µí‹°ë§ˆì´ì € (ë§¤ìš° ë‚®ì€ í•™ìŠµë¥ )\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LR_PHASE2)\n",
        "    # (4) ìŠ¤ì¼€ì¤„ëŸ¬ (ì„ íƒì‚¬í•­ì´ë‚˜ ê°•ë ¥ ê¶Œì¥)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_PHASE2, eta_min=1e-7)\n",
        "\n",
        "    for epoch in range(EPOCHS_PHASE2):\n",
        "        print(f\"\\n--- Epoch {epoch+1}/{EPOCHS_PHASE2} ---\")\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion, DEVICE)\n",
        "\n",
        "        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Phase 2 - Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}% (LR: {optimizer.param_groups[0]['lr']:.1e})\")\n",
        "\n",
        "        # (5) ìµœê³  ëª¨ë¸ ê°±ì‹ \n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "            print(f\"  -> ëª¨ë¸ ì €ì¥ ì™„ë£Œ (Val Loss: {val_loss:.4f})\")\n",
        "\n",
        "    print(f\"\\n===== ëª¨ë“  í•™ìŠµ ì™„ë£Œ. ìµœì¢… ìµœê³  ëª¨ë¸: {BEST_MODEL_PATH} =====\")\n",
        "\n",
        "    # --- 7. ì˜ˆì¸¡ (Inference) ë° ì œì¶œ íŒŒì¼ ìƒì„± ---\n",
        "    print(\"\\n===== [ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±] ì‹œì‘ =====\")\n",
        "\n",
        "    # (1) í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ë¡œë”\n",
        "    test_dataset = StateFarmTestDataset(TEST_DIR, transform=val_test_transforms)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "    # (2) ìµœì¢… ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
        "    model.eval()\n",
        "\n",
        "    all_img_names = []\n",
        "    all_probs = [] # ëª¨ë“  í™•ë¥ (probabilities)ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, img_names in tqdm(test_loader, desc=\"Predicting\"):\n",
        "            images = images.to(DEVICE)\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            # !ì¤‘ìš”!: LogLoss ì œì¶œì„ ìœ„í•´ ë¡œì§“(logits)ì„ í™•ë¥ (probabilities)ë¡œ ë³€í™˜\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "            all_probs.append(probs.cpu().numpy())\n",
        "            all_img_names.extend(img_names)\n",
        "\n",
        "    # (3) ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "    # ë¦¬ìŠ¤íŠ¸ë“¤ì„ í•˜ë‚˜ë¡œ í•©ì¹¨\n",
        "    all_probs = np.concatenate(all_probs, axis=0)\n",
        "\n",
        "    # Pandas DataFrame ìƒì„±\n",
        "    submission_df = pd.DataFrame(all_probs, columns=[f\"c{i}\" for i in range(NUM_CLASSES)])\n",
        "    submission_df['img'] = all_img_names\n",
        "\n",
        "    # ì—´ ìˆœì„œ ë§ì¶”ê¸° (img, c0, c1, ..., c9)\n",
        "    submission_df = submission_df[['img'] + [f\"c{i}\" for i in range(NUM_CLASSES)]]\n",
        "\n",
        "    # CSVë¡œ ì €ì¥\n",
        "    submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
        "    print(f\"\\nì œì¶œ íŒŒì¼ '{SUBMISSION_FILE}' ìƒì„± ì™„ë£Œ!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1B1m2zMimQMDsM7_sPdFcbKhfVlXkuDa4",
      "authorship_tag": "ABX9TyNdP3+45U5IfwAjKH545GJ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}