{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlTDQ7Z5GnU6Pk4AH2yCQx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Im-jDiOt/DeepLearning-Term-Proj/blob/feature-inception/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKpWLEFamDnx",
        "outputId": "10d97c5e-fd3b-4b78-b9b5-7ca44fcd5df1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt7dPPabmAmy",
        "outputId": "da613551-9058-4403-9139-cfa7a50f923d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "... ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘ ...\n",
            "\n",
            "===== Fold 1/5 =====\n",
            "Train drivers: 20ëª… | Val drivers: 6ëª…\n",
            "Train images: 17446 | Val images: 4978\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 162MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- [Fold 1] í•™ìŠµ ë‹¨ê³„ 1: Feature Extraction ì‹œì‘ ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFold 1 | Phase 1 | Epoch 1/5 (Train):   0%|          | 0/1091 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Fold 1 | Phase 1 | Epoch 1/5 (Train):   0%|          | 2/1091 [00:48<6:45:24, 22.34s/it] "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import InterpolationMode # [ìˆ˜ì •] import ë°©ì‹ ë³€ê²½\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "# --- 1. í™˜ê²½ ì„¤ì • (Configuration) ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# ë°ì´í„° ê²½ë¡œ\n",
        "DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
        "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
        "CSV_PATH = os.path.join(DATA_DIR, \"driver_imgs_list.csv\")\n",
        "SUBMISSION_FILE = \"submission_kfold_resnet50.csv\"\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 16\n",
        "IMG_SIZE = 128\n",
        "EPOCHS_PHASE1 = 5   # (ì–¼ë¦¬ ìŠ¤íƒ‘í•‘ì´ ìˆìœ¼ë¯€ë¡œ, ìµœëŒ€ì¹˜ë¡œ ì„¤ì •)\n",
        "# EPOCHS_PHASE2 = 15  # [ì„ì‹œ ì œê±°]\n",
        "LR_PHASE1 = 1e-3\n",
        "# LR_PHASE2 = 1e-5  # [ì„ì‹œ ì œê±°]\n",
        "DROPOUT_P = 0.3\n",
        "\n",
        "# --- K-Fold êµì°¨ ê²€ì¦ ì„¤ì • ---\n",
        "N_FOLDS = 5\n",
        "BASE_SEED = 42\n",
        "\n",
        "random.seed(BASE_SEED)\n",
        "np.random.seed(BASE_SEED)\n",
        "torch.manual_seed(BASE_SEED)\n",
        "\n",
        "\n",
        "# --- [ìˆ˜ì •] 2. EarlyStopping í´ë˜ìŠ¤ ì •ì˜ ---\n",
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Validation lossê°€ patience íšŸìˆ˜ë§Œí¼ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í›ˆë ¨ì„ ì¡°ê¸° ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pth', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): Validation lossê°€ ê°œì„ ë˜ì§€ ì•Šì•„ë„ ê¸°ë‹¤ë¦´ ì—í¬í¬ ìˆ˜\n",
        "            verbose (bool): ì–¼ë¦¬ ìŠ¤íƒ‘í•‘ ë©”ì‹œì§€ ì¶œë ¥ ì—¬ë¶€\n",
        "            delta (float): ê°œì„ ìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ loss ê°ì†ŒëŸ‰\n",
        "            path (str): ìµœê³  ì„±ëŠ¥ ëª¨ë¸ì„ ì €ì¥í•  ê²½ë¡œ\n",
        "            trace_func (function): ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        # [ìˆ˜ì •] np.Inf ëŒ€ì‹  float('inf')ë¥¼ ì‚¬ìš© (NumPy 2.0 í˜¸í™˜)\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            # ê°œì„ ë˜ì§€ ì•ŠìŒ\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            # ê°œì„ ë¨\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''ìµœì € val_lossë¥¼ ê¸°ë¡í•œ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "# --- 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¦ê°• (Transforms) ---\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC), # [ìˆ˜ì •] import ì˜¤ë¥˜ í•´ê²°\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomPerspective(distortion_scale=0.1, p=0.2),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC), # [ìˆ˜ì •] import ì˜¤ë¥˜ í•´ê²°\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "# --- 4. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ (Custom Dataset) ---\n",
        "class StateFarmDataset(Dataset):\n",
        "    \"\"\" í›ˆë ¨ ë° ê²€ì¦ìš© ë°ì´í„°ì…‹ (CSV ê¸°ë°˜, ìš´ì „ì ë¶„ë¦¬ìš©) \"\"\"\n",
        "    def __init__(self, df, root_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_to_int = {f\"c{i}\": i for i in range(NUM_CLASSES)}\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        class_name = row['classname']\n",
        "        img_name = row['img']\n",
        "        img_path = os.path.join(self.root_dir, class_name, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = self.class_to_int[class_name]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class StateFarmTestDataset(Dataset):\n",
        "    \"\"\" í…ŒìŠ¤íŠ¸(ì œì¶œ)ìš© ë°ì´í„°ì…‹ (os.listdir ìˆ˜ì •ë³¸) \"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        try:\n",
        "            all_files = os.listdir(root_dir)\n",
        "            self.img_paths = [os.path.join(root_dir, f) for f in all_files if f.endswith('.jpg')]\n",
        "            print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹: {len(self.img_paths)}ê°œ íŒŒì¼ ì°¾ìŒ.\")\n",
        "        except OSError as e:\n",
        "            print(f\"ERROR: í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬({root_dir}) ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
        "            self.img_paths = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img_name = os.path.basename(img_path)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_name\n",
        "\n",
        "# --- 5. ëª¨ë¸ ì •ì˜ (ì „ì´ í•™ìŠµ ResNet-50) ---\n",
        "def build_transfer_resnet50(num_classes=NUM_CLASSES, dropout_p=DROPOUT_P, pretrained=True):\n",
        "    weights = models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "    model = models.resnet50(weights=weights)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(p=dropout_p),\n",
        "        nn.Linear(num_ftrs, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- 6. í•™ìŠµ ë° ê²€ì¦ ë£¨í”„ (Training & Validation) ---\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device, fold_num, epoch_num, total_epochs, phase_name):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    desc = f\"Fold {fold_num} | {phase_name} | Epoch {epoch_num}/{total_epochs} (Train)\"\n",
        "    for images, labels in tqdm(loader, desc=desc):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "def validate(model, loader, criterion, device, fold_num, epoch_num, total_epochs, phase_name):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    desc = f\"Fold {fold_num} | {phase_name} | Epoch {epoch_num}/{total_epochs} (Val)\"\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=desc):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "# --- 7. [ìˆ˜ì •] ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ (Fine-Tuning ì„ì‹œ ì œê±°) ---\n",
        "\n",
        "def main():\n",
        "    # --- ë°ì´í„° ì¤€ë¹„ ---\n",
        "    print(\"... ì „ì²´ ë°ì´í„° ë¡œë“œ ì¤‘ ...\")\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "    drivers = df['subject'].unique() # ëª¨ë“  ìš´ì „ì\n",
        "\n",
        "    # --- K-Fold ì„¤ì • ---\n",
        "    kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=BASE_SEED)\n",
        "\n",
        "    all_fold_losses = [] # ëª¨ë“  í´ë“œì˜ (ìµœì¢… ì†ì‹¤)ì„ ì €ì¥\n",
        "\n",
        "    # ====================================================\n",
        "    # K-Fold í›ˆë ¨ ë£¨í”„ ì‹œì‘\n",
        "    # ====================================================\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(drivers), 1):\n",
        "\n",
        "        # --- Foldë³„ ì‹œë“œ ê³ ì • ---\n",
        "        seed = BASE_SEED + fold\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        if DEVICE == 'cuda':\n",
        "            torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "        # --- ìš´ì „ì ë¶„ë¦¬ ---\n",
        "        train_drivers = drivers[train_idx]\n",
        "        val_drivers   = drivers[val_idx]\n",
        "\n",
        "        train_df = df[df['subject'].isin(train_drivers)]\n",
        "        val_df   = df[df['subject'].isin(val_drivers)]\n",
        "\n",
        "        print(f\"\\n===== Fold {fold}/{N_FOLDS} =====\")\n",
        "        print(f\"Train drivers: {len(train_drivers)}ëª… | Val drivers: {len(val_drivers)}ëª…\")\n",
        "        print(f\"Train images: {len(train_df)} | Val images: {len(val_df)}\")\n",
        "\n",
        "\n",
        "        # --- [ì¶”ê°€] ì´ ë‘ ì¤„ì˜ ì½”ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤! ---\n",
        "        train_dataset = StateFarmDataset(train_df, TRAIN_DIR, transform=train_transforms)\n",
        "        val_dataset   = StateFarmDataset(val_df, TRAIN_DIR, transform=val_test_transforms)\n",
        "        # --- ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ ---\n",
        "\n",
        "        # --- ë°ì´í„°ì…‹ ë° ë¡œë” ---\n",
        "        # [ìˆ˜ì •] num_workers=0 (Colab ë©ˆì¶¤ í˜„ìƒ í•´ê²°)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
        "        val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "        # --- ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜ ---\n",
        "        model = build_transfer_resnet50(pretrained=True).to(DEVICE)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        BEST_MODEL_PATH = f\"best_model_fold_{fold}.pth\"\n",
        "\n",
        "        # --- [ìˆ˜ì •] Early Stopping ì´ˆê¸°í™” (Phase 1ìš©) ---\n",
        "        early_stopping_p1 = EarlyStopping(patience=3, verbose=True, path=BEST_MODEL_PATH)\n",
        "\n",
        "        # --- í•™ìŠµ ë‹¨ê³„ 1: íŠ¹ì§• ì¶”ì¶œ (ì´ê²ƒë§Œ ì‹¤í–‰) ---\n",
        "        print(f\"\\n--- [Fold {fold}] í•™ìŠµ ë‹¨ê³„ 1: Feature Extraction ì‹œì‘ ---\")\n",
        "        for name, param in model.named_parameters():\n",
        "            if \"fc\" not in name:\n",
        "                param.requires_grad = False\n",
        "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR_PHASE1)\n",
        "\n",
        "        for epoch in range(1, EPOCHS_PHASE1 + 1):\n",
        "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, fold, epoch, EPOCHS_PHASE1, \"Phase 1\")\n",
        "            val_loss, val_acc = validate(model, val_loader, criterion, DEVICE, fold, epoch, EPOCHS_PHASE1, \"Phase 1\")\n",
        "            print(f\"  Fold {fold}, Phase 1, Epoch {epoch}: Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "            early_stopping_p1(val_loss, model)\n",
        "            if early_stopping_p1.early_stop:\n",
        "                print(\"Early stopping (Phase 1)\")\n",
        "                break\n",
        "\n",
        "        # --- [ì„ì‹œ ì œê±°] í•™ìŠµ ë‹¨ê³„ 2: ë¯¸ì„¸ ì¡°ì • (Fine-Tuning) ---\n",
        "        #\n",
        "        # print(f\"\\n--- [Fold {fold}] í•™ìŠµ ë‹¨ê³„ 2: Fine-Tuning ì‹œì‘ ---\")\n",
        "        # model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
        "        # for param in model.parameters():\n",
        "        #     param.requires_grad = True\n",
        "        # optimizer = optim.AdamW(model.parameters(), lr=LR_PHASE2)\n",
        "        # scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_PHASE2, eta_min=1e-7)\n",
        "        # early_stopping_p2 = EarlyStopping(patience=5, verbose=True, path=BEST_MODEL_PATH)\n",
        "        # early_stopping_p2.val_loss_min = early_stopping_p1.val_loss_min\n",
        "        # early_stopping_p2.best_score = -early_stopping_p1.val_loss_min\n",
        "        #\n",
        "        # for epoch in range(1, EPOCHS_PHASE2 + 1):\n",
        "        #     train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, fold, epoch, EPOCHS_PHASE2, \"Phase 2\")\n",
        "        #     val_loss, val_acc = validate(model, val_loader, criterion, DEVICE, fold, epoch, EPOCHS_PHASE2, \"Phase 2\")\n",
        "        #     scheduler.step()\n",
        "        #     print(f\"  Fold {fold}, Phase 2, Epoch {epoch}: Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        #     early_stopping_p2(val_loss, model)\n",
        "        #     if early_stopping_p2.early_stop:\n",
        "        #         print(\"Early stopping (Phase 2)\")\n",
        "        #         break\n",
        "        #\n",
        "        # final_best_loss = early_stopping_p2.val_loss_min\n",
        "        # --- Fine-Tuning ë¶€ë¶„ ë ---\n",
        "\n",
        "\n",
        "        # [ìˆ˜ì •] Phase 1ì˜ ìµœì¢… ê²°ê³¼ë¡œ ì ìˆ˜ ì§‘ê³„\n",
        "        final_best_loss = early_stopping_p1.val_loss_min\n",
        "        print(f\"ğŸ¯ Fold {fold} ì™„ë£Œ! Best Validation Loss: {final_best_loss:.4f}\")\n",
        "        all_fold_losses.append(final_best_loss)\n",
        "\n",
        "    # ====================================================\n",
        "    # K-Fold í›ˆë ¨ ë£¨í”„ ì¢…ë£Œ\n",
        "    # ====================================================\n",
        "\n",
        "    print(\"\\n\\n==================== K-Fold í›ˆë ¨ ìš”ì•½ ====================\")\n",
        "    for i, loss in enumerate(all_fold_losses):\n",
        "        print(f\"Fold {i+1} Best Val Loss: {loss:.4f}\")\n",
        "\n",
        "    print(f\"\\nğŸ”¥ K-Fold í‰ê·  Val Loss: {np.mean(all_fold_losses):.4f} Â± {np.std(all_fold_losses):.4f}\")\n",
        "\n",
        "\n",
        "    # --- 8. ì˜ˆì¸¡ (Inference) ë° K-Fold ì•™ìƒë¸” ---\n",
        "    print(\"\\n\\n\" + \"=\" * 70)\n",
        "    print(\"ğŸ”® 5-Fold ì•™ìƒë¸” ì˜ˆì¸¡\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # (1) í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ë¡œë”\n",
        "    test_dataset = StateFarmTestDataset(TEST_DIR, transform=val_test_transforms)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0) # [ìˆ˜ì •] num_workers=0\n",
        "\n",
        "    # (2) ê° Fold ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    all_fold_probs = []\n",
        "    all_img_names = []\n",
        "\n",
        "    for fold in range(1, N_FOLDS + 1):\n",
        "        model_path = f\"best_model_fold_{fold}.pth\"\n",
        "        print(f\"\\nğŸ“ Fold {fold} ëª¨ë¸ ì˜ˆì¸¡ ì¤‘... ({model_path})\")\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"WARNING: {model_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì´ FoldëŠ” ì•™ìƒë¸”ì—ì„œ ì œì™¸ë©ë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "        model = build_transfer_resnet50(pretrained=False).to(DEVICE)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        fold_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, img_names in tqdm(test_loader, desc=f'Predicting Fold {fold}'):\n",
        "                images = images.to(DEVICE)\n",
        "                outputs = model(images)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                fold_probs.append(probs.cpu().numpy())\n",
        "\n",
        "                if fold == 1:\n",
        "                    all_img_names.extend(img_names)\n",
        "\n",
        "        all_fold_probs.append(np.concatenate(fold_probs, axis=0))\n",
        "\n",
        "    # --- ì•™ìƒë¸” (í‰ê· ) ---\n",
        "    if not all_fold_probs:\n",
        "        print(\"ERROR: í›ˆë ¨ëœ ëª¨ë¸ì´ í•˜ë‚˜ë„ ì—†ì–´ ì˜ˆì¸¡ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n... ëª¨ë“  Foldì˜ ì˜ˆì¸¡ í™•ë¥ ì„ í‰ê· (ì•™ìƒë¸”) ì¤‘ ...\")\n",
        "    final_probs = np.mean(all_fold_probs, axis=0)\n",
        "\n",
        "    # --- ì œì¶œ íŒŒì¼ ìƒì„± ---\n",
        "    submission_df = pd.DataFrame(final_probs, columns=[f\"c{i}\" for i in range(NUM_CLASSES)])\n",
        "    submission_df['img'] = all_img_names\n",
        "    submission_df = submission_df[['img'] + [f\"c{i}\" for i in range(NUM_CLASSES)]]\n",
        "\n",
        "    submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
        "    print(f\"\\nâœ… K-Fold ì•™ìƒë¸” ì œì¶œ íŒŒì¼ '{SUBMISSION_FILE}' ìƒì„± ì™„ë£Œ!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}