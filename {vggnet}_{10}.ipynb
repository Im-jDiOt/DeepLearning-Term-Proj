{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdTbzYgKDluIinomqSGYMK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Im-jDiOt/DeepLearning-Term-Proj/blob/feature-vgg/%7Bvggnet%7D_%7B10%7D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqiAYaGCSvz8"
      },
      "outputs": [],
      "source": [
        " # ============================================\n",
        "# 1. Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
        "# ============================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import random # Ï∂îÍ∞Ä\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§:\", device)\n",
        "\n",
        "# Albumentations ÏÑ§Ïπò (KaggleÏóêÎäî Í∏∞Î≥∏ ÏÑ§ÏπòÎêòÏñ¥ ÏûàÏùå)\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ÏãúÎìú Í≥†Ï†ï Ïã§Ìñâ (Ïà´ÏûêÎäî ÏïÑÎ¨¥Í±∞ÎÇò ÏÉÅÍ¥ÄÏóÜÏúºÎÇò Î≥¥ÌÜµ 42 ÏÇ¨Ïö©)\n",
        "seed_everything(42)\n",
        "print(\"Seed set to 42 for reproducibility\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 2. Í≤ΩÎ°ú ÏÑ§Ï†ï (Kaggle Í∏∞Ï§Ä)\n",
        "# ============================================\n",
        "train_dir = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/train\"\n",
        "test_dir = \"/kaggle/input/state-farm-distracted-driver-detection/imgs/test\"\n",
        "driver_csv_path = \"/kaggle/input/state-farm-distracted-driver-detection/driver_imgs_list.csv\"\n",
        "\n",
        "# ============================================\n",
        "# 3. ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
        "# ============================================\n",
        "img_size = 224\n",
        "# [ÏàòÏ†ï] VGGNetÏùÄ Î©îÎ™®Î¶¨Î•º ÎßéÏù¥ ÏÇ¨Ïö©ÌïòÎØÄÎ°ú 32 -> 16ÏúºÎ°ú Ï§ÑÏûÑ (OOM Î∞©ÏßÄ)\n",
        "batch_size = 16\n",
        "num_classes = 10\n",
        "num_epochs = 15\n",
        "learning_rate = 3e-4\n",
        "weight_decay = 1e-4\n",
        "num_workers = 2\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 4. Dataset Ï†ïÏùò\n",
        "# ============================================\n",
        "class DriverDataset(Dataset):\n",
        "    def __init__(self, img_dir, df, driver_list, transform=None, is_test=False):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.images, self.labels = [], []\n",
        "\n",
        "        if is_test:\n",
        "            for img_name in sorted(os.listdir(img_dir)):\n",
        "                self.images.append(os.path.join(img_dir, img_name))\n",
        "\n",
        "        else:\n",
        "            subset = df[df['subject'].isin(driver_list)]\n",
        "            for _, row in subset.iterrows():\n",
        "                class_name = row['classname']\n",
        "                img_name = row['img']\n",
        "                path = os.path.join(img_dir, class_name, img_name)\n",
        "                self.images.append(path)\n",
        "                self.labels.append(int(class_name[1:]))\n",
        "\n",
        "        print(f\"{'TEST' if is_test else 'TRAIN'}: {len(self.images)}Í∞ú Ïù¥ÎØ∏ÏßÄ\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        # AlbumentationsÎäî resizeÎ•º transform ÏïàÏóêÏÑú Ï≤òÎ¶¨ÌïòÎäî Í≤å Ï¢ãÏßÄÎßå,\n",
        "        # Ïó¨Í∏∞ÏÑúÎäî ÏõêÎ≥∏ ÌÅ¨Í∏∞Î•º ÎßûÏ∂îÍ∏∞ ÏúÑÌï¥ ÎØ∏Î¶¨ resize\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)[\"image\"]\n",
        "\n",
        "        if self.is_test:\n",
        "            return img, os.path.basename(img_path)\n",
        "        else:\n",
        "            return img, self.labels[idx]\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 5. Albumentations Transform (ÌåÄÏõê ÏÑ§Ï†ï Ïú†ÏßÄ)\n",
        "# ============================================\n",
        "train_transform = A.Compose([\n",
        "    A.RandomScale(scale_limit=(-0.3, 0.0), p=1.0),  # 70~100% ÌÅ¨Í∏∞\n",
        "    A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=cv2.BORDER_CONSTANT),\n",
        "    A.RandomCrop(height=img_size, width=img_size, p=1.0),\n",
        "\n",
        "    # [ÏàòÏ†ï] Ï¢åÏö∞Î∞òÏ†Ñ Ï†úÍ±∞ (Ïö¥Ï†ÑÏÑù ÏúÑÏπò ÌòºÎèô Î∞©ÏßÄ)\n",
        "    # A.HorizontalFlip(p=0.5),\n",
        "\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
        "    A.GaussianBlur(blur_limit=(3, 5), p=0.2),\n",
        "    A.HueSaturationValue(p=0.3),\n",
        "\n",
        "    A.Normalize(mean=(0.485,0.456,0.406),\n",
        "                std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "eval_transform = A.Compose([\n",
        "    A.Resize(img_size, img_size),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406),\n",
        "                std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 6. GroupKFold split\n",
        "# ============================================\n",
        "df = pd.read_csv(driver_csv_path)\n",
        "groups = df['subject']\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "folds = list(gkf.split(df, df['classname'], groups))\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 7. Train / Validate Ìï®Ïàò\n",
        "# ============================================\n",
        "def train_epoch(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for x, y in tqdm(loader, desc=\"TRAIN\", leave=False):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    return running_loss / total, 100 * correct / total\n",
        "\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(loader, desc=\"VALID\", leave=False):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "            running_loss += loss.item() * x.size(0)\n",
        "            correct += (out.argmax(1) == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return running_loss / total, 100 * correct / total\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 8. Warmup + CosineAnnealing Scheduler\n",
        "# ============================================\n",
        "class WarmupCosineLR(torch.optim.lr_scheduler._LRScheduler):\n",
        "    def __init__(self, optimizer, warmup_epochs, max_epochs, last_epoch=-1):\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.max_epochs = max_epochs\n",
        "        self.base_lrs = [group['lr'] for group in optimizer.param_groups] # Ï¥àÍ∏∞Ìôî Ï∂îÍ∞Ä\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if self.last_epoch < self.warmup_epochs:\n",
        "            return [base_lr * (self.last_epoch + 1) / self.warmup_epochs\n",
        "                    for base_lr in self.base_lrs]\n",
        "\n",
        "        cos_epoch = self.last_epoch - self.warmup_epochs\n",
        "        total_cos = self.max_epochs - self.warmup_epochs\n",
        "\n",
        "        return [\n",
        "            base_lr * 0.5 * (1 + np.cos(np.pi * cos_epoch / total_cos))\n",
        "            for base_lr in self.base_lrs\n",
        "        ]\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 9. Fold ÌïôÏäµ (Fold 0Îßå Ïã§Ìñâ)\n",
        "# ============================================\n",
        "fold_idx = 0\n",
        "print(f\"===== Start Training Fold {fold_idx} =====\")\n",
        "\n",
        "train_idx, val_idx = folds[fold_idx]\n",
        "\n",
        "train_drivers = df.iloc[train_idx]['subject'].unique()\n",
        "val_drivers   = df.iloc[val_idx]['subject'].unique()\n",
        "\n",
        "train_dataset = DriverDataset(train_dir, df, train_drivers, transform=train_transform)\n",
        "val_dataset   = DriverDataset(train_dir, df, val_drivers, transform=eval_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 10. [ÏàòÏ†ïÎê®] VGG16_BN Î™®Îç∏ Ï†ïÏùò\n",
        "# ============================================\n",
        "# Î∞∞Ïπò Ï†ïÍ∑úÌôî(BN)Í∞Ä Ìè¨Ìï®Îêú Î≤ÑÏ†ÑÏùÑ Ïç®Ïïº ÌïôÏäµÏù¥ Ïûò Îê©ÎãàÎã§.\n",
        "model = models.vgg16_bn(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "# VGGÏùò Î∂ÑÎ•òÍ∏∞Îäî 'classifier'ÎùºÎäî Ïù¥Î¶ÑÏùò Sequential Î∏îÎ°ùÏûÖÎãàÎã§.\n",
        "# ÎßàÏßÄÎßâ Î†àÏù¥Ïñ¥Îäî Ïù∏Îç±Ïä§ 6Î≤àÏûÖÎãàÎã§: Linear(in_features=4096, out_features=1000, bias=True)\n",
        "num_ftrs = model.classifier[6].in_features # 4096\n",
        "model.classifier[6] = nn.Linear(num_ftrs, num_classes) # 10Í∞ú ÌÅ¥ÎûòÏä§Î°ú ÍµêÏ≤¥\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = WarmupCosineLR(optimizer, warmup_epochs=3, max_epochs=num_epochs)\n",
        "\n",
        "best_val_loss = 1e9\n",
        "best_path = f\"best_vgg16bn_fold{fold_idx}.pth\"\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 11. Training Loop\n",
        "# ============================================\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Train Loss {train_loss:.4f} | Acc {train_acc:.2f}%\")\n",
        "    print(f\"Val   Loss {val_loss:.4f} | Acc {val_acc:.2f}%\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        print(f\"üî• Best model updated: {best_path}\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 12. ÌÖåÏä§Ìä∏ÏÖã ÏòàÏ∏° & Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ±\n",
        "# ============================================\n",
        "print(\"\\nPredicting on Test Set...\")\n",
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "test_dataset = DriverDataset(test_dir, None, None, transform=eval_transform, is_test=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "all_probs = []\n",
        "all_imgs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, names in tqdm(test_loader, desc=\"PREDICT\"):\n",
        "        imgs = imgs.to(device)\n",
        "        out = model(imgs)\n",
        "        probs = torch.softmax(out, dim=1).cpu().numpy()\n",
        "\n",
        "        all_probs.append(probs)\n",
        "        all_imgs.extend(names)\n",
        "\n",
        "all_probs = np.vstack(all_probs)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'img': all_imgs,\n",
        "    **{f'c{i}': all_probs[:, i] for i in range(10)}\n",
        "})\n",
        "\n",
        "sub_path = f\"submission_vgg16bn_fold{fold_idx}.csv\"\n",
        "submission.to_csv(sub_path, index=False)\n",
        "\n",
        "print(\"\\nDONE:\", sub_path)"
      ]
    }
  ]
}